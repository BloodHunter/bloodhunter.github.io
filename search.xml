<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>Spring-boot定时任务</title>
      <link href="/2019/04/20/spring-boot-ding-shi-ren-wu/"/>
      <url>/2019/04/20/spring-boot-ding-shi-ren-wu/</url>
      
        <content type="html"><![CDATA[<h2 id="create-project"><a href="#create-project" class="headerlink" title="create project"></a>create project</h2><p>使用IDEA创建一个scheduler-demo项目，这里可以使用spring initializr插件初始化spring boot</p><p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1g291m3ryxrj311n0u00yl.jpg" alt=""></p><h2 id="EnableScheduling"><a href="#EnableScheduling" class="headerlink" title="@EnableScheduling"></a>@EnableScheduling</h2><p>注解EnableScheduling表示允许Spring Boot开启定时任务管理</p><pre><code>@SpringBootApplication@EnableSchedulingpublic class SchedulerDemoApplication {    public static void main(String[] args) {        SpringApplication.run(SchedulerDemoApplication.class, args);    }}</code></pre><h2 id="Scheduled"><a href="#Scheduled" class="headerlink" title="@Scheduled"></a>@Scheduled</h2><p>@Scheduled用来生成一个定时任务</p><p>@Scheduled的配置如下</p><table><thead><tr><th style="text-align:center">param</th><th style="text-align:center">explain</th></tr></thead><tbody><tr><td style="text-align:center">fixedDelay</td><td style="text-align:center">两个定时任务之间的间隔，即前一个任务执行完后，延迟delay毫秒再执行下一个任务</td></tr><tr><td style="text-align:center">fixedDelayString</td><td style="text-align:center">与fixedDelay相同，只不过用string类型表示时间</td></tr><tr><td style="text-align:center">fixedRate</td><td style="text-align:center">固定周期执行任务，例如每隔10s执行一次任务</td></tr><tr><td style="text-align:center">fixedRateString</td><td style="text-align:center">与fixedRate相同，用string表示时间</td></tr><tr><td style="text-align:center">cron</td><td style="text-align:center">用cron表达式来管理定时任务</td></tr><tr><td style="text-align:center">initialDelay</td><td style="text-align:center">执行第一个定时任务的延迟时间，只对fixedDelay或fixedRate任务生效</td></tr><tr><td style="text-align:center">initialDelayString</td><td style="text-align:center">与initialDelay相同</td></tr><tr><td style="text-align:center">zone</td><td style="text-align:center">时区，默认使用server的时区</td></tr></tbody></table><h3 id="fixedDelay与fixedRate的区别"><a href="#fixedDelay与fixedRate的区别" class="headerlink" title="fixedDelay与fixedRate的区别"></a>fixedDelay与fixedRate的区别</h3><p>对于fixedDelay任务，后个任务一定需要在前一个任务执行完并且再过delay毫秒后才会执行。对于下面的例子来说，delay为5s，而任务执行需要5s，所有每隔10s任务才会执行一次</p><pre><code>@Scheduled(fixedDelay = 5000)public void fixedDelayTask() throws Exception{    SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm&quot;);    System.out.println(dateFormat.format(new Date()) + &quot;:&quot; + &quot; task of fixed delay&quot;);    Thread.sleep(5000);}</code></pre><p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1g292hzkr0wj31700nqtcz.jpg" alt=""></p><p>对于fixedRate任务，他们的执行是严格按照时间周期，即使上一个任务还未执行完毕，只要时间一到就会里面执行</p><pre><code>@Scheduled(fixedRate = 5000,initialDelay = 5000)public void fixedRateTask() throws Exception{    SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);    System.out.println(dateFormat.format(new Date()) + &quot;:&quot; + &quot; task of fixed rate&quot;);    Thread.sleep(5000);}</code></pre><p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1g292nj7rxqj30u20rutca.jpg" alt=""></p><h3 id="cron表达式"><a href="#cron表达式" class="headerlink" title="cron表达式"></a>cron表达式</h3><pre><code>@Scheduled(cron = &quot;[Seconds] [Minutes] [Hours] [Day of month] [Month] [Day of week]&quot;)</code></pre><ul><li>second 取值在[0-59]，或者特殊字符 , - * /</li><li>minute 取值在[0-59], 或者特殊字符, - * /</li><li>hour 取值在[0-23],或者特殊字符, - * /</li><li>day of month 每个月第几天，取值在[0-31],或者特殊字段, - * / ? </li><li>month 取值[1-12]或者月份的英文描述，特殊字符为, - * /</li><li>day of week 取值为[1-7]，1表示星期天，2表示星期一，以此类推，也可用英文描述的星期，例如SUN，特殊字符为, - * / #</li></ul><table><thead><tr><th style="text-align:center">特殊字符</th><th style="text-align:center">含义</th></tr></thead><tbody><tr><td style="text-align:center">*</td><td style="text-align:center">表示任意值，若second为*，表示每秒都会触发该事件</td></tr><tr><td style="text-align:center">,</td><td style="text-align:center">表示列出枚举值，若minute为5,20 则表示第5分钟和第20分钟会触发事件</td></tr><tr><td style="text-align:center">/</td><td style="text-align:center">表示起始时间开始触发，然后每隔固定周期都会触发，例如minute为5/20，则在5分，25分，45分都会触发事件</td></tr><tr><td style="text-align:center">-</td><td style="text-align:center">表示取值范围，若minute为5-20，则表示从5分到20分，每分钟都会触发事件</td></tr><tr><td style="text-align:center">?</td><td style="text-align:center">只能用在每月第几天和星期两个域。表示不指定值，当2个子表达式其中之一被指定了值以后，为了避免冲突，需要将另一个子表达式的值设为”?”</td></tr><tr><td style="text-align:center">L</td><td style="text-align:center">表示最后，只能出现在week或者day of month中，若week为1L,表示在最后一个星期天</td></tr><tr><td style="text-align:center">W</td><td style="text-align:center">表示有效工作日(周一到周五),只能出现在day of month中</td></tr><tr><td style="text-align:center">#</td><td style="text-align:center">用于确定每个月第几个星期几，只能出现在day of month中，例如1#3 表示每个月第三个星期日</td></tr></tbody></table><h4 id="cron示例"><a href="#cron示例" class="headerlink" title="cron示例"></a>cron示例</h4><p>每天10点</p><pre><code>0 0 10 * * *</code></pre><p>每隔5分钟</p><pre><code>* */5 * * * *</code></pre><p>每天8点，8点半，9点，9点半，10点</p><pre><code>* */30 8-10 * * *</code></pre><h2 id="自定义线程池来管理定时任务"><a href="#自定义线程池来管理定时任务" class="headerlink" title="自定义线程池来管理定时任务"></a>自定义线程池来管理定时任务</h2><p>自定义线程池配置，例如线程池size，线程池名称</p><pre><code>@Configurationpublic class ScheduleConfig implements SchedulingConfigurer {    @Override    public void configureTasks(ScheduledTaskRegistrar scheduledTaskRegistrar) {        ThreadPoolTaskScheduler taskScheduler = new ThreadPoolTaskScheduler();        taskScheduler.setPoolSize(10);        taskScheduler.setThreadNamePrefix(&quot;schedule-task-pool&quot;);        taskScheduler.initialize();        scheduledTaskRegistrar.setTaskScheduler(taskScheduler);    }}</code></pre><p>定义一个cron任务</p><pre><code>@Scheduled(cron = &quot;*/5 * * * * *&quot;)public void cronTask(){    String name = Thread.currentThread().getName();    SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);    System.out.println(String.format(&quot;%s: current thread %s&quot;, dateFormat.format(new Date()), name));}</code></pre><p>运行程序，可以得到如下的运行结果，可以看到此时定时任务是运行在自定义的线程池里        </p><p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1g29486h5y6j311a08amyp.jpg" alt=""></p><h2 id="动态管理定时任务"><a href="#动态管理定时任务" class="headerlink" title="动态管理定时任务"></a>动态管理定时任务</h2><p>使用ThreadPoolTaskScheduler来生成定时任务，在通过维护定时任务的ScheduleFuture的map来实现动态管理定时任务</p><h3 id="DynamicScheduleTaskManager"><a href="#DynamicScheduleTaskManager" class="headerlink" title="DynamicScheduleTaskManager"></a>DynamicScheduleTaskManager</h3><pre><code>@Componentpublic class DynamicScheduleTaskManager {    private ThreadPoolTaskScheduler taskScheduler = new ThreadPoolTaskScheduler();    private Map&lt;Integer, ScheduledFuture&gt; futureMap = new HashMap&lt;&gt;();    @PostConstruct    public void init(){        taskScheduler.initialize();    }    /**     * 增加定时任务，若任务已存在，则删除旧任务，更新新任务     * @param taskConfig     */    public void addOrUpdateTask(TaskConfig taskConfig){        int taskConfigId = taskConfig.getId();        if (futureMap.containsKey(taskConfigId)){            deleteTask(taskConfig);        }        ScheduledFuture&lt;?&gt; scheduledFuture = taskScheduler.schedule(() -&gt; {            SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);            String timeFormat = dateFormat.format(new Date());            System.out.println(String.format(&quot;time:%s,process task,id:%d&quot;,timeFormat,taskConfigId));        }, new CronTrigger(taskConfig.getCron()));        futureMap.put(taskConfigId, scheduledFuture);    }    /**     * 删除任务     * @param taskConfig     */    public void deleteTask(TaskConfig taskConfig){        int taskConfigId = taskConfig.getId();        if (futureMap.containsKey(taskConfigId)){            ScheduledFuture scheduledFuture = futureMap.get(taskConfigId);            scheduledFuture.cancel(true);            System.out.println(&quot;delete task,id:&quot; + taskConfigId);        }    }}        TaskConfig@Getter@Setterpublic class TaskConfig {    /**     * id of task     */    private int id;    /**     * cron expression     */    private String cron;}</code></pre><h3 id="ScheduleController"><a href="#ScheduleController" class="headerlink" title="ScheduleController"></a>ScheduleController</h3><pre><code>@RestController@RequestMapping(produces = &quot;application/json; charset=utf-8&quot;)public class ScheduleController {    @Autowired    private DynamicScheduleTaskManager scheduleTaskManager;    @PostMapping(&quot;/add/task&quot;)    public String addTask(@RequestBody TaskConfig taskConfig){        scheduleTaskManager.addOrUpdateTask(taskConfig);        return &quot;success&quot;;    }    @PostMapping(&quot;/delete/task&quot;)    public void deleteTask(@RequestBody TaskConfig taskConfig){        scheduleTaskManager.deleteTask(taskConfig);    }}    </code></pre><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>####1. 新增taskConfig</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1g295imsq3uj31c80fwjt8.jpg" alt=""></p><p>####2. 更新taskConfig</p><p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1g295kc5vt5j31c80e2myy.jpg" alt=""></p><p>####3. 删除taskConfig<br><img src="https://ws3.sinaimg.cn/large/006tNc79gy1g295kx02yej31ck0es765.jpg" alt=""></p><p>####4.输出</p><p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1g295nz4evhj31b80feq68.jpg" alt=""></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://cloud.tencent.com/info/9d5782f8b475dfa8c41968f11aaea733.html" target="_blank" rel="noopener">SpringBoot定时任务及Cron表达式详解</a></li><li><a href="https://dzone.com/articles/running-on-time-with-springs-scheduled-tasks" target="_blank" rel="noopener">Running on Time With Spring’s Scheduled Tasks</a></li><li><a href="https://www.callicoder.com/spring-boot-task-scheduling-with-scheduled-annotation/" target="_blank" rel="noopener">How to Schedule Tasks with Spring Boot</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Spring Boot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Boot </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Raft协议之日志复制</title>
      <link href="/2019/03/31/raft-xie-yi-zhi-ri-zhi-fu-zhi/"/>
      <url>/2019/03/31/raft-xie-yi-zhi-ri-zhi-fu-zhi/</url>
      
        <content type="html"><![CDATA[<p>上篇<a href="https://bloodhunter.github.io/2019/03/30/raft-xie-yi-zhi-leader-xuan-ju/" target="_blank" rel="noopener">Raft协议之Leader选举</a>介绍了Leader选举的过程。Leader会处理来自客户端的请求，并将客户端更新操作以消息(Append Entries消息)的形式发送到集群中所有Follower节点。本文将介绍Raft协议日志复制的流程。</p><h2 id="日志复制"><a href="#日志复制" class="headerlink" title="日志复制"></a>日志复制</h2><p>假设集群中有A，B，C三个节点，其中节点A为Leader，此时有一个客户端发送了一个更新操作到集群，</p><ol><li>当收到客户端的请求，节点A会将更新操作记录到本地Log中</li><li>节点A向其他节点发送Append Entries消息，消息中记录了Leader节点最近收到的请求日志</li><li>B,C收到来自Leader的Append Entries消息时，会将该操作记录到本地Log中，并返回响应消息</li><li>当A收到超过半数的响应消息时，会认为集群中有半数以上的节点已经记录了该更新操作。Leader节点将该日志设置为已提交(committed)</li><li>Leader向客户端返回响应，并通知Follower节点该日志已被提交</li><li>Follower收到消息时，才会认为该日志已被提交</li></ol><p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1g1m0wfu6bzj31em0eatbw.jpg" alt=""><br><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1g1m149rhf4j31ok0e4dil.jpg" alt=""></p><h2 id="日志一致性"><a href="#日志一致性" class="headerlink" title="日志一致性"></a>日志一致性</h2><p>当一个新的Leader被选举出来，它的日志可能会其他Follower不一致，这时候需要一个机制来保证日志的一致性。</p><p>集群中每个节点都会维护一个本地log用于记录操作，另外，每个节点还会维护两个索引值，分别是commitIndex和lastApplied</p><blockquote><p>commitIndex表示当前节点<strong>已知的，最大的，已提交</strong>的日志索引</p><p>lastApplied索引表示当前节点最后一条被应用到状态机的日志索引，当commitIndex大于lastApplied时，会将lastApplied加1，并将lastApplied对应的日志应用到状态机</p></blockquote><p>Leader节点还需要知道每个Follower节点的日志复制到哪个位置，从而决定下次发送Append Entries消息中包含哪些日志记录。为此Leader会会维护两个数组，nextIndex[]和matchIndex[]</p><blockquote><p>nextIndex[]记录了需要发给每个Follower的下一条日志的索引值</p><p>matchIndex[]记录了已经复制给每个Follower的最大的日志索引值</p></blockquote><p>下面通过一个示例来说明nextIndex[]和matchIndex[]在日志复制过程的作用，假设有三个节点A,B,C，其中节点A为term=1的Leader，C由于宕机导致一段时间没有与Leader同步日志，此时C的log并不包含全部已提交日志，此时Leader记录的nextIndex[]和matchIndex[]的值如下</p><table><thead><tr><th>节点</th><th>nextIndex</th><th>matchIndex</th></tr></thead><tbody><tr><td>A</td><td>4</td><td>3</td></tr><tr><td>B</td><td>4</td><td>3</td></tr><tr><td>C</td><td>2</td><td>1</td></tr></tbody></table><p>因为Leader中记录了C的nextIndex=2，所以会向C发送index=2的Append Entries消息。C收到消息之后，会将日志记录到本地log中，并向Leader发送响应。Leader收到响应后，会递增C对应的nextIndex和matchIndex</p><table><thead><tr><th>节点</th><th>nextIndex</th><th>matchIndex</th></tr></thead><tbody><tr><td>A</td><td>4</td><td>3</td></tr><tr><td>B</td><td>4</td><td>3</td></tr><tr><td>C</td><td>3</td><td>2</td></tr></tbody></table><p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1g1m1z1w3kqj30so0f4q3p.jpg" alt=""></p><p>如果在上述例子中，节点C故障恢复后，节点A宕机后重启，导致节点B成为term=2的新Leader，此时B不知道旧Leader节点的nextIndex和matchIndex，所以新的Leader会重置nextIndex[]和matchIndex[],其中nextIndex[]全部重置为新Leader节点自身最后一条已提交日志的index值，而matchIndex[]全部重置为0</p><table><thead><tr><th>节点</th><th>nextIndex</th><th>matchIndex</th></tr></thead><tbody><tr><td>A</td><td>4</td><td>0</td></tr><tr><td>B</td><td>4</td><td>0</td></tr><tr><td>C</td><td>4</td><td>0</td></tr></tbody></table><p>新的Leader会发送新的Append Entries消息(term=2,index=4),对于C节点，它没有index=2，index=3两条日志，因此追加失败。</p><p>Leader收到C追加日志失败的响应，会将nextIndex减1，即发送(term=2,index=3)的Append Entries消息给C。循环反复，不断减小nextIndex的值，直到节点C返回追加成功的响应。</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1g1m2man8dgj31mq0fignb.jpg" alt=""></p><h2 id="选举限制"><a href="#选举限制" class="headerlink" title="选举限制"></a>选举限制</h2><ol><li>Candidate在拉票时需要携带自己本地已经持久化的最新的日志信息，等待投票的节点如果发现自己本地的日志信息比竞选的Candidate更新，则拒绝给他投票</li><li>只允许Leader提交（commit）当前Term的日志。</li></ol><p>第一条限制保证了已经Commited日志不会丢失，第二条限制是为了防止即使超过半数的节点已提交了日志，依然有可能被新选Leader覆盖的情况</p><p>例如<br><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1g1m2ryimtfj312z0u0142.jpg" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> Raft </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Raft </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Raft协议之Leader选举</title>
      <link href="/2019/03/30/raft-xie-yi-zhi-leader-xuan-ju/"/>
      <url>/2019/03/30/raft-xie-yi-zhi-leader-xuan-ju/</url>
      
        <content type="html"><![CDATA[<h2 id="Raft节点状态"><a href="#Raft节点状态" class="headerlink" title="Raft节点状态"></a>Raft节点状态</h2><p>Raft协议的工作模式是一个Leader和多个Follower节点的模式。在Raft协议中，每个节点都维护了一个状态机，该状态机有3种状态，Leader，Follower，Candidate，在任意时间，集群中的任意节点都处于这三个状态之一。</p><p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1g1kyvbmbw1j30ua0fw3zt.jpg" alt=""></p><h3 id="Leader"><a href="#Leader" class="headerlink" title="Leader"></a>Leader</h3><blockquote><p>Leader节点的主要工作有两个，一个是处理所有client的请求，另一个是定期向Follower节点发送心跳信息。</p><p>当收到客户端写入请求时，Leader节点会在本地追加一个日志，然后将其封装成消息发送到集群中的其他Follow节点。Follower节点收到对应消息对其进行响应。Leader如果收到超过半数节点的响应信息，则认为该条日志已被committed，可以对client返回响应</p><p>定期向Follower发送心跳信息是为了防止集群其他Follower节点的选举计时器超时而导致触发新一轮选举</p></blockquote><p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1g1kx1bm3g3j30ra0jugmo.jpg" alt=""></p><h3 id="Follower"><a href="#Follower" class="headerlink" title="Follower"></a>Follower</h3><blockquote><p>Follower节点不会处理任何请求，他们只是简单的响应来自Leader或者Candidate的请求。Follower会将client节点的请求重定向给集群的Leader节点</p></blockquote><h3 id="Candidate"><a href="#Candidate" class="headerlink" title="Candidate"></a>Candidate</h3><blockquote><p>Candidate节点由Follower节点转换而来，当Follower节点长时间没有收到来自Leader节点发送的心跳信息，则该节点的选举计时器就会过期，同时将自身状态变为Candidate，发起新一轮选举</p></blockquote><h2 id="Leader选举"><a href="#Leader选举" class="headerlink" title="Leader选举"></a>Leader选举</h2><p>在Raft协议中有两个时间控制Leader选举发生</p><ol><li>选举超时时间(election timeout)</li><li>心跳超时时间(heartbeat timeout)</li></ol><blockquote><p>选举超时时间：Follower在election timeout时间内没有收到Leader的心跳信息，则切换为Candidate开始新一轮的选举。election timeout一般设置为150ms~300ms的随机数，<strong>也即每个节点的选举超时时间一般都不同</strong></p><p>心跳超时时间：Leader向Follower节点发送心跳消息的<strong>间隔</strong>时间</p></blockquote><h3 id="初始选举"><a href="#初始选举" class="headerlink" title="初始选举"></a>初始选举</h3><ol><li>集群初始化时，所有节点为Follower</li><li>在经过一段时间后(election timeout)收不到Leader的心跳信息，则认为Leader出现故障，切换为Candidate发起选举</li><li>Raft协议中每次发起选举，任期(Term)都会进行递增，每个节点都会记录当前任期(currentTerm)</li><li>当一个Candidate收到超过半数节点的选票，则成为Leader</li></ol><p>假设集群有A，B,C三个节点，若A节点的选举超时时间最先超时，则</p><ol><li>A切换为Candidate，同时重置选举计时器(election timer)</li><li>A先把票投给自己，并向集群其他节点B,C发送选举请求(Request vote)，此时A的term=1</li><li>B,C收到选举请求时，因为两个节点的term=0，且都是Follower状态，所以它们会把选票投给A节点</li><li>B,C节点投票之后，会重置选举计时器，这是防止一个任期中出现多个Candidate，导致选举失败</li><li>A节点得到超过半数的选票，在term=1的任期中，A成为集群的Leader</li><li>A节点成为Leader后，会定期向B,C节点发送心跳信息，防止B,C节点的选举计时器超时而触发新一轮选举，所以心跳超时时间要远小于选举超时时间</li></ol><p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1g1l00eqkbaj314x0u00xd.jpg" alt=""></p><h3 id="出现多个Candidate节点"><a href="#出现多个Candidate节点" class="headerlink" title="出现多个Candidate节点"></a>出现多个Candidate节点</h3><p>当出现多个Candidate同时发起选举，而每个Candidate都获取不到半数的选票，这种情况Raft情况会如何处理呢？</p><p>假设集群有4个节点，其中节点A和节点B的选举计时器同时到期，切换为Candidate并向集群其他节点发起选举请求</p><ol><li>假设A的选举请求先到C，而B的请求先到D，则节点A和节点B得票数都为2，没有超过半数</li><li>在这种情况下，这次选举以失败结束，随着时间流逝，当任意节点的选举计时器到期后，会再一次发起选举。</li><li>由于election timeout是一个时间区间内取的随机数，所以上述情况多次出现的概率不大</li></ol><h3 id="宕机选举"><a href="#宕机选举" class="headerlink" title="宕机选举"></a>宕机选举</h3><p>假设集群中有4个节点，其中A为Leader，B，C，D为Follower，在系统运行一段时间后(当前term为5)，A因为故障而宕机。</p><ol><li>由于Leader不在往Follower发送心跳消息，Follower的election timer将会过期，假设为D节点最先超时，切换为Candidate发起新一轮选举</li><li>当B和C收到节点D的选举请求后，会将其选票投给D，由于节点A已经宕机，无法投票，但D节点仍获得超过半数的投票，成为新任期(term=6)的Leader，并开始向其他节点发送心跳信息</li><li>当A节点恢复后，会收到来自D节点的心跳信息，改信息中携带的任期号(term=6)大于节点A当前记录的任期号(term=5),A节点切换为Follower</li></ol><p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1g1lxrmbw9ij31pa0iw42h.jpg" alt=""></p><p>在Raft协议中，当某个节点收到的消息中所携带的任期号大于当前节点记录的任期号，那么节点会自动切换为Follower，并且更新自身记录的任期号</p><h2 id="Leader选举时间要求"><a href="#Leader选举时间要求" class="headerlink" title="Leader选举时间要求"></a>Leader选举时间要求</h2><p>通过上述几个例子，可以看到Leader选举对于时间的要求比较严格，一般要求整个集群的时间满足如下不等式</p><pre><code>广播时间 &lt;&lt; 选举超时时间 &lt;&lt; 平均故障间隔时间</code></pre><p>广播时间指从一个节点发送心跳信息到其他节点收到信息并发出响应的平均时间</p><p>平均故障时间是指一个节点，两次故障之间的平均时间。</p><p>为了保证集群可用，广播时间必须比选举超时时间小一个数量级，这样Leader才能发送心跳信息来重置其他Follower的选举计时器，从而防止他们切换为Candidate，触发新一轮选举。选举超时时间是一个<strong>随机数</strong>    ，这样可以减少出现多个Candidate而瓜分选票的情况。</p><p>一般情况广播时间可以做到0.5ms~50ms，选举超时时间一般设置为200ms~1s之间。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>Raft协议中节点有三种状态Leader，Follower，Candidate</li><li>控制选举触发的时间有两个，一是选举超时时间(election timeout)，一个心跳超时时间(heartbeat timeout)</li><li>选举计时器(election timer)每次重置都会从某个时间区间随机取一个随机数，作为新的选举超时时间，这样是为了避免出现多个Candidate而导致选举无效的情况出现</li></ol>]]></content>
      
      
      <categories>
          
          <category> Raft </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Raft </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring Boot多数据源</title>
      <link href="/2019/03/23/spring-boot-duo-shu-ju-yuan/"/>
      <url>/2019/03/23/spring-boot-duo-shu-ju-yuan/</url>
      
        <content type="html"><![CDATA[<h2 id="maven-配置"><a href="#maven-配置" class="headerlink" title="maven 配置"></a>maven 配置</h2><pre><code>&lt;parent&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;    &lt;version&gt;2.1.3.RELEASE&lt;/version&gt;    &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt;&lt;dependencies&gt;     &lt;dependency&gt;        &lt;groupId&gt;mysql&lt;/groupId&gt;        &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;        &lt;scope&gt;runtime&lt;/scope&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;        &lt;optional&gt;true&lt;/optional&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;        &lt;artifactId&gt;lombok&lt;/artifactId&gt;        &lt;optional&gt;true&lt;/optional&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;        &lt;scope&gt;test&lt;/scope&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;    &lt;/dependency&gt; &lt;/dependencies&gt;</code></pre><h2 id="application-properties-配置"><a href="#application-properties-配置" class="headerlink" title="application.properties 配置"></a>application.properties 配置</h2><p>配置两个数据源</p><pre><code>## 数据源1user.datasource.jdbc-url=jdbc:mysql://localhost:3306/testuser.datasource.username=rootuser.datasource.password=root## 数据源2product.datasource.jdbc-url=jdbc:mysql://172.16.28.3:6606/testproduct.datasource.username=rootproduct.datasource.password=meitu.com</code></pre><h2 id="数据实例"><a href="#数据实例" class="headerlink" title="数据实例"></a>数据实例</h2><p>构建两个实例与两个数据源中的表格对应</p><h3 id="user"><a href="#user" class="headerlink" title="user"></a>user</h3><pre><code>@Entity@Getter@Setterpublic class User {    @Id    @GeneratedValue(strategy = GenerationType.IDENTITY)    private int id;    private String name;}    CREATE TABLE `user` (  `id` int(11) NOT NULL AUTO_INCREMENT,  `name` varchar(20) DEFAULT NULL,  PRIMARY KEY (`id`))</code></pre><h3 id="product"><a href="#product" class="headerlink" title="product"></a>product</h3><pre><code>@Entity@Getter@Setterpublic class Product {    @Id    @GeneratedValue(strategy = GenerationType.IDENTITY)    private int id;    private String name;}CREATE TABLE `product` (  `id` int(11) NOT NULL AUTO_INCREMENT,  `name` varchar(20) DEFAULT NULL,  PRIMARY KEY (`id`))</code></pre><h2 id="包结构"><a href="#包结构" class="headerlink" title="包结构"></a>包结构</h2><p>为了读取不同数据源的配置，根据包结构来对配置进行区分</p><pre><code>src/main/java    - com.wbl.springDemo        - produce            - data                        - repo                        - config        - user            - data            - repo            - config</code></pre><h3 id="ProductDao"><a href="#ProductDao" class="headerlink" title="ProductDao"></a>ProductDao</h3><pre><code>@Repositorypublic interface ProductDao extends JpaRepository&lt;Product, Integer&gt; {}                </code></pre><h3 id="UserDao"><a href="#UserDao" class="headerlink" title="UserDao"></a>UserDao</h3><pre><code>@Repositorypublic interface UserDao extends JpaRepository&lt;User, Integer&gt; {}    </code></pre><h2 id="数据源配置"><a href="#数据源配置" class="headerlink" title="数据源配置"></a>数据源配置</h2><h3 id="user配置"><a href="#user配置" class="headerlink" title="user配置"></a>user配置</h3><pre><code>@Configuration@EnableTransactionManagement@EnableJpaRepositories(        entityManagerFactoryRef = &quot;userEntityManagerFactory&quot;,        transactionManagerRef = &quot;userTransactionManager&quot;,        basePackages = {                &quot;com.wbl.spingbootdemo.muldatasource.user.repo&quot;        })public class UserConfig {    @Primary    @Bean(&quot;userDatasource&quot;)    @ConfigurationProperties(&quot;user.datasource&quot;)    public HikariDataSource userDatasource(){        return DataSourceBuilder.create().type(HikariDataSource.class).build();    }    @Primary    @Bean(&quot;userEntityManagerFactory&quot;)    public LocalContainerEntityManagerFactoryBean entityManagerFactory(            EntityManagerFactoryBuilder builder,            @Qualifier(&quot;userDatasource&quot;)DataSource dataSource){        return builder.dataSource(dataSource)                .packages(&quot;com.wbl.spingbootdemo.muldatasource.user.data&quot;)                .persistenceUnit(&quot;db1&quot;)                .build();    }    @Primary    @Bean(&quot;userTransactionManager&quot;)    public PlatformTransactionManager userTransactionManager(@Qualifier(&quot;userEntityManagerFactory&quot;) EntityManagerFactory entityManagerFactory){        return new JpaTransactionManager(entityManagerFactory);    }}</code></pre><h3 id="product-配置"><a href="#product-配置" class="headerlink" title="product 配置"></a>product 配置</h3><pre><code>@EnableTransactionManagement@EnableJpaRepositories(        entityManagerFactoryRef = &quot;productEntityManagerFactory&quot;,        transactionManagerRef = &quot;productTransactionManager&quot;,        basePackages = {                &quot;com.wbl.spingbootdemo.muldatasource.product.repo&quot;        })public class ProductConfig {    @Bean(&quot;productDatasource&quot;)    @ConfigurationProperties(prefix = &quot;product.datasource&quot;)    public DataSource productDatasource(){        return DataSourceBuilder.create().build();    }    @Bean(&quot;productEntityManagerFactory&quot;)    public LocalContainerEntityManagerFactoryBean productEntityManagerFactory(            EntityManagerFactoryBuilder builder,            @Qualifier(&quot;productDatasource&quot;)DataSource productDatasource){        return builder.dataSource(productDatasource)                .packages(&quot;com.wbl.spingbootdemo.muldatasource.product.data&quot;)                .persistenceUnit(&quot;db2&quot;)                .build();    }    @Bean(name = &quot;productTransactionManager&quot;)    public PlatformTransactionManager productTransactionManager(            @Qualifier(&quot;productEntityManagerFactory&quot;) EntityManagerFactory productEntityManagerFactory    ) {        return new JpaTransactionManager(productEntityManagerFactory);    }}</code></pre><p>其中@Primary的作用是，在对同一接口有几种不同实现时，告诉spring默认注入哪个实例</p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><pre><code>@RunWith(SpringRunner.class)@SpringBootTestpublic class MultipleDataSourcesProductTests {    @Autowired    ProductDao productDao;    @Test    @Transactional(&quot;productTransactionManager&quot;)    public void testSaveProduct(){        Product product = new Product();        product.setName(&quot;product1&quot;);        product = productDao.save(product);        Assert.assertNotNull(productDao.findById(product.getId()));    }}        @RunWith(SpringRunner.class)@SpringBootTestpublic class MultipleDataSourcesUserTests {    @Autowired    private UserDao userDao;    @Test//    @Transactional(&quot;userTransactionManager&quot;)    public void testSaveUser(){        User user = new User();        user.setName(&quot;name&quot;);        userDao.save(user);    }}</code></pre><p>其中加入@Transactional注解，数据不会真正保存在数据库中</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>spring boot 多数据源配置步骤总结</p><ol><li>配置application.properties，填入数据源的详细信息</li><li>生成entity</li><li>生成entity对应的Repository</li><li>配置entityManager以及TransactionManager(事务管理)</li></ol>]]></content>
      
      
      <categories>
          
          <category> Spring Boot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Boot </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>InfluxDB的RP与CQ</title>
      <link href="/2019/03/16/influxdb-de-rp-yu-cq/"/>
      <url>/2019/03/16/influxdb-de-rp-yu-cq/</url>
      
        <content type="html"><![CDATA[<h2 id="Retention-Policy"><a href="#Retention-Policy" class="headerlink" title="Retention Policy"></a>Retention Policy</h2><p>RP表示数据保留策略，策略包含数据保留时长，备份个数等信息。InfluxDB为每个database默认创建了一个默认的RP，名称为autogen，默认数据保留时间为永久。</p><h3 id="查看RP"><a href="#查看RP" class="headerlink" title="查看RP"></a>查看RP</h3><pre><code>show retention policies</code></pre><p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1g14lvppooxj311808sjtd.jpg" alt="">    </p><h3 id="新建RP"><a href="#新建RP" class="headerlink" title="新建RP"></a>新建RP</h3><pre><code>CREATE RETENTION POLICY &lt;retention_policy_name&gt; ON &lt;database_name&gt; DURATION &lt;duration&gt; REPLICATION &lt;n&gt; [SHARD DURATION &lt;duration&gt;] [DEFAULT]</code></pre><table><thead><tr><th>name</th><th>example</th></tr></thead><tbody><tr><td>duration</td><td>表示数据保留时间，最长为INF，最短为1h</td></tr><tr><td>replication</td><td>备份数，在集群模式中可用</td></tr><tr><td>shard duration</td><td>一个分片包含的时间，InfluxDB会根据duration设置默认的shard duration</td></tr><tr><td>default</td><td>表示该RP为默认的RP</td></tr></tbody></table><p>新建一个RP，保留时间为1d</p><pre><code>CREATE RETENTION POLICY &quot;one_day_only&quot; ON &quot;NOAA_water_database&quot; DURATION 1d REPLICATION 1    </code></pre><h3 id="修改RP"><a href="#修改RP" class="headerlink" title="修改RP"></a>修改RP</h3><pre><code>ALTER RETENTION POLICY &lt;retention_policy_name&gt; ON &lt;database_name&gt; DURATION &lt;duration&gt; REPLICATION &lt;n&gt; SHARD DURATION &lt;duration&gt; DEFAULT</code></pre><h3 id="删除RP"><a href="#删除RP" class="headerlink" title="删除RP"></a>删除RP</h3><pre><code>DROP RETENTION POLICY &lt;retention_policy_name&gt; ON &lt;database_name&gt;</code></pre><h3 id="RP使用"><a href="#RP使用" class="headerlink" title="RP使用"></a>RP使用</h3><p>在查询或者插入数据时，需要指定RP，若不指定，则认为选择了默认的RP</p><pre><code>select sum(value) from &quot;rp_1h&quot;.test_me where time &gt; now() - 6h;</code></pre><p>假设默认RP为autogen，则</p><pre><code>select sum(value) from test_me where time &gt; now() - 6h;=== 两条语句等价select sum(value) from &quot;autogen&quot;.test_me where time &gt; now() - 6h;</code></pre><h2 id="Continue-Query"><a href="#Continue-Query" class="headerlink" title="Continue Query"></a>Continue Query</h2><p>InfluxDB提供了自动聚合数据，并将聚合数据存储至measurement的方法，即continue query</p><h3 id="基础用法"><a href="#基础用法" class="headerlink" title="基础用法"></a>基础用法</h3><pre><code>CREATE CONTINUOUS QUERY &lt;cq_name&gt; ON &lt;database_name&gt;BEGIN  &lt;cq_query&gt;END            </code></pre><p>其中cq_query表示聚合语句，</p><pre><code>SELECT &lt;function[s]&gt; INTO &lt;destination_measurement&gt; FROM &lt;measurement&gt; [WHERE &lt;stuff&gt;] GROUP BY time(&lt;interval&gt;)[,&lt;tag_key[s]&gt;]</code></pre><p>cq_query的where条件中不需要设置时间区间，inflxuDB会自动生成时间区间</p><p>influxDB根据cq_query中的Group By time(interval)的interval，每隔interval执行一次cq_query，而查询的时间区间也为interval。例如当前时间为17：00，interval为1h，则cq_query会查询16:00至16：59分的数据。</p><p>生成一条CQ如下，则每隔1h执行一次query</p><pre><code>CREATE CONTINUOUS QUERY &quot;cq_basic&quot; ON &quot;transportation&quot;BEGIN  SELECT mean(&quot;passengers&quot;) INTO &quot;average_passengers&quot; FROM &quot;bus_data&quot; GROUP BY time(1h)END</code></pre><p>在8：00，时间区间为[7:00,8:00)</p><p>在9：00，时间区间为[8:00,9:00)</p><p>根据CQ的特性，可以进行数据降准，例如将维度为1m的数据聚合为5m,measurement_1m存储维度为1m的数据，cq每隔5m对数据进行聚合，并将聚合的数据存储到rp_5m.measurement_5m中，此时维度变成了5m</p><pre><code>CREATE CONTINUOUS QUERY &quot;cq_basic_5m&quot; ON &quot;test_database&quot;BEGIN  SELECT mean(*) INTO &quot;rp_5m&quot;.&quot;measurement_5m&quot;   FROM &quot;rp_1m&quot;.&quot;measurement_1m&quot;  GROUP BY time(5m),*END    </code></pre><h4 id="时间偏移"><a href="#时间偏移" class="headerlink" title="时间偏移"></a>时间偏移</h4><pre><code>CREATE CONTINUOUS QUERY &quot;cq_basic_offset&quot; ON &quot;transportation&quot;BEGIN  SELECT mean(&quot;passengers&quot;) INTO &quot;average_passengers&quot; FROM &quot;bus_data&quot; GROUP BY time(1h,15m)END</code></pre><p>group by time(1h) 与 group by time(1h,15m)的区别</p><p>group by time(1h)的执行时间点和时间区间</p><table><thead><tr><th>time</th><th>range</th></tr></thead><tbody><tr><td>8:00</td><td>[7:00,8:00)</td></tr><tr><td>9:00</td><td>[8:00,9:00)</td></tr></tbody></table><p>group by time(1h, 15m)的执行时间点和时间区间</p><table><thead><tr><th>time</th><th>range</th></tr></thead><tbody><tr><td>8:15</td><td>[7:15,8:15)</td></tr><tr><td>9:15</td><td>[8:15,9:15)</td></tr></tbody></table><h3 id="高级用法"><a href="#高级用法" class="headerlink" title="高级用法"></a>高级用法</h3><pre><code>CREATE CONTINUOUS QUERY &lt;cq_name&gt; ON &lt;database_name&gt;RESAMPLE EVERY &lt;interval&gt; FOR &lt;interval&gt;BEGIN  &lt;cq_query&gt;END    </code></pre><p>其中EVERY表示执行间隔，即每隔多久执行一次，FOR表示时间区间，即每次执行查询多久的数据，区间为[now - for_interval, now)</p><h4 id="EVERY-30m-GROUP-BY-time-1h"><a href="#EVERY-30m-GROUP-BY-time-1h" class="headerlink" title="EVERY=30m,GROUP BY time(1h)"></a>EVERY=30m,GROUP BY time(1h)</h4><pre><code>CREATE CONTINUOUS QUERY &quot;cq_advanced_every&quot; ON &quot;transportation&quot;RESAMPLE EVERY 30mBEGIN  SELECT mean(&quot;passengers&quot;) INTO &quot;average_passengers&quot; FROM &quot;bus_data&quot; GROUP BY time(1h)END</code></pre><table><thead><tr><th>time</th><th>range</th><th>返回time</th></tr></thead><tbody><tr><td>8:00</td><td>[7:00,8:00)</td><td>7:00</td></tr><tr><td>8:30</td><td>[7:00,8:00)</td><td>7:00</td></tr><tr><td>9:00</td><td>[8:00,9:00)</td><td>8:00</td></tr></tbody></table><p>可以看到区间[7:00,8:00)的数据被查询了两次，后一次的数据会覆盖前一次的查询</p><h4 id="FOR-1h-GROUP-BY-time-30m"><a href="#FOR-1h-GROUP-BY-time-30m" class="headerlink" title="FOR=1h,GROUP BY time(30m)"></a>FOR=1h,GROUP BY time(30m)</h4><pre><code>CREATE CONTINUOUS QUERY &quot;cq_advanced_for&quot; ON &quot;transportation&quot;RESAMPLE FOR 1hBEGIN  SELECT mean(&quot;passengers&quot;) INTO &quot;average_passengers&quot; FROM &quot;bus_data&quot; GROUP BY time(30m)END</code></pre><table><thead><tr><th>time</th><th>range</th><th>返回time</th></tr></thead><tbody><tr><td>8:00</td><td>[7:00,8:00)</td><td>7:00<br>7:30</td></tr><tr><td>8:30</td><td>[7:30,8:30)</td><td>7:30<br>8:00</td></tr><tr><td>9:00</td><td>[8:00,9:00)</td><td>8:00<br>8:30</td></tr></tbody></table><p>每次查询都会返回两条数据，每个时间点的数据都被计算了两次，这样在一定程度可以避免数据延迟而导致CQ数据丢失的情况。</p><h4 id="EVERY-1h，FOR-90m，GROUP-BY-time-30m"><a href="#EVERY-1h，FOR-90m，GROUP-BY-time-30m" class="headerlink" title="EVERY=1h，FOR=90m，GROUP BY time(30m)"></a>EVERY=1h，FOR=90m，GROUP BY time(30m)</h4><pre><code>CREATE CONTINUOUS QUERY &quot;cq_advanced_every_for&quot; ON &quot;transportation&quot;RESAMPLE EVERY 1h FOR 90mBEGIN  SELECT mean(&quot;passengers&quot;) INTO &quot;average_passengers&quot; FROM &quot;bus_data&quot; GROUP BY time(30m)END</code></pre><table><thead><tr><th>time</th><th>range</th><th>返回time</th></tr></thead><tbody><tr><td>8:00</td><td>[6:30,8:00)</td><td>6:30<br>7:00<br>7:30</td></tr><tr><td>9:00</td><td>[7:30,9:00)</td><td>7:30<br>8:00<br>8:30    </td></tr></tbody></table><p>FOR interval必须大于GROUP by time(interval)以及EVERY interval，否则InfluxDB会返回如下错误，因为这样会造成数据丢失</p><pre><code>error parsing query: FOR duration must be &gt;= GROUP BY time duration: must be a minimum of &lt;minimum-allowable-interval&gt; got &lt;user-specified-interval&gt;</code></pre><h3 id="CQ管理"><a href="#CQ管理" class="headerlink" title="CQ管理"></a>CQ管理</h3><h4 id="查看CQ"><a href="#查看CQ" class="headerlink" title="查看CQ"></a>查看CQ</h4><pre><code>SHOW CONTINUOUS QUERIES</code></pre><h4 id="删除CQ"><a href="#删除CQ" class="headerlink" title="删除CQ"></a>删除CQ</h4><pre><code>DROP CONTINUOUS QUERY &lt;cq_name&gt; ON &lt;database_name&gt;</code></pre><h4 id="修改CQ"><a href="#修改CQ" class="headerlink" title="修改CQ"></a>修改CQ</h4><p>CQ不能被修改，如果需要需改，只能先删除CQ，在重新创建CQ</p><h2 id="使用CQ与RP的目的"><a href="#使用CQ与RP的目的" class="headerlink" title="使用CQ与RP的目的"></a>使用CQ与RP的目的</h2><ol><li>利用CQ可以达到数据降准的目的，即将细粒度的数据转换为粗粒度的数据，例如1m维度的数据可以聚合为5m数据</li><li>不同粒度的数据可以设置不同的RP，节省存储空间。例如1m维度的数据可以保存7d，而5m维度的数据则可以保存30d，细粒度的数据主要用于及时排查问题，粗粒度的数据在于查看变化趋势。            </li></ol>]]></content>
      
      
      <categories>
          
          <category> 监控 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> InfluxDB </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>InfluxDB group by time()说明</title>
      <link href="/2019/03/08/influxdb-group-by-time-shuo-ming/"/>
      <url>/2019/03/08/influxdb-group-by-time-shuo-ming/</url>
      
        <content type="html"><![CDATA[<h2 id="使用姿势"><a href="#使用姿势" class="headerlink" title="使用姿势"></a>使用姿势</h2><pre><code>SELECT &lt;function&gt;(&lt;field_key&gt;) FROM_clause WHERE &lt;time_range&gt; GROUP BY time(&lt;time_interval&gt;),[tag_key] [fill(&lt;fill_option&gt;)]</code></pre><p>group time(interval)会对查询结果按照interval进行聚合，例如，time(5m),interval=5m, 则会将数据每隔5m进行聚合</p><h2 id="示例说明"><a href="#示例说明" class="headerlink" title="示例说明"></a>示例说明</h2><p>样例数据</p><pre><code>&gt; SELECT &quot;water_level&quot;,&quot;location&quot; FROM &quot;h2o_feet&quot; WHERE time &gt;= &#39;2015-08-18T00:00:00Z&#39; AND time &lt;= &#39;2015-08-18T00:30:00Z&#39;name: h2o_feet--------------time                   water_level   location2015-08-18T00:00:00Z   8.12          coyote_creek2015-08-18T00:00:00Z   2.064         santa_monica2015-08-18T00:06:00Z   8.005         coyote_creek2015-08-18T00:06:00Z   2.116         santa_monica2015-08-18T00:12:00Z   7.887         coyote_creek2015-08-18T00:12:00Z   2.028         santa_monica2015-08-18T00:18:00Z   7.762         coyote_creek2015-08-18T00:18:00Z   2.126         santa_monica2015-08-18T00:24:00Z   7.635         coyote_creek2015-08-18T00:24:00Z   2.041         santa_monica2015-08-18T00:30:00Z   7.5           coyote_creek2015-08-18T00:30:00Z   2.051         santa_monica</code></pre><p>此时按照interval=12m 对数据进行聚合，查询语句以及查询结果如下：</p><pre><code>&gt; SELECT COUNT(&quot;water_level&quot;) FROM &quot;h2o_feet&quot; WHERE &quot;location&quot;=&#39;coyote_creek&#39; AND time &gt;= &#39;2015-08-18T00:00:00Z&#39; AND time &lt;= &#39;2015-08-18T00:30:00Z&#39; GROUP BY time(12m)name: h2o_feet--------------time                   count2015-08-18T00:00:00Z   22015-08-18T00:12:00Z   22015-08-18T00:24:00Z   2</code></pre><p>InfluxDB在计算group by时，会用到两个时间区间，一个是根据interval形成的预设区间，一个是根据where语句中的time_range形成的区间，在上述例子中time_range为[2015-08-18T00:00:00Z,2015-08-18T00:30:00Z),详细说明如下所示</p><table><thead><tr><th>预设区间</th><th>where time_range</th><th>数据</th><th>返回时间戳</th></tr></thead><tbody><tr><td>time&gt;=2015-08-18T00:00:00Z and time&lt;2015-08-18T00:12:00Z</td><td>time&gt;=2015-08-18T00:00:00Z and time&lt;2015-08-18T00:12:00Z</td><td>8.12，8.005</td><td>2015-08-18T00:00:00Z</td></tr><tr><td>time&gt;=2015-08-18T00:12:00Z and time&lt;2015-08-18T00:24:00Z</td><td>time&gt;=2015-08-18T00:12:00Z and time&lt;2015-08-18T00:24:00Z</td><td>7.887，7.762</td><td>2015-08-18T00:12:00Z</td></tr><tr><td>time&gt;=2015-08-18T00:24:00Z and time&lt;2015-08-18T00:36:00Z</td><td>time&gt;=2015-08-18T00:24:00Z and time&lt;2015-08-18T00:30:00Z</td><td>7.635,7.5</td><td>2015-08-18T00:24:00Z</td></tr></tbody></table><h2 id="异常情况说明"><a href="#异常情况说明" class="headerlink" title="异常情况说明"></a>异常情况说明</h2><p>有的时候使用group by time()，会发现查询结果的时间与where条件中的time_range冲突，这是因为InfluxDB在返回时间时是以预设区间的时间为主。详细说明如下</p><p>样本数据</p><pre><code>&gt; SELECT &quot;water_level&quot; FROM &quot;h2o_feet&quot; WHERE &quot;location&quot;=&#39;coyote_creek&#39; AND time &gt;= &#39;2015-08-18T00:00:00Z&#39; AND time &lt;= &#39;2015-08-18T00:18:00Z&#39;name: h2o_feet--------------time                   water_level2015-08-18T00:00:00Z   8.122015-08-18T00:06:00Z   8.0052015-08-18T00:12:00Z   7.8872015-08-18T00:18:00Z   7.762</code></pre><p>查询语句以及查询结果：</p><pre><code>&gt; SELECT COUNT(&quot;water_level&quot;) FROM &quot;h2o_feet&quot; WHERE &quot;location&quot;=&#39;coyote_creek&#39; AND time &gt;= &#39;2015-08-18T00:06:00Z&#39; AND time &lt; &#39;2015-08-18T00:18:00Z&#39; GROUP BY time(12m)name: h2o_feettime                   count----                   -----2015-08-18T00:00:00Z   1        &lt;----- 时间戳超出where条件中的起始时间2015-08-18T00:12:00Z   1</code></pre><table><thead><tr><th>预设区间</th><th>where time_range</th><th>数据</th><th>返回时间戳</th></tr></thead><tbody><tr><td>time&gt;=2015-08-18T00:00:00Z and time&lt;2015-08-18T00:12:00Z</td><td>time&gt;=2015-08-18T00:06:00Z and time&lt;2015-08-18T00:12:00Z</td><td>8.005</td><td>2015-08-18T00:00:00Z</td></tr><tr><td>time&gt;=2015-08-18T00:12:00Z and time&lt;2015-08-18T00:24:00Z</td><td>time&gt;=2015-08-18T00:12:00Z and time&lt;2015-08-18T00:18:00Z</td><td>7.887</td><td>2015-08-18T00:12:00Z</td></tr></tbody></table><p>数据需要同时在预设区间和time_range在能满足查询条件，8.12这条数据在预设区间中，但是不在time_range中，所以不满足条件，只有8.005这条数据满足</p><p>如果要避免这种异常情况，需要group by time()的高级用法</p><h2 id="高级用法"><a href="#高级用法" class="headerlink" title="高级用法"></a>高级用法</h2><p>使用姿势</p><pre><code>SELECT &lt;function&gt;(&lt;field_key&gt;) FROM_clause WHERE &lt;time_range&gt; GROUP BY time(&lt;time_interval&gt;,&lt;offset_interval&gt;),[tag_key] [fill(&lt;fill_option&gt;)]</code></pre><p>与基本用法的唯一区别在于多了一个offset_interval的参数，这个参数表示在设置预设区间时需要偏移的时间，可以为正数或负数</p><p>若time_range为[2019-03-08T16:00:00Z, 2019-03-08T16:30:00Z)</p><p>###group by time(10m)</p><table><thead><tr><th>预设区间</th><th>where time_range</th><th>返回时间戳</th></tr></thead><tbody><tr><td>time&gt;=2019-03-08T16:00:00Z and time&lt;2019-03-08T16:10:00Z</td><td>time&gt;=2019-03-08T16:00:00Z and time&lt;2019-03-08T16:10:00Z</td><td>2019-03-08T16:00:00Z</td></tr><tr><td>time&gt;=2019-03-08T16:10:00Z and time&lt;2019-03-08T16:20:00Z</td><td>与预设区间相同</td><td>2019-03-08T16:10:00Z</td></tr><tr><td>time&gt;=2019-03-08T16:20:00Z and time&lt;2019-03-08T16:30:00Z</td><td>与预设区间相同</td><td>2019-03-08T16:20:00Z</td></tr></tbody></table><p>###group by time(10m,-5m)<br>|预设区间|where time_range|返回时间戳<br>|—|—|—|<br>|time&gt;=2019-03-08T15:55:00Z and time&lt;2019-03-08T16:05:00Z|time&gt;=2019-03-08T16:00:00Z and time&lt;2019-03-08T16:10:00Z|2019-03-08T15:55:00Z<br>|time&gt;=2019-03-08T16:05:00Z and time&lt;2019-03-08T16:15:00Z|time&gt;=2019-03-08T16:10:00Z and time&lt;2019-03-08T16:20:00Z|2019-03-08T16:05:00Z<br>|time&gt;=2019-03-08T16:15:00Z and time&lt;2019-03-08T16:25:00Z|time&gt;=2019-03-08T16:20:00Z and time&lt;2019-03-08T16:30:00Z|2019-03-08T16:15:00Z<br>|time&gt;=2019-03-08T16:25:00Z and time&lt;2019-03-08T16:35:00Z||2019-03-08T16:25:00Z</p><h2 id="group-by-time-1d"><a href="#group-by-time-1d" class="headerlink" title="group by time(1d)"></a>group by time(1d)</h2><p>InfluxDB默认是使用UTC时区，所以在进行计算group by time(1d)，对于CST时区，数据会偏移8个小时，所以在聚合1d数据时，需要使用time(1d, -8h)</p>]]></content>
      
      
      <categories>
          
          <category> 监控 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> InfluxDB </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>InfluxDB配置详解</title>
      <link href="/2019/02/24/influxdb-pei-zhi-xiang-jie/"/>
      <url>/2019/02/24/influxdb-pei-zhi-xiang-jie/</url>
      
        <content type="html"><![CDATA[<h2 id="配置文件位置"><a href="#配置文件位置" class="headerlink" title="配置文件位置"></a>配置文件位置</h2><pre><code>Linux：/etc/influxdb/influxdb.confmaxOS：/usr/local/etc/influxdb.conf</code></pre><p>使用配置文件</p><pre><code>influxd -config /etc/influxdb/influxdb.conf</code></pre><p>可以使用环境变量INFLUXDB_CONFIG_PATH来指定配置文件位置</p><pre><code>echo $INFLUXDB_CONFIG_PATH/etc/influxdb/influxdb.confinfluxd</code></pre><h2 id="环境变量配置"><a href="#环境变量配置" class="headerlink" title="环境变量配置"></a>环境变量配置</h2><p>InfluxDB的配置可以放在环境变量中，InfluxDB相关的环境变量都已INFLUXDB_作为前缀</p><pre><code>INFLUXDB_*</code></pre><h2 id="配置优先级"><a href="#配置优先级" class="headerlink" title="配置优先级"></a>配置优先级</h2><p>inflxudb所有的配置项可以在配置文件influxdb.conf中配置，也可以通过环境变量来配置。环境变量的配置优先级高于配置文件的配置。如果有配置环境变量，环境变量的配置将覆盖配置文件的配置</p><pre><code>环境变量 &gt;     配置文件 &gt; InfluxDB内置配置</code></pre><h2 id="全局配置"><a href="#全局配置" class="headerlink" title="全局配置"></a>全局配置</h2><table><thead><tr><th>配置名称</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td>reporting-disabled</td><td>false</td><td>是否向每隔24小时向influxdb汇报信息，包括influxdb版本，database，measurement和series的数量等信息</td></tr><tr><td>bind-address</td><td>127.0.0.1:8088</td><td>RPC服务的地址</td></tr></tbody></table><h2 id="元数据配置-meta"><a href="#元数据配置-meta" class="headerlink" title="元数据配置[meta]"></a>元数据配置[meta]</h2><p>用来控制influxdb的元数据信息，包括database，rp策略，CQ等信息</p><table><thead><tr><th>配置名称</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td>dir</td><td>/usr/local/var/influxdb/meta</td><td>存储元数据信息的路径</td></tr><tr><td>retention-autocreate</td><td>true</td><td>当数据库创建时是否自动创建默认的retention policy</td></tr><tr><td>logging-enabled</td><td>true</td><td>是否允许打印元数据相关的日志</td></tr></tbody></table><h2 id="数据配置-data"><a href="#数据配置-data" class="headerlink" title="数据配置[data]"></a>数据配置[data]</h2><table><thead><tr><th>配置名称</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td>dir</td><td>/usr/local/var/influxdb/data</td><td>TSM文件存储的路径</td></tr><tr><td>wal-dir</td><td>/usr/local/var/influxdb/wal</td><td>WAL文件存储的路径</td></tr><tr><td>trace-logging-enabled</td><td>false</td><td>输出TSM Engine的日志</td></tr><tr><td>query-log-enabled</td><td>true</td><td>在执行查询语句之前，将查询语句输出到日志中</td></tr><tr><td>cache-max-memory-size</td><td>1g</td><td>shard缓存的最大值，如果超过最大值，shard将不再写入数据。若不带单位，则默认为字节</td></tr><tr><td>cache-snapshot-memory-size</td><td>25m</td><td>缓存快照的大小，超过数值，engine会将数据写入到TSM文件中</td></tr></tbody></table><p>cache-snapshot-write-cold-duration|10m|当shard没有写入或删除数据，engine将cache的数据写入到TSM文件中的间隔<br>|compact-full-write-cold-duration|4h|当shard没有写入或删除数据时，engine压缩shard中所有TSM文件的间隔<br>|max-series-per-database|1000000|每个database允许的最大series的最大值，当database的series的数据量超过数值，将拒绝写入，并返回{“error”:”max series per database exceeded: <series>“}。设置为0表示对series的数量没有限制<br>|max-values-per-tag|100000|每个tag value所允许的最大数量。当tag的数量超过配置，influxdb会返回partial write 错误。对应已有的tag value写入不会失败，但是对于新建的tag value，写入会失败</series></p><h2 id="查询配置-coordinator"><a href="#查询配置-coordinator" class="headerlink" title="查询配置[coordinator]"></a>查询配置[coordinator]</h2><table><thead><tr><th>配置名称</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td>write-timeout</td><td>10s</td><td>写入超时时间</td></tr><tr><td>max-concurrent-queries</td><td>0</td><td>inflxudb实例允许的最大查询数</td></tr><tr><td>query-timeout</td><td>0s</td><td>查询超时时间，设置为0表示查询没有超时时间</td></tr><tr><td>log-queries-after</td><td>0s</td><td>慢查询时间，当查询时间超过配置，influxdb将把这个查询记录到日志中</td></tr><tr><td>max-select-point</td><td>0</td><td>select语句所能处理的最大point数，设置为0，表示没有限制</td></tr><tr><td>max-select-series</td><td>0</td><td>select语句所能处理的最大series数据，设置为0，表示没有限制</td></tr><tr><td>max-select_buckets</td><td>0</td><td>group by time()的最大数量</td></tr></tbody></table><h2 id="retention-policy配置-retention"><a href="#retention-policy配置-retention" class="headerlink" title="retention policy配置[retention]"></a>retention policy配置[retention]</h2><table><thead><tr><th>配置名称</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td>enabled</td><td>true</td><td>是否启用retention policy</td></tr><tr><td>check-interval</td><td>30ms0s</td><td>check retention policy的间隔</td></tr></tbody></table><h2 id="监控配置-monitor"><a href="#监控配置-monitor" class="headerlink" title="监控配置[monitor]"></a>监控配置[monitor]</h2><table><thead><tr><th>配置名称</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td>store-enabled</td><td>true</td><td>是否记录监控信息</td></tr><tr><td>store-database</td><td>_interval</td><td>监控数据存储的数据库</td></tr><tr><td>store-interval</td><td>10s</td><td>记录监控信息的间隔</td></tr></tbody></table><h2 id="http配置-http"><a href="#http配置-http" class="headerlink" title="http配置[http]"></a>http配置[http]</h2><table><thead><tr><th>配置名称</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td>enabled</td><td>true</td><td>是否启用http</td></tr><tr><td>bind-address</td><td>8086</td><td>Http端口</td></tr><tr><td>auth-enabled</td><td>false</td><td>是否开启验证</td></tr><tr><td>max-body-size</td><td>25000000</td><td>request body的最大值，如果超过配置，将返回413</td></tr></tbody></table><h2 id="CQ配置-continuous-queries"><a href="#CQ配置-continuous-queries" class="headerlink" title="CQ配置[continuous_queries]"></a>CQ配置[continuous_queries]</h2><table><thead><tr><th>配置名称</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td>enabled</td><td>true</td><td>是否启用CQ</td></tr><tr><td>query-stats-enabled</td><td>false</td><td>是否将CQ的监控信息记录到默认的监控数据库</td></tr><tr><td>run-interval</td><td>1s</td><td>influxdb检查是否需要执行CQ的间隔</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 监控 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> InfluxDB </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>InfluxDB简介</title>
      <link href="/2019/02/16/influxdb-jian-jie/"/>
      <url>/2019/02/16/influxdb-jian-jie/</url>
      
        <content type="html"><![CDATA[<h2 id="InfluxDB简介"><a href="#InfluxDB简介" class="headerlink" title="InfluxDB简介"></a>InfluxDB简介</h2><p>InfluxDB是一个时序型数据库，用于高性能的查询与存储时序型数据。目前，InfluxDB被广泛的用于监控系统中。InfluxDB与Grafana结合，可以为用户带来清晰明了的监控面板。</p><h2 id="InfluxDB安装"><a href="#InfluxDB安装" class="headerlink" title="InfluxDB安装"></a>InfluxDB安装</h2><h3 id="macOS"><a href="#macOS" class="headerlink" title="macOS"></a>macOS</h3><pre><code>brew updatebrew install influxdbinfluxd -config /usr/local/etc/influxdb.conf   //启动influxdb</code></pre><h3 id="Ubuntu"><a href="#Ubuntu" class="headerlink" title="Ubuntu"></a>Ubuntu</h3><pre><code>sudo apt-get update &amp;&amp; sudo apt-get install influxdbsudo service influxdb start</code></pre><h2 id="InfluxDB相关概念"><a href="#InfluxDB相关概念" class="headerlink" title="InfluxDB相关概念"></a>InfluxDB相关概念</h2><h3 id="database"><a href="#database" class="headerlink" title="database"></a>database</h3><p>数据库，包含用户，数据保留策略以及时序型数据。类似关系型数据库中数据库</p><h3 id="measurement"><a href="#measurement" class="headerlink" title="measurement"></a>measurement</h3><p>具有相同tag以及filed的数据集合</p><h3 id="tag"><a href="#tag" class="headerlink" title="tag"></a>tag</h3><p>influxdb使用键值对key-value的形式来保存数据，tag是具有索引的数据</p><h3 id="filed"><a href="#filed" class="headerlink" title="filed"></a>filed</h3><p>influxdb中用来存储具体数值，也是key-value的形式，与tag相比，filed没有索引，因此用filed来过滤查询数据性能会很低</p><h3 id="point"><a href="#point" class="headerlink" title="point"></a>point</h3><p>tag + filed + timestamp = point，类似于关系型数据库中的一行数据(row)</p><h3 id="continuous-query-CQ"><a href="#continuous-query-CQ" class="headerlink" title="continuous query(CQ)"></a>continuous query(CQ)</h3><p>InfluxDB自动并且周期性执行的SQL语句，主要用来自动聚合数据，提供查询性能</p><h3 id="retention-policy-RP"><a href="#retention-policy-RP" class="headerlink" title="retention policy(RP)"></a>retention policy(RP)</h3><p>保留数据策略，每一个RP都会设置一个数据保留期限(duration)，对于超过期限的数据，InfluxDB会自动删除。例如RP设置的期限为7天，则7天之前的数据都会被删除</p><h3 id="series"><a href="#series" class="headerlink" title="series"></a>series</h3><p>在同一个measurement，具有相同的retention policy以及相同tag的数据集合</p><h3 id="shard"><a href="#shard" class="headerlink" title="shard"></a>shard</h3><p>分片包含了实际加密和压缩的数据，一个分片对应了磁盘上的一个TSM文件</p><h2 id="InfluxDB与关系型数据库的对比"><a href="#InfluxDB与关系型数据库的对比" class="headerlink" title="InfluxDB与关系型数据库的对比"></a>InfluxDB与关系型数据库的对比</h2><h3 id="相关概念对比"><a href="#相关概念对比" class="headerlink" title="相关概念对比"></a>相关概念对比</h3><table><thead><tr><th>InfluxDB</th><th>关系型数据库</th></tr></thead><tbody><tr><td>database</td><td>database</td></tr><tr><td>measurement</td><td>table</td></tr><tr><td>tag</td><td>primary-key</td></tr><tr><td>filed</td><td>column</td></tr><tr><td>point</td><td>row</td></tr></tbody></table><p>下面一张表，可以对应到InfluxDB的measurement中<br><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1g08cg9a683j30su076q44.jpg" alt=""></p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1g08chjy7isj30xk08st9w.jpg" alt=""></p><h2 id="InfluxDB-Quick-start"><a href="#InfluxDB-Quick-start" class="headerlink" title="InfluxDB Quick start"></a>InfluxDB Quick start</h2><pre><code>//1. 启动influxd</code></pre><p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1g08co9olscj327c0icaff.jpg" alt=""></p><pre><code>//2. 进入命令行influx -precision rfc3339</code></pre><p>-precision 用来指定时间戳的显示格式<br><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1g08cpc9a2fj30x006yjsu.jpg" alt=""></p><pre><code>//3. 查看databaseshow databases;</code></pre><p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1g08crkttvjj310e09sjs2.jpg" alt=""></p><pre><code>//4. 使用databaseuse media_quality//5. 查看measurementshow measurements</code></pre><p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1g08cthchcvj30l609qmy4.jpg" alt=""></p><pre><code>//6. 查询数据select * from [measurement] where time &gt; now() - 5m limit 10</code></pre><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://docs.influxdata.com/influxdb/v1.7/about_the_project/" target="_blank" rel="noopener">InfluDB官网</a>                </li></ul>]]></content>
      
      
      <categories>
          
          <category> 监控 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> influxDB </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>logback配置</title>
      <link href="/2019/02/01/logback-pei-zhi/"/>
      <url>/2019/02/01/logback-pei-zhi/</url>
      
        <content type="html"><![CDATA[<h2 id="logback配置文件加载顺序"><a href="#logback配置文件加载顺序" class="headerlink" title="logback配置文件加载顺序"></a>logback配置文件加载顺序</h2><ol><li>在 classpath 中寻找 logback-test.xml文件</li><li>如果找不到 logback-test.xml，则在 classpath 中寻找 logback.groovy 文件</li><li>如果找不到 logback.groovy，则在 classpath 中寻找 logback.xml文件</li><li>如果上述的文件都找不到，则 logback 会使用 JDK 的 SPI 机制查找 META-INF/services/ch.qos.logback.classic.spi.Configurator 中的 logback 配置实现类，这个实现类必须实现 Configuration 接口，使用它的实现来进行配置</li><li>如果上述操作都不成功，logback 就会使用它自带的 BasicConfigurator 来配置，并将日志输出到 console<h2 id="logback配置结构"><a href="#logback配置结构" class="headerlink" title="logback配置结构"></a>logback配置结构</h2> configuration<pre><code> - appender - logger - root </code></pre></li></ol><p>下面详细说明各个标签的详细配置</p><h2 id="configuration"><a href="#configuration" class="headerlink" title="configuration"></a>configuration</h2><pre><code>&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt;      &lt;property name=&quot;glmapper-name&quot; value=&quot;glmapper-demo&quot; /&gt;     &lt;contextName&gt;${glmapper-name}&lt;/contextName&gt;     &lt;appender&gt;        //xxxx    &lt;/appender&gt;       &lt;logger&gt;        //xxxx    &lt;/logger&gt;    &lt;root&gt;                    //xxxx    &lt;/root&gt;  &lt;/configuration&gt;   </code></pre><table><thead><tr><th>属性名称</th><th>属性说明</th></tr></thead><tbody><tr><td>scan</td><td>为true时，配置文件变化后会自动重新加载，默认设置为true</td></tr><tr><td>scanPeriod</td><td>扫描配置文件的时间间隔，如果没有给出时间单位，默认为ms。当scan为true，此属性生效，默认值为1m</td></tr><tr><td>debug</td><td>为true时，打印logback内部的日志，默认为false</td></tr></tbody></table><h2 id="contextName"><a href="#contextName" class="headerlink" title="contextName"></a>contextName</h2><pre><code>&lt;contextName&gt;${glmapper-name}&lt;/contextName&gt; </code></pre><p>默认的contextName为default，可以通过设置contextName来区分不同应用程序的日志</p><h2 id="property"><a href="#property" class="headerlink" title="property"></a>property</h2><pre><code>&lt;property name=&quot;glmapper-name&quot; value=&quot;glmapper-demo&quot; /&gt;</code></pre><p>property标签用来定义变量，具有如下两个属性</p><table><thead><tr><th>属性名称</th><th>属性说明</th></tr></thead><tbody><tr><td>name</td><td>变量名称</td></tr><tr><td>value</td><td>变量值</td></tr></tbody></table><p>定义变量之后，可以通过表示式来使用变量</p><pre><code>${name}</code></pre><h2 id="logger"><a href="#logger" class="headerlink" title="logger"></a>logger</h2><p>用来设置某一个包或者具体的某一个类的日志打印级别以及指定appender。</p><pre><code>&lt;logger name=&quot;com.meitu.alarm&quot; level=&quot;debug&quot; additivity=&quot;false&quot;&gt;</code></pre><table><thead><tr><th>属性名称</th><th>属性说明</th></tr></thead><tbody><tr><td>name</td><td>logger名称，必填，与LoggerFactory.getLogger(“name”)中的name对应</td></tr><tr><td>level</td><td>level的取值可以为TRACE, DEBUG, INFO, WARN, ERROR, ALL, OFF</td></tr><tr><td>additivity</td><td>是否向父类继续上报日志，如果设置为true，则日志会向上传递，父类也会打印该日志</td></tr></tbody></table><p><logger>标签只有一个子标签<appender-ref>，用来绑定对应的appender</appender-ref></logger></p><h2 id="appender"><a href="#appender" class="headerlink" title="appender"></a>appender</h2><p>appender用来标识日志输出的格式以及日志输出地点，可以是控制台，文件</p><pre><code>&lt;appender name=&quot;console&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;&lt;/appender&gt;</code></pre><table><thead><tr><th>属性名称</th><th>属性说明</th></tr></thead><tbody><tr><td>name</td><td>appender的名称</td></tr><tr><td>class</td><td>appender的实现类名称</td></tr></tbody></table><appender> 标签下可以包含至多一个 <layout>，0个或多个 <encoder>，0个或多个 <filter><br><br>以下是几种常见的appender<br>### Console<br>将日志输出到控制台中<br><br>    <appender name="console" class="ch.qos.logback.core.ConsoleAppender"><br>        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"><br>            <pattern>%d{YY-MM-dd HH:mm:ss.SSS} %-5level %logger{36} - %msg%n</pattern><br>        </encoder><br>    </appender><h3 id="RollingFileAppender-by-time"><a href="#RollingFileAppender-by-time" class="headerlink" title="RollingFileAppender(by time)"></a>RollingFileAppender(by time)</h3><p>将日志输出到文件中，并根据time分割日志</p><pre><code>&lt;appender name=&quot;debug&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;        &lt;file&gt;${LOG_PATH}/debug.log&lt;/file&gt;        &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;            &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss} %logger %msg%n&lt;/pattern&gt;        &lt;/encoder&gt;        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;            &lt;fileNamePattern&gt;${LOG_PATH}/debug.%d{yyyyMMdd-HH}.log&lt;/fileNamePattern&gt;            &lt;maxHistory&gt;30&lt;/maxHistory&gt;        &lt;/rollingPolicy&gt;        &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt;            &lt;level&gt;DEBUG&lt;/level&gt;            &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt;            &lt;onMismatch&gt;DENY&lt;/onMismatch&gt;        &lt;/filter&gt;    &lt;/appender&gt;</code></pre><h3 id="JSON-Appender"><a href="#JSON-Appender" class="headerlink" title="JSON Appender"></a>JSON Appender</h3><p>按照JSON格式输出日志</p><pre><code>&lt;appender name=&quot;console&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;    &lt;encoder class=&quot;net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder&quot;&gt;        &lt;providers&gt;            &lt;pattern&gt;                &lt;pattern&gt;                    {                    &quot;timestamp&quot;: &quot;%date{\&quot;yyyy-MM-dd HH:mm:ss\&quot;}&quot;,                    &quot;log_level&quot;: &quot;%level&quot;,                    &quot;class_name&quot;: &quot;%class&quot;,                    &quot;message&quot;: &quot;%message&quot;,                    &quot;stack_trace&quot;: &quot;%exception{5}&quot;                    }                &lt;/pattern&gt;            &lt;/pattern&gt;        &lt;/providers&gt;        &lt;!--&lt;charset&gt;UTF-8&lt;/charset&gt;--&gt;    &lt;/encoder&gt;&lt;/appender&gt;</code></pre><h2 id="多环境日志输出"><a href="#多环境日志输出" class="headerlink" title="多环境日志输出"></a>多环境日志输出</h2><p>根据不同的环境(test,dev,pre,release)来定义输出日志</p><pre><code>&lt;springProfile name=&quot;test,dev&quot;&gt; //多个环境用逗号分隔    &lt;logger name=&quot;com.meitu.alarm&quot; level=&quot;debug&quot; additivity=&quot;false&quot;&gt;        &lt;appender-ref ref=&quot;debug&quot;/&gt;        &lt;appender-ref ref=&quot;info&quot;/&gt;        &lt;appender-ref ref=&quot;warn&quot;/&gt;        &lt;appender-ref ref=&quot;error&quot;/&gt;    &lt;/logger&gt;&lt;/springProfile&gt;&lt;springProfile name=&quot;release&quot;&gt;    &lt;logger name=&quot;com.meitu.alarm&quot; level=&quot;info&quot; additivity=&quot;false&quot;&gt;        &lt;appender-ref ref=&quot;console&quot;/&gt;    &lt;/logger&gt;&lt;/springProfile&gt;</code></pre><h2 id="关闭某个包或者某个类的日志"><a href="#关闭某个包或者某个类的日志" class="headerlink" title="关闭某个包或者某个类的日志"></a>关闭某个包或者某个类的日志</h2><pre><code>&lt;logger name=&quot;packageName&quot; level=&quot;OFF&quot; /&gt;</code></pre><h2 id="自定义字段"><a href="#自定义字段" class="headerlink" title="自定义字段"></a>自定义字段</h2><p>若日志最终存储到ES中，可以在JSON中添加自定义的字段，方便问题的排查</p><h3 id="StructuredArguments提供的结构化字段"><a href="#StructuredArguments提供的结构化字段" class="headerlink" title="StructuredArguments提供的结构化字段"></a>StructuredArguments提供的结构化字段</h3><pre><code>import static net.logstash.logback.argument.StructuredArguments.*//output: log message valuelogger.info(&quot;log message {}&quot;, value(&quot;name&quot;, &quot;value&quot;));//output: log message name=valuelogger.info(&quot;log message {}&quot;, keyValue(&quot;name&quot;, &quot;value&quot;));//json output: {&quot;message&quot;:&quot;log message&quot;,&quot;name&quot;:&quot;value&quot;}logger.info(&quot;log message&quot;, keyValue(&quot;name&quot;, &quot;value&quot;));</code></pre><p>如果想在输出的JSON中，加上自定义字段，需要配置arguments参数</p><pre><code>&lt;encoder class=&quot;net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder&quot;&gt;        &lt;providers&gt;            &lt;pattern&gt;                &lt;pattern&gt;                    {                    &quot;timestamp&quot;: &quot;%date{\&quot;yyyy-MM-dd HH:mm:ss\&quot;}&quot;,                    &quot;log_level&quot;: &quot;%level&quot;,                    &quot;class_name&quot;: &quot;%class&quot;,                    &quot;thread&quot;: &quot;%thread&quot;,                    &quot;message&quot;: &quot;%message&quot;,                    &quot;stack_trace&quot;: &quot;%exception{5}&quot;                    }                &lt;/pattern&gt;            &lt;/pattern&gt;            &lt;arguments/&gt;        &lt;/providers&gt;    &lt;/encoder&gt;</code></pre><h3 id="Markers提供的标记"><a href="#Markers提供的标记" class="headerlink" title="Markers提供的标记"></a>Markers提供的标记</h3><pre><code>import static net.logstash.logback.marker.Markers.* /* * Add &quot;name&quot;:&quot;value&quot; to the JSON output. */logger.info(append(&quot;name&quot;, &quot;value&quot;), &quot;log message&quot;);/* * Add &quot;name1&quot;:&quot;value1&quot;,&quot;name2&quot;:&quot;value2&quot; to the JSON output by using multiple markers. */logger.info(append(&quot;name1&quot;, &quot;value1&quot;).and(append(&quot;name2&quot;, &quot;value2&quot;)), &quot;log message&quot;);</code></pre><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://www.jianshu.com/p/a26da0c55255" target="_blank" rel="noopener">logstash中logback的json编码器插件</a></li></ul></filter></encoder></layout></appender>]]></content>
      
      
      <categories>
          
          <category> Spring Boot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Logback </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Prometheus2.0实战</title>
      <link href="/2019/01/26/prometheus2-0-shi-zhan/"/>
      <url>/2019/01/26/prometheus2-0-shi-zhan/</url>
      
        <content type="html"><![CDATA[<h2 id="Prometheus-1-x-VS-Prometheus-2-x"><a href="#Prometheus-1-x-VS-Prometheus-2-x" class="headerlink" title="Prometheus 1.x VS Prometheus 2.x"></a>Prometheus 1.x VS Prometheus 2.x</h2><p>1.0版本与2.0版本最大的改变之一就是存储引擎，1.x版本使用的是LevelDB，2.x使用的是TSDB，性能上有较大的提升，以下是官方对比数据</p><ul><li>与 Prometheus 1.8 相比，CPU使用率降低了 20％ - 40％</li><li>与 Prometheus 1.8 相比，磁盘空间使用率降低了 33％ - 50％</li><li>没有太多查询，平均负载的磁盘 I/O&lt;1％</li></ul><h2 id="Prometheus-存储"><a href="#Prometheus-存储" class="headerlink" title="Prometheus 存储"></a>Prometheus 存储</h2><h3 id="本地存储"><a href="#本地存储" class="headerlink" title="本地存储"></a>本地存储</h3><p>Prometheus将两个小时的数据存储在一个目录底下，目录包含chunk(存储时间序列样本)，meta(存储元数据)，index(存储metric名称以及label)</p><p>数据会先缓存在内存中而不会立刻持久化到磁盘中，因此Prometheus采用write-ahead-log机制，当prometheus server发生异常，重启之后会根据日志重新加载数据。</p><p>通过API删除数据，数据先保存到tombstone文件，而不是立即从磁盘删除</p><pre><code>./data/01BKGTZQ1SYQJTR4PB43C8PD98./data/01BKGTZQ1SYQJTR4PB43C8PD98/meta.json./data/01BKGTZQ1SYQJTR4PB43C8PD98/index./data/01BKGTZQ1SYQJTR4PB43C8PD98/chunks./data/01BKGTZQ1SYQJTR4PB43C8PD98/chunks/000001./data/01BKGTZQ1SYQJTR4PB43C8PD98/tombstones</code></pre><h3 id="远程存储"><a href="#远程存储" class="headerlink" title="远程存储"></a>远程存储</h3><p>prometheus可以与远程系统进行如下交互：</p><ol><li>prometheus可以通过remote_write写入数据</li><li>prometheus可以通过remote_read读取数据</li></ol><p><img src="https://prometheus.io/docs/prometheus/latest/images/remote_integrations.png" alt=""></p><p>目前prometheus是通过HTTP协议传输数据，未来可能会使用gRPC。</p><p>采用远程存储时，prometheus进行查询时，会从远端拉取所需的数据，然后进行相应的处理，因此可靠性不能保证。目前PromQL是不支持分布式查询。</p><p>目前支持prometheus远程存储的数据源如下：</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fzgkyab3ybj30bc0brmye.jpg" alt=""></p><h2 id="Prometheus-Federation"><a href="#Prometheus-Federation" class="headerlink" title="Prometheus Federation"></a>Prometheus Federation</h2><h3 id="Hierarchical-federation"><a href="#Hierarchical-federation" class="headerlink" title="Hierarchical federation"></a>Hierarchical federation</h3><p>这种方式相同job的不同instance分布在不同的prometheus上，高一层级的prometheus server从低层级的prometheus server查询数据。</p><p>这种方式适合于某个job收集metrics过多，单台prometheus无法负荷时，可以利用这种方式对job的instance进行水平扩展，将不同的instance拆分到不同的prometheus中，在由全局的prometheus来收集聚合数据<br><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fzgjb6rttlj30kp08at92.jpg" alt=""></p><h3 id="Cross-service-federation"><a href="#Cross-service-federation" class="headerlink" title="Cross-service federation"></a>Cross-service federation</h3><p>这种方式是以service维度来拆分prometheus，在由全局的prometheus来收集聚合数据<br><img src="https://ws4.sinaimg.cn/large/006tNc79gy1fzgjg57ocrj30gx07q3yo.jpg" alt=""></p><h3 id="Federation的优缺点"><a href="#Federation的优缺点" class="headerlink" title="Federation的优缺点"></a>Federation的优缺点</h3><p>优点：数据集中式管理，告警，不需要为每个prometheus实例管理数据</p><p>缺点：数据集中化，网络可能会延迟。Federation没有解决数据单点问题</p><h2 id="Recording-rules"><a href="#Recording-rules" class="headerlink" title="Recording rules"></a>Recording rules</h2><p>recording rule类似于Influxdb的CQ，可以在后台处理配置的表达式，并将表达式的结果存储起来。recording rule主要目的是为了提前计算一些复杂运算结果，提供查询效率。CQ的主要目的在于聚合数据，从而通过不同的RP策略来保存数据</p><pre><code>groups:  - name: example    rules:    - record: job:http_inprogress_requests:sum      expr: sum(http_inprogress_requests) by (job)</code></pre><p>其中record表示指标的名称，expr则是指标的表达式</p><h2 id="prometheus高可用部署"><a href="#prometheus高可用部署" class="headerlink" title="prometheus高可用部署"></a>prometheus高可用部署</h2><h3 id="基于HA"><a href="#基于HA" class="headerlink" title="基于HA"></a>基于HA</h3><p>部署多台prometheus server(一主一从)，并采集相同export的指标。</p><p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1fziofcdgszj30el06c74a.jpg" alt=""></p><p>基于HA模式只能确保prometheus服务可用性问题，但是不解决prometheus server之间数据一致性问题已经持久化问题(数据丢失无法恢复)。</p><h3 id="基于HA-远程存储"><a href="#基于HA-远程存储" class="headerlink" title="基于HA + 远程存储"></a>基于HA + 远程存储</h3><p>在HA的基础上通过添加remote storage，将监控数据存储到第三方存储服务上。既解决了服务可用性问题，同时也确保了数据的持久化</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fzirxf5gtnj30e207ndfx.jpg" alt=""></p><h3 id="基于HA-远程存储-联邦集成"><a href="#基于HA-远程存储-联邦集成" class="headerlink" title="基于HA + 远程存储 + 联邦集成"></a>基于HA + 远程存储 + 联邦集成</h3><p>当单台prometheus需要处理大量的采集任务时，可以使用prometheusde联邦的方式，将采集任务分割到不同的prometheus实例中。</p><p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1fzisip7noyj30pw09l0t5.jpg" alt=""></p><h3 id="三种方式对比"><a href="#三种方式对比" class="headerlink" title="三种方式对比"></a>三种方式对比</h3><table><thead><tr><th>部署方式</th><th>使用场景</th></tr></thead><tbody><tr><td>基于HA</td><td>监控规模不大，prometheus server不会经常发生迁移，并且数据保存周期较短</td></tr><tr><td>基于HA + 远程存储</td><td>监控规模不大，但要求监控数据持久化</td></tr><tr><td>基于HA + 远程存储 + 联邦集成</td><td>单数据中心，并且采集指标量很大，此时prometheus的性能瓶颈主要在于大量的采集任务</td></tr></tbody></table><h3 id="Thanos"><a href="#Thanos" class="headerlink" title="Thanos"></a>Thanos</h3><p><a href="https://github.com/improbable-eng/thanos" target="_blank" rel="noopener">thanos</a>是开源的大规模Prometheus集群解决方案，它的设计目标如下</p><ol><li>全局的查询视图</li><li>不受限的数据存储</li><li>高可用性</li></ol><p>thanos的架构如图</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fzk1j4mmlnj317f0u07kq.jpg" alt=""></p><h3 id="M3"><a href="#M3" class="headerlink" title="M3"></a>M3</h3><p><a href="https://github.com/m3db/m3" target="_blank" rel="noopener">M3</a>是Uber开源的基于M3DB的指标平台，它提供了如下的功能</p><ol><li>全局数据查询和存储</li><li>提供数据聚合以及保留(retention)功能</li><li>可作为prometheus的存储后台，提供prometheus的高可用部署</li></ol><p><img src="http://eng.uber.com/wp-content/uploads/2018/08/image4-1.png" alt=""></p><p><img src="http://eng.uber.com/wp-content/uploads/2018/08/image1-1.png" alt=""></p><h2 id="Prometheus实践"><a href="#Prometheus实践" class="headerlink" title="Prometheus实践"></a>Prometheus实践</h2><h3 id="recording-rule"><a href="#recording-rule" class="headerlink" title="recording rule"></a>recording rule</h3><p>生成recording rule</p><pre><code>groups: - name: test   rules:   - record: job:prometheus_http_response_size_bytes_sum:sum     expr: sum(prometheus_http_response_size_bytes_sum) by (job)</code></pre><p>在graph中查看recording rule生成的指标</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fzjyh83xnsj32200f0jt9.jpg" alt=""></p><p>可以看到生成的新指标与表达式得到的指标值一致</p><p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1fzjyjcgsasj31vk0eumyu.jpg" alt="">       </p><h3 id="remote-write-remote-read"><a href="#remote-write-remote-read" class="headerlink" title="remote_write/remote_read"></a>remote_write/remote_read</h3><h4 id="influxdb"><a href="#influxdb" class="headerlink" title="influxdb"></a>influxdb</h4><p>influxdb内部已经实现了读写prometheus数据的协议，只需要在prometheus.yml中配置remote_write和remote_read的url地址即可</p><pre><code>remote_write: - url: &quot;http://127.0.0.1:8086/api/v1/prom/write?db=prometheus_test&quot;remote_read: - url: &quot;http://127.0.0.1:8086/api/v1/prom/read?db=prometheus_test&quot;</code></pre><p>配置prometheus之后，需要在infludb中创建配置中对应的数据库</p><pre><code>create database prometheus_test</code></pre><p>启动prometheus之后，可以在influxdb中看到生成的measurement，每个metric对应一个measurement，而metric中的label对应inflxudb的tag</p><pre><code># Prometheus metricexample_metric{queue=&quot;0:http://example:8086/api/v1/prom/write?db=prometheus&quot;,le=&quot;0.005&quot;} 308# Same metric parsed into InfluxDBmeasurement  example_metrictags  queue = &quot;0:http://example:8086/api/v1/prom/write?db=prometheus&quot;  le = &quot;0.005&quot;  job = &quot;prometheus&quot;  instance = &quot;localhost:9090&quot;  __name__ = &quot;example_metric&quot;fields  value = 308</code></pre><p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1fzjzk2viz9j30sw0le423.jpg" alt=""></p><p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1fzjzkukt4wj317y0bmtac.jpg" alt=""></p><h3 id="federation"><a href="#federation" class="headerlink" title="federation"></a>federation</h3><p>启动三台prometheus server，其中一台作为master，从另外两台拉取数据</p><table><thead><tr><th>name</th><th>role</th><th>port</th></tr></thead><tbody><tr><td>prometheus</td><td>master</td><td>9090</td></tr><tr><td>node1</td><td>collector</td><td>9091</td></tr><tr><td>node2</td><td>collector</td><td>9092</td></tr></tbody></table><p>master配置</p><pre><code>global:  scrape_interval: 15s   evaluation_interval: 15s scrape_configs: - job_name: &#39;prometheus&#39;   honor_labels: true   metrics_path: &#39;/federate&#39;   params:    &#39;match[]&#39;:      - &#39;{job=&quot;node1&quot;}&#39;      - &#39;{job=&quot;node2&quot;}&#39;</code></pre><p>node1配置</p><pre><code>global:  scrape_interval:     15s  evaluation_interval: 15s  external_labels:      server: &#39;node1&#39;scrape_configs:  - job_name: &#39;node1&#39;    static_configs:      - targets: [&#39;localhost:9091&#39;]</code></pre><p>node2配置    </p><pre><code>global:  scrape_interval:     15s  evaluation_interval: 15s  external_labels:      server: &#39;node2&#39;scrape_configs:  - job_name: &#39;node2&#39;    static_configs:      - targets: [&#39;localhost:9092&#39;]</code></pre><p>启动3台prometheus</p><pre><code>#master./prometheus --config.file=prometheus.yml#node1./prometheus --config.file=prometheus-node1-9091.yml --storage.tsdb.path=data-node1 --web.listen-address=0.0.0.0:9091#node2./prometheus --config.file=prometheus-node2-9092.yml --storage.tsdb.path=data-node2 --web.listen-address=0.0.0.0:9092</code></pre><p>可以看到在master可以查询到另外两台node的数据</p><p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fzk187nu4wj326u0l443s.jpg" alt="">                 </p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://www.ctolib.com/docs/sfile/prometheus-book/alert/prometheus-recoding-rules.html" target="_blank" rel="noopener">使用Recoding Rules优化性能</a></li><li><a href="https://www.imuo.com/a/dbe9b42ff8b0c9569db6d250c4ca1261fc228876ef86ada92d45dc3523c20e20" target="_blank" rel="noopener">Prometheus 联邦及高可用详解</a></li><li><a href="https://hk.saowen.com/a/c1c70c681b1df019e2e8bc9291e1e43b489bbaaca5923b5b4fd9bb4f734c7d73" target="_blank" rel="noopener">Prometheus高可用方案策略</a></li><li><a href="http://dockone.io/article/6019" target="_blank" rel="noopener">Thanos：开源的大规模Prometheus集群解决方案</a></li><li><a href="https://docs.mesosphere.com/services/prometheus/0.1.1-2.3.2/configuration/remote-storage/" target="_blank" rel="noopener">Prometheus Remote Storage to InfluxDB</a></li><li><a href="https://docs.influxdata.com/influxdb/v1.7/supported_protocols/prometheus/" target="_blank" rel="noopener">Prometheus remote read and write API support</a></li><li><a href="https://kairen.github.io/2018/06/29/devops/prometheus-federation/" target="_blank" rel="noopener">了解 Prometheus Federation 功能</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 监控 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Prometheus简介</title>
      <link href="/2019/01/16/prometheus-jian-jie/"/>
      <url>/2019/01/16/prometheus-jian-jie/</url>
      
        <content type="html"><![CDATA[<h2 id="Prometheus简介"><a href="#Prometheus简介" class="headerlink" title="Prometheus简介"></a>Prometheus简介</h2><p>Prometheus 是一套开源的系统监控报警框架。作为新一代的监控框架，Prometheus具有如下几个特点</p><ol><li>多维度的数据模型</li><li>灵活和强大的查询语句(PromQL)</li><li>易于管理，prometheus是一个独立的二进制文件，不依赖分布式存储</li><li>采用pull模式利用HTTP采集数据</li><li>有多种的可视化图形界面(目前推荐使用Grafana展示数据)</li></ol><p>prometheus的架构如下图所示</p><p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fzbvfyy503j31ae0r60yu.jpg" alt=""></p><p>prometheus的主要工作流程如下</p><ol><li>prometheus serve定期从job pull metric，或者接收来自Pushgateway的metrics</li><li>prometheus将获取的metric存储在本地，并根据配置的alert rule向Alertmanage发送告警信息</li><li>Alertmanage根据配置，对接收的告警信息进行处理，发出相应的告警</li><li>可视化采集的数据</li></ol><h2 id="Prometheus相关概念"><a href="#Prometheus相关概念" class="headerlink" title="Prometheus相关概念"></a>Prometheus相关概念</h2><h3 id="instance"><a href="#instance" class="headerlink" title="instance"></a>instance</h3><p>一个单独采集的目标(target)，一般对应一个进程</p><h3 id="job"><a href="#job" class="headerlink" title="job"></a>job</h3><p>一组相同类型的instance</p><pre><code>web-api部署在多台实例上，prometheus会从每个实例上去采集数据job: web-api    instance x.x.x.x:port1    instance x.x.x.x:port2</code></pre><h3 id="sample"><a href="#sample" class="headerlink" title="sample"></a>sample</h3><p>实际的时间序列，每一个时间序列包含一个float64的值以及一个毫秒级的时间戳</p><h3 id="metric"><a href="#metric" class="headerlink" title="metric"></a>metric</h3><p>prometheus有4中metric，可以将metric理解为数据模型，metric的格式如下</p><pre><code>&lt;metric name&gt;{&lt;label name&gt;=&lt;label value&gt;,...}</code></pre><h3 id="label"><a href="#label" class="headerlink" title="label"></a>label</h3><p>标签，用来表示采集数据的维度,例如有个指标为http_request_total表示所有http请求的总数，则http_request_total{method=”POST”}则表示请求方式为POST的请求总数，其中method就是label</p><h2 id="Prometheus安装配置"><a href="#Prometheus安装配置" class="headerlink" title="Prometheus安装配置"></a>Prometheus安装配置</h2><p>下载<a href="https://prometheus.io/download" target="_blank" rel="noopener">prometheus</a>，解压安装包</p><pre><code>tar -zxvf prometheus-2.6.0.darwin-amd64.tar.gzcd prometheus-2.6.0.darwin-amd64</code></pre><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><p>prometheus安装包下有一个二进制文件，叫prometheus，之前运行该文件，即可启动prometheus server</p><pre><code>./prometheus --help</code></pre><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>prometheus的配置文件为prometheus.yml，内容如下</p><pre><code>global:  scrape_interval:     15s # prometheus server 从instance拉取metric的间隔  evaluation_interval: 15s # prometheus server检测alert rule的间隔  scrape_timeout: 10s # proemtheus server抓取数据的超时时间# Alertmanager 配置alerting:  alertmanagers:  - static_configs:    - targets:      # - alertmanager:9093# 告警规则rule_files:  # - &quot;first_rules.yml&quot;  # - &quot;second_rules.yml&quot;# 抓取对象配置scrape_configs:  # 全局唯一的名称，用来标识一个job  - job_name: &#39;prometheus&#39;    # 该job对应的所有instance    static_configs:    - targets: [&#39;localhost:9090&#39;]</code></pre><h2 id="Metric"><a href="#Metric" class="headerlink" title="Metric"></a>Metric</h2><h3 id="Counter"><a href="#Counter" class="headerlink" title="Counter"></a>Counter</h3><p>对数据进行累加，数据只会递增，例如http请求数，错误个数</p><h3 id="Guage"><a href="#Guage" class="headerlink" title="Guage"></a>Guage</h3><p>可以对数据进行加减，例如温度，线程数量</p><h3 id="Histogram"><a href="#Histogram" class="headerlink" title="Histogram"></a>Histogram</h3><p>可以理解为柱状图，依据事先设置的阈值，对采集数据进行分类统计，适合统计的指标如response time，request size等</p><p>Histogram具有3个指标值</p><pre><code>&lt;metric_name&gt;_bucket 对应分桶的条数&lt;metric_name&gt;_sum 采集数据求和的值&lt;metric_name&gt;_count 采集条数</code></pre><p>下面以实例来说明上述三个指标，例如对response time进行统计，总共采集了3条数据，分别是</p><pre><code>100ms,200ms,120ms</code></pre><p>则以下三个指标分别表示</p><pre><code>response_time_bucket{le=120}=2, response time小于等于120ms的数据有两条response_time_sum=(100+200+120)=420 对所有的response time进行求和response_time_count=3 总共采集了3条数据</code></pre><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>与Histogram类似，最大的区别在于Summary可以精确的统计百分位的值，例如90%的响应时间低于200ms</p><p>summary也有三个指标</p><pre><code>&lt;metric_name&gt;{quantile=&quot;&lt;q&gt;&quot;}  0=&lt;q&lt;=1 百分位位于q的值&lt;metric_name&gt;_sum 采集数据求和的值&lt;metric_name&gt;_count 采集条数</code></pre><h3 id="Histogram-VS-Summary"><a href="#Histogram-VS-Summary" class="headerlink" title="Histogram VS Summary"></a>Histogram VS Summary</h3><ul><li>都包含&lt;basename>_sum，&lt;basename>_count</li><li>Histogram 需要通过 \<basename>_bucket 计算 quantile, 而 Summary 直接存储了 quantile 的值。</basename></li></ul><h2 id="Prometheus实例演示"><a href="#Prometheus实例演示" class="headerlink" title="Prometheus实例演示"></a>Prometheus实例演示</h2><h3 id="启动prometheus"><a href="#启动prometheus" class="headerlink" title="启动prometheus"></a>启动prometheus</h3><pre><code>./prometheus --config.file=&quot;prometheus.yml&quot;</code></pre><p>启动成功之后可以在localhost:9090上查看对应的metric<br><img src="https://ws4.sinaimg.cn/large/006tNc79gy1fzbx49z7fqj327w0ra78w.jpg" alt=""></p><h3 id="查看对应的指标"><a href="#查看对应的指标" class="headerlink" title="查看对应的指标"></a>查看对应的指标</h3><p>在输入框中输入指标名称，即可看到对应指标的值</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fzbx6jtpt3j327i0mu428.jpg" alt=""></p><h3 id="可视化指标"><a href="#可视化指标" class="headerlink" title="可视化指标"></a>可视化指标</h3><p>选择graph标签页，即可将对应的数据可视化，例如查看http请求code为200的QPS</p><pre><code>rate(promhttp_metric_handler_requests_total{code=&quot;200&quot;}[1m])</code></pre><p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fzbxac8hggj31ww0u0jva.jpg" alt=""></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://prometheus.io/docs/introduction/overview/" target="_blank" rel="noopener">https://prometheus.io/docs/introduction/overview/</a></li><li><a href="https://prometheus.io/docs/practices/histograms/" target="_blank" rel="noopener">https://prometheus.io/docs/practices/histograms/</a></li><li><a href="https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/index.html" target="_blank" rel="noopener">https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/index.html</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 监控 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> prometheus </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kafka源码分析——Consumer</title>
      <link href="/2019/01/13/kafka-yuan-ma-fen-xi-consumer/"/>
      <url>/2019/01/13/kafka-yuan-ma-fen-xi-consumer/</url>
      
        <content type="html"><![CDATA[<h2 id="Consumer使用实例"><a href="#Consumer使用实例" class="headerlink" title="Consumer使用实例"></a>Consumer使用实例</h2><h3 id="kafka-console-consumer"><a href="#kafka-console-consumer" class="headerlink" title="kafka-console-consumer"></a>kafka-console-consumer</h3><pre><code>sh kafka-console-consumer.sh ----bootstrap-server localhost:9092 --topic test --from-beginning</code></pre><h3 id="consumer-client"><a href="#consumer-client" class="headerlink" title="consumer client"></a>consumer client</h3><pre><code>Properties props = new Properties();props.put(&quot;bootstrap.servers&quot;,&quot;localhost:9092&quot;);    props.put(&quot;group.id&quot;,&quot;test_group_id&quot;);props.put(&quot;enable.auto.commit&quot;,&quot;true&quot;);props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;);props.put(&quot;key.deserializer&quot;,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);KafkaConsumer&lt;String,String&gt; consumer = new KafkaConsumer&lt;&gt;(props);while(true){    ConsumerRecords&lt;String,String&gt; records = consumer.poll(1000)    for(ConsumerRecord&lt;String, String&gt; record : records){        System.out.printf(&quot;offset=%d,key=%s,value=%s&quot;,record.offset(),record.key(),record.value());    }}</code></pre><p>可以看到consumer的入口在poll方法，下面来看下poll方法的实现</p><h2 id="Consumer-poll模型"><a href="#Consumer-poll模型" class="headerlink" title="Consumer poll模型"></a>Consumer poll模型</h2><pre><code>//timeout是Consumer消费的超时时间，如果设置为0，表示buffer中只要有数据就立刻拉取public ConsumerRecords&lt;K, V&gt; poll(long timeout) {    acquire();    try {        if (timeout &lt; 0)            throw new IllegalArgumentException(&quot;Timeout must not be negative&quot;);        if (this.subscriptions.hasNoSubscriptionOrUserAssignment())            throw new IllegalStateException(&quot;Consumer is not subscribed to any topics or assigned any partitions&quot;);        // poll for new data until the timeout expires        long start = time.milliseconds();        long remaining = timeout;        do {                //从订阅的partition中消费数据，pollonce是其核心实现            Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; records = pollOnce(remaining);            if (!records.isEmpty()) {                // 在返回获取数据之前，需要发起下次的fetch请求，主要是为了避免用户在处理获取数据，而导致fetch请求被阻塞                if (fetcher.sendFetches() &gt; 0 || client.pendingRequestCount() &gt; 0)                    client.pollNoWakeup();                if (this.interceptors == null)                    return new ConsumerRecords&lt;&gt;(records);                else                    return this.interceptors.onConsume(new ConsumerRecords&lt;&gt;(records));            }            long elapsed = time.milliseconds() - start;            remaining = timeout - elapsed;        } while (remaining &gt; 0);        return ConsumerRecords.empty();    } finally {        release();    }}</code></pre><p>Consumer的poll方法主要在做以下几件事：</p><ol><li>检测timeout是否合法以及Consumer是否订阅了相应的topic-partition</li><li>调用pollOnce方法获取数据</li><li>在返回结果前，提前发起下次的fetch请求，避免用户在处理返回数据时，而导致线程被阻塞</li><li>如果在timeout的时间中没有获取到数据，则返回空数据</li></ol><h3 id="pollOnce方法"><a href="#pollOnce方法" class="headerlink" title="pollOnce方法"></a>pollOnce方法</h3><pre><code>private Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; pollOnce(long timeout) {    coordinator.poll(time.milliseconds());    // 确认是否所有的分区的offset是否有效，更新没有生效的partition的offset    if (!subscriptions.hasAllFetchPositions())        updateFetchPositions(this.subscriptions.missingFetchPositions());    // 如果获取到数据，则立马返回    Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; records = fetcher.fetchedRecords();    if (!records.isEmpty())        return records;    // 对于新的fetch请求，立即发起请求    fetcher.sendFetches();    long now = time.milliseconds();    long pollTimeout = Math.min(coordinator.timeToNextPoll(now), timeout);     //调用底层的poll方法，发起请求    client.poll(pollTimeout, now, new PollCondition() {        @Override        public boolean shouldBlock() {            // 对于已完成的fetch请求，则不进行阻塞            return !fetcher.hasCompletedFetches();        }    });    // 如果消费组group需要进行负责均衡rebalance，则直接返回空数据，    if (coordinator.needRejoin())        return Collections.emptyMap();    return fetcher.fetchedRecords();}    </code></pre><p>pollOnce方法，主要有以下几个步骤：</p><ol><li>coordinator.poll()</li><li>updateFetchPositions()</li><li>fetcher.fetchedRecords()</li><li>fetcher.sendFetches()</li><li>client.poll()</li><li>coordinator.needRejoin()</li></ol><p>下面详细分析以上几个步骤</p><h3 id="ConsumerCoordinator-poll"><a href="#ConsumerCoordinator-poll" class="headerlink" title="ConsumerCoordinator.poll()"></a>ConsumerCoordinator.poll()</h3><pre><code>//确保这个group的coordinator是已知的，并且已经Consumer已经加入到这个group中public void poll(long now) {    invokeCompletedOffsetCommitCallbacks();      //若订阅了topic，并且该coordinator是未知的，则初始化coordinator    if (subscriptions.partitionsAutoAssigned() &amp;&amp; coordinatorUnknown()) {        ensureCoordinatorReady();        now = time.milliseconds();    }     //Consumer是否需要重新加入到group中（如果partition发生变化，则需要rejoin）    if (needRejoin()) {        // due to a race condition between the initial metadata fetch and the initial rebalance,        // we need to ensure that the metadata is fresh before joining initially. This ensures        // that we have matched the pattern against the cluster&#39;s topics at least once before joining.        if (subscriptions.hasPatternSubscription())            client.ensureFreshMetadata();          // 确保group是active的        ensureActiveGroup();        now = time.milliseconds();    }     //检测心跳线程是否正常，若不正常，则抛出异常    pollHeartbeat(now);    //开启auto commit时，当定时时间到时则自动提交    maybeAutoCommitOffsetsAsync(now);}</code></pre><h3 id="updateFetchPositions"><a href="#updateFetchPositions" class="headerlink" title="updateFetchPositions()"></a>updateFetchPositions()</h3><pre><code>//如果有committed position，则将fetch position设置为committed position，否则使用配置的重置策略去设置offsetprivate void updateFetchPositions(Set&lt;TopicPartition&gt; partitions) {    //先重置那些需要重置的partition，比如调用了seekToBeginning，seekToEnd的partition    fetcher.resetOffsetsIfNeeded(partitions);    if (!subscriptions.hasAllFetchPositions(partitions)) {        // if we still don&#39;t have offsets for the given partitions, then we should either        // seek to the last committed position or reset using the auto reset policy        // first refresh commits for all assigned partitions        coordinator.refreshCommittedOffsetsIfNeeded();        // then do any offset lookups in case some positions are not known        fetcher.updateFetchPositions(partitions);    }}   </code></pre><h3 id="fetcher-fetchedRecords"><a href="#fetcher-fetchedRecords" class="headerlink" title="fetcher.fetchedRecords()"></a>fetcher.fetchedRecords()</h3><pre><code>public Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; fetchedRecords() {    if (nextInLineExceptionMetadata != null) {        ExceptionMetadata exceptionMetadata = nextInLineExceptionMetadata;        nextInLineExceptionMetadata = null;        TopicPartition tp = exceptionMetadata.partition;        if (subscriptions.isFetchable(tp) &amp;&amp; subscriptions.position(tp) == exceptionMetadata.fetchedOffset)            throw exceptionMetadata.exception;    }    Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; drained = new HashMap&lt;&gt;();    int recordsRemaining = maxPollRecords;    while (recordsRemaining &gt; 0) {        if (nextInLineRecords == null || nextInLineRecords.isDrained()) {            CompletedFetch completedFetch = completedFetches.poll();            if (completedFetch == null) break;            try {                nextInLineRecords = parseCompletedFetch(completedFetch);            } catch (KafkaException e) {                if (drained.isEmpty())                    throw e;                nextInLineExceptionMetadata = new ExceptionMetadata(completedFetch.partition, completedFetch.fetchedOffset, e);            }        } else {            TopicPartition partition = nextInLineRecords.partition;            List&lt;ConsumerRecord&lt;K, V&gt;&gt; records = drainRecords(nextInLineRecords, recordsRemaining);            if (!records.isEmpty()) {                List&lt;ConsumerRecord&lt;K, V&gt;&gt; currentRecords = drained.get(partition);                if (currentRecords == null) {                    drained.put(partition, records);                } else {                    // this case shouldn&#39;t usually happen because we only send one fetch at a time per partition,                    // but it might conceivably happen in some rare cases (such as partition leader changes).                    // we have to copy to a new list because the old one may be immutable                    List&lt;ConsumerRecord&lt;K, V&gt;&gt; newRecords = new ArrayList&lt;&gt;(records.size() + currentRecords.size());                    newRecords.addAll(currentRecords);                    newRecords.addAll(records);                    drained.put(partition, newRecords);                }                recordsRemaining -= records.size();            }        }    }    return drained;}</code></pre><h3 id="fetcher-sendFetches"><a href="#fetcher-sendFetches" class="headerlink" title="fetcher.sendFetches()"></a>fetcher.sendFetches()</h3><pre><code>//向订阅的所有的partition所在leader发送fetch请求public int sendFetches() {     //构建fetch请求    Map&lt;Node, FetchRequest.Builder&gt; fetchRequestMap = createFetchRequests();    for (Map.Entry&lt;Node, FetchRequest.Builder&gt; fetchEntry : fetchRequestMap.entrySet()) {        final FetchRequest.Builder request = fetchEntry.getValue();        final Node fetchTarget = fetchEntry.getKey();        log.debug(&quot;Sending fetch for partitions {} to broker {}&quot;, request.fetchData().keySet(), fetchTarget);        //发起fetch请求        client.send(fetchTarget, request)                .addListener(new RequestFutureListener&lt;ClientResponse&gt;() {                    @Override                    public void onSuccess(ClientResponse resp) {                        FetchResponse response = (FetchResponse) resp.responseBody();                        if (!matchesRequestedPartitions(request, response)) {                            // obviously we expect the broker to always send us valid responses, so this check                            // is mainly for test cases where mock fetch responses must be manually crafted.                            log.warn(&quot;Ignoring fetch response containing partitions {} since it does not match &quot; +                                    &quot;the requested partitions {}&quot;, response.responseData().keySet(),                                    request.fetchData().keySet());                            return;                        }                        Set&lt;TopicPartition&gt; partitions = new HashSet&lt;&gt;(response.responseData().keySet());                        FetchResponseMetricAggregator metricAggregator = new FetchResponseMetricAggregator(sensors, partitions);                        for (Map.Entry&lt;TopicPartition, FetchResponse.PartitionData&gt; entry : response.responseData().entrySet()) {                            TopicPartition partition = entry.getKey();                            long fetchOffset = request.fetchData().get(partition).offset;                            FetchResponse.PartitionData fetchData = entry.getValue();                            completedFetches.add(new CompletedFetch(partition, fetchOffset, fetchData, metricAggregator,                                    request.version()));                        }                        sensors.fetchLatency.record(resp.requestLatencyMs());                        sensors.fetchThrottleTimeSensor.record(response.getThrottleTime());                    }                    @Override                    public void onFailure(RuntimeException e) {                        log.debug(&quot;Fetch request to {} for partitions {} failed&quot;, fetchTarget, request.fetchData().keySet(), e);                    }                });    }    return fetchRequestMap.size();}    </code></pre><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="http://matt33.com/2017/11/11/consumer-pollonce/" target="_blank" rel="noopener">http://matt33.com/2017/11/11/consumer-pollonce/</a></li><li><a href="http://matt33.com/2017/10/22/consumer-join-group/" target="_blank" rel="noopener">http://matt33.com/2017/10/22/consumer-join-group/</a>    </li></ul>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kafka源码分析——Producer</title>
      <link href="/2019/01/05/kafka-yuan-ma-fen-xi-producer/"/>
      <url>/2019/01/05/kafka-yuan-ma-fen-xi-producer/</url>
      
        <content type="html"><![CDATA[<h2 id="Producer-使用示例"><a href="#Producer-使用示例" class="headerlink" title="Producer 使用示例"></a>Producer 使用示例</h2><h3 id="kafka-console-producer"><a href="#kafka-console-producer" class="headerlink" title="kafka-console-producer"></a>kafka-console-producer</h3><pre><code>sh kafka-console-producer.sh --broker-list localhost:9092 --topic test</code></pre><h3 id="producer-client"><a href="#producer-client" class="headerlink" title="producer client"></a>producer client</h3><pre><code>Properties props = new Properties(); props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;); props.put(&quot;acks&quot;, &quot;all&quot;); props.put(&quot;retries&quot;, 0); props.put(&quot;batch.size&quot;, 16384); props.put(&quot;linger.ms&quot;, 1); props.put(&quot;buffer.memory&quot;, 33554432); props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props); for(int i = 0; i &lt; 100; i++)     producer.send(new ProducerRecord&lt;String, String&gt;(&quot;my-topic&quot;, Integer.toString(i), Integer.toString(i))); producer.close();</code></pre><p>上述调用kafka Producer相关API，可以看到非常简单</p><pre><code>1. 生成Producer的配置，例如broker的地址，重试次数，key和value的序列化方式2. 调用KafkaProducer的send方法</code></pre><p>下面来看下Producer send的具体流程</p><h2 id="Producer-数据发送流程"><a href="#Producer-数据发送流程" class="headerlink" title="Producer 数据发送流程"></a>Producer 数据发送流程</h2><h3 id="KafkaProducer-send方法"><a href="#KafkaProducer-send方法" class="headerlink" title="KafkaProducer send方法"></a>KafkaProducer send方法</h3><pre><code>/** * * @param record 需要发送的数据    * @param callback 当数据发送成功调用的回调函数 *    */public Future&lt;RecordMetadata&gt; send(ProducerRecord&lt;K, V&gt; record, Callback callback) {    // intercept the record, which can be potentially modified; this method does not throw exceptions    ProducerRecord&lt;K, V&gt; interceptedRecord = this.interceptors == null ? record : this.interceptors.onSend(record);    return doSend(interceptedRecord, callback);}    </code></pre><p>可以看到真正的发送逻辑是在doSend方法中</p><h3 id="KafkaProducer-doSend方法"><a href="#KafkaProducer-doSend方法" class="headerlink" title="KafkaProducer doSend方法"></a>KafkaProducer doSend方法</h3><pre><code>private Future&lt;RecordMetadata&gt; doSend(ProducerRecord&lt;K, V&gt; record, Callback callback) {    TopicPartition tp = null;    try {        // 1. 检测topic的元数据是否可用        ClusterAndWaitTime clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), maxBlockTimeMs);        long remainingWaitMs = Math.max(0, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs);        Cluster cluster = clusterAndWaitTime.cluster;        // 2. 对record的key和value进行序列化        byte[] serializedKey;        try {            serializedKey = keySerializer.serialize(record.topic(), record.key());        } catch (ClassCastException cce) {            throw new SerializationException(&quot;Can&#39;t convert key of class &quot; + record.key().getClass().getName() +                    &quot; to class &quot; + producerConfig.getClass(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).getName() +                    &quot; specified in key.serializer&quot;);        }        byte[] serializedValue;        try {            serializedValue = valueSerializer.serialize(record.topic(), record.value());        } catch (ClassCastException cce) {            throw new SerializationException(&quot;Can&#39;t convert value of class &quot; + record.value().getClass().getName() +                    &quot; to class &quot; + producerConfig.getClass(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG).getName() +                    &quot; specified in value.serializer&quot;);        }          // 3. 确定需要发送的partition        int partition = partition(record, serializedKey, serializedValue, cluster);        int serializedSize = Records.LOG_OVERHEAD + Record.recordSize(serializedKey, serializedValue);        ensureValidRecordSize(serializedSize);        tp = new TopicPartition(record.topic(), partition);        long timestamp = record.timestamp() == null ? time.milliseconds() : record.timestamp();        log.trace(&quot;Sending record {} with callback {} to topic {} partition {}&quot;, record, callback, record.topic(), partition);        // producer callback will make sure to call both &#39;callback&#39; and interceptor callback        Callback interceptCallback = this.interceptors == null ? callback : new InterceptorCallback&lt;&gt;(callback, this.interceptors, tp);        // 4. 往RecordAccumulator追加record        RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey, serializedValue, interceptCallback, remainingWaitMs);        // 5. 如果batch已经满了，或者新的batch已经创建了，则唤醒send线程发送数据        if (result.batchIsFull || result.newBatchCreated) {            log.trace(&quot;Waking up the sender since topic {} partition {} is either full or getting a new batch&quot;, record.topic(), partition);            this.sender.wakeup();        }        return result.future;        // handling exceptions and record the errors;        // for API exceptions return them in the future,        // for other exceptions throw directly    } catch (ApiException e) {        log.debug(&quot;Exception occurred during message send:&quot;, e);        if (callback != null)            callback.onCompletion(null, e);        this.errors.record();        if (this.interceptors != null)            this.interceptors.onSendError(record, tp, e);        return new FutureFailure(e);    } catch (InterruptedException e) {        this.errors.record();        if (this.interceptors != null)            this.interceptors.onSendError(record, tp, e);        throw new InterruptException(e);    } catch (BufferExhaustedException e) {        this.errors.record();        this.metrics.sensor(&quot;buffer-exhausted-records&quot;).record();        if (this.interceptors != null)            this.interceptors.onSendError(record, tp, e);        throw e;    } catch (KafkaException e) {        this.errors.record();        if (this.interceptors != null)            this.interceptors.onSendError(record, tp, e);        throw e;    } catch (Exception e) {        // we notify interceptor about all exceptions, since onSend is called before anything else in this method        if (this.interceptors != null)            this.interceptors.onSendError(record, tp, e);        throw e;    }}</code></pre><p>doSend方法主要做了一下几件事情</p><h4 id="1-确认topic的元数据是否可用"><a href="#1-确认topic的元数据是否可用" class="headerlink" title="1. 确认topic的元数据是否可用"></a>1. 确认topic的元数据是否可用</h4><pre><code>ClusterAndWaitTime clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), maxBlockTimeMs);</code></pre><h4 id="2-对record的key和value进行序列化"><a href="#2-对record的key和value进行序列化" class="headerlink" title="2. 对record的key和value进行序列化"></a>2. 对record的key和value进行序列化</h4><p>kafka提供了需要的序列化的方法，用户也可以根据需要自定义序列化方法，只要实现Serializer接口即可<br><img src="https://ws4.sinaimg.cn/large/006tNc79gy1fyvqrc8es2j31zq0kwais.jpg" alt=""></p><h4 id="3-确定需要发送的partition"><a href="#3-确定需要发送的partition" class="headerlink" title="3. 确定需要发送的partition"></a>3. 确定需要发送的partition</h4><pre><code>int partition = partition(record, serializedKey, serializedValue, cluster);private int partition(ProducerRecord&lt;K, V&gt; record, byte[] serializedKey, byte[] serializedValue, Cluster cluster) {    Integer partition = record.partition();    // 若指定了partition则使用指定的partition，若没指定则使用默认(DefaultPartitioner)的生成规则    return partition != null ?            partition :            partitioner.partition(                    record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);}//DefaultPartitioner 中的partition方法public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {    List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);    int numPartitions = partitions.size();    // 若key为空，则随机生成一个num，利用num对partition的格式取余，同时保存num，下次在取num时，则对num递增即可    if (keyBytes == null) {        int nextValue = nextValue(topic);        List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);        if (availablePartitions.size() &gt; 0) {            int part = Utils.toPositive(nextValue) % availablePartitions.size();            return availablePartitions.get(part).partition();        } else {            // no partitions are available, give a non-available partition            return Utils.toPositive(nextValue) % numPartitions;        }    } else {        // 若key不为空，则对key进行hash，并用得到的hash值对partition的个数进行取余        return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;    }}private int nextValue(String topic) {    AtomicInteger counter = topicCounterMap.get(topic);    // 若num为null，则随机取个num    if (null == counter) {        counter = new AtomicInteger(new Random().nextInt());        AtomicInteger currentCounter = topicCounterMap.putIfAbsent(topic, counter);        if (currentCounter != null) {            counter = currentCounter;        }    }    // 对num进行自增操作    return counter.getAndIncrement();}</code></pre><p>获取partition的流程图<br><img src="https://ws1.sinaimg.cn/large/006tNc79gy1fyvr5e6f0ij319i0nwn59.jpg" alt=""></p><h4 id="4-往RecordAccumulator追加record"><a href="#4-往RecordAccumulator追加record" class="headerlink" title="4. 往RecordAccumulator追加record"></a>4. 往RecordAccumulator追加record</h4><p>RecordAccumulator最重要的数据结构是batches，这是一个map，其中key是topicPartition，value是一个recordBatch的先进后出的队列, batchs的结构如下图所示。batchs每次从队尾append数据，从队头开始send数据</p><pre><code>private final ConcurrentMap&lt;TopicPartition, Deque&lt;RecordBatch&gt;&gt; batches;</code></pre><p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fyvrv76ah2j30py0f4juz.jpg" alt=""></p><pre><code>public RecordAppendResult append(TopicPartition tp,                                 long timestamp,                                 byte[] key,                                 byte[] value,                                 Callback callback,                                 long maxTimeToBlock) throws InterruptedException {    // abortIncompleteBatches().    appendsInProgress.incrementAndGet();    try {        // 获取对应topicPartition的Deque        Deque&lt;RecordBatch&gt; dq = getOrCreateDeque(tp);        //对deque进行append操作，会保证线程安全        synchronized (dq) {            if (closed)                throw new IllegalStateException(&quot;Cannot send after the producer is closed.&quot;);            // 开始追加数据            RecordAppendResult appendResult = tryAppend(timestamp, key, value, callback, dq);            // 当前队尾的recordBatch数据追加成功，无需新建recordBatch            if (appendResult != null)                return appendResult;        }        // 当前队尾无recordBatch，或者数据已满，需要新分配recordBatch        int size = Math.max(this.batchSize, Records.LOG_OVERHEAD + Record.recordSize(key, value));        log.trace(&quot;Allocating a new {} byte message buffer for topic {} partition {}&quot;, size, tp.topic(), tp.partition());        ByteBuffer buffer = free.allocate(size, maxTimeToBlock);        synchronized (dq) {            // Need to check if producer is closed again after grabbing the dequeue lock.            if (closed)                throw new IllegalStateException(&quot;Cannot send after the producer is closed.&quot;);            RecordAppendResult appendResult = tryAppend(timestamp, key, value, callback, dq);            // recordBatch已经创建，需要释放刚刚分配的buffer            if (appendResult != null) {                free.deallocate(buffer);                return appendResult;            }            MemoryRecordsBuilder recordsBuilder = MemoryRecords.builder(buffer, compression, TimestampType.CREATE_TIME, this.batchSize);            RecordBatch batch = new RecordBatch(tp, recordsBuilder, time.milliseconds());            FutureRecordMetadata future = Utils.notNull(batch.tryAppend(timestamp, key, value, callback, time.milliseconds()));                // 在deque中追加新建的recordBatch            dq.addLast(batch);            // 往未返回ack的队列中，增加刚刚创建的recordBatch            incomplete.add(batch);            // 如果队列中有多个recordBatch，那么最先创建的recordBatch，肯定是可以发送的，或者新建的recordBatch已满，则可以发送数据            return new RecordAppendResult(future, dq.size() &gt; 1 || batch.isFull(), true);        }    } finally {        appendsInProgress.decrementAndGet();    }}</code></pre><h4 id="5-唤醒send线程发送数据"><a href="#5-唤醒send线程发送数据" class="headerlink" title="5. 唤醒send线程发送数据"></a>5. 唤醒send线程发送数据</h4><p>如果发现recordBatch达到发送的要求，则唤醒send线程开始发送数据，下面来看下send线程中的run方法</p><pre><code>package org.apache.kafka.clients.producer.internals;void run(long now) {    Cluster cluster = metadata.fetch();    // 获取可以发送的recordBatch    RecordAccumulator.ReadyCheckResult result = this.accumulator.ready(cluster, now);    // 如果topicPartition的leader是未知，则强制更新metadata    if (!result.unknownLeaderTopics.isEmpty()) {        // The set of topics with unknown leader contains topics with leader election pending as well as        // topics which may have expired. Add the topic again to metadata to ensure it is included        // and request metadata update, since there are messages to send to the topic.        for (String topic : result.unknownLeaderTopics)            this.metadata.add(topic);        this.metadata.requestUpdate();    }    // 删除没有ready的node    Iterator&lt;Node&gt; iter = result.readyNodes.iterator();    long notReadyTimeout = Long.MAX_VALUE;    while (iter.hasNext()) {        Node node = iter.next();        if (!this.client.ready(node, now)) {            iter.remove();            notReadyTimeout = Math.min(notReadyTimeout, this.client.connectionDelay(node, now));        }    }    // 获取对应node可发送的RecordBatch，key为node id    Map&lt;Integer, List&lt;RecordBatch&gt;&gt; batches = this.accumulator.drain(cluster,                                                                     result.readyNodes,                                                                     this.maxRequestSize,                                                                     now);    if (guaranteeMessageOrder) {        // Mute all the partitions drained        for (List&lt;RecordBatch&gt; batchList : batches.values()) {            for (RecordBatch batch : batchList)                this.accumulator.mutePartition(batch.topicPartition);        }    }    // 删除超时的RecordBatch    List&lt;RecordBatch&gt; expiredBatches = this.accumulator.abortExpiredBatches(this.requestTimeout, now);    // update sensors    for (RecordBatch expiredBatch : expiredBatches)        this.sensors.recordErrors(expiredBatch.topicPartition.topic(), expiredBatch.recordCount);    sensors.updateProduceRequestMetrics(batches);    // If we have any nodes that are ready to send + have sendable data, poll with 0 timeout so this can immediately    // loop and try sending more data. Otherwise, the timeout is determined by nodes that have partitions with data    // that isn&#39;t yet sendable (e.g. lingering, backing off). Note that this specifically does not include nodes    // with sendable data that aren&#39;t ready to send since they would cause busy looping.    long pollTimeout = Math.min(result.nextReadyCheckDelayMs, notReadyTimeout);    if (!result.readyNodes.isEmpty()) {        log.trace(&quot;Nodes with data ready to send: {}&quot;, result.readyNodes);        pollTimeout = 0;    }    // 发送RecordBatch    sendProduceRequests(batches, now);    // if some partitions are already ready to be sent, the select time would be 0;    // otherwise if some partition already has some data accumulated but not ready yet,    // the select time will be the time difference between now and its linger expiry time;    // otherwise the select time will be the time difference between now and the metadata expiry time;    this.client.poll(pollTimeout, now);}</code></pre><p>可以看到具体的发送逻辑在sendProduceRequests</p><pre><code>private void sendProduceRequest(long now, int destination, short acks, int timeout, List&lt;RecordBatch&gt; batches) {    Map&lt;TopicPartition, MemoryRecords&gt; produceRecordsByPartition = new HashMap&lt;&gt;(batches.size());    final Map&lt;TopicPartition, RecordBatch&gt; recordsByPartition = new HashMap&lt;&gt;(batches.size());    // 将同一个topicPartition的RecordBatch放在一起发送    for (RecordBatch batch : batches) {        TopicPartition tp = batch.topicPartition;        produceRecordsByPartition.put(tp, batch.records());        recordsByPartition.put(tp, batch);    }    ProduceRequest.Builder requestBuilder =            new ProduceRequest.Builder(acks, timeout, produceRecordsByPartition);    RequestCompletionHandler callback = new RequestCompletionHandler() {        public void onComplete(ClientResponse response) {            handleProduceResponse(response, recordsByPartition, time.milliseconds());        }    };    String nodeId = Integer.toString(destination);    ClientRequest clientRequest = client.newClientRequest(nodeId, requestBuilder, now, acks != 0, callback);    client.send(clientRequest, now);    log.trace(&quot;Sent produce request to {}: {}&quot;, nodeId, requestBuilder);}</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>总结一下Producer的发送流程</p><ol><li>确认topic的元数据是否可用</li><li>对key和value进行序列化</li><li>确定发送的partition</li><li>往RecordAccumulator追加record</li><li>如果满足发送条件，则唤醒sender线程发送数据</li></ol>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kafka——QuickStart(2)</title>
      <link href="/2018/12/20/kafka-quickstart-2/"/>
      <url>/2018/12/20/kafka-quickstart-2/</url>
      
        <content type="html"><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="下载源码安装"><a href="#下载源码安装" class="headerlink" title="下载源码安装"></a>下载源码安装</h3><p><a href="https://kafka.apache.org/downloads" target="_blank" rel="noopener">下载地址</a></p><p>我用的kafka的版本是0.10.2.0，后续的例子都是使用这个版本</p><pre><code>tar -zxvf kafka-0.10.2.0-src.tgzcd kafka-0.10.2.0</code></pre><h3 id="Mac-Homebrew安装"><a href="#Mac-Homebrew安装" class="headerlink" title="Mac Homebrew安装"></a>Mac Homebrew安装</h3><pre><code>brew install kafka</code></pre><p>kafka的启动需要依赖zookeeper，用homebrew安装时，会自动安装zookeeper。安装完成之后，可以用以下命令查看安装信息</p><pre><code>brew info kafka</code></pre><p>kafka的安装路径，可以用以下命令查看</p><pre><code>brew list kakfa</code></pre><p>一般情况下，brew安装的项目路径为</p><pre><code>/usr/local/Cellar</code></pre><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><h3 id="1-启动zookeeper"><a href="#1-启动zookeeper" class="headerlink" title="1. 启动zookeeper"></a>1. 启动zookeeper</h3><pre><code>cd /usr/local/Cellar/kafka/0.10.2.0/libexec/binsh zookeeper-server-start.sh ../config/zookeeper.properties</code></pre><p><img src="https://ws4.sinaimg.cn/large/006tNbRwgy1fyfqs9ohd9j327o0patom.jpg" alt=""></p><h3 id="2-启动Kafka-Server"><a href="#2-启动Kafka-Server" class="headerlink" title="2. 启动Kafka Server"></a>2. 启动Kafka Server</h3><pre><code>sh kafka-server-start.sh ../config/server.properties</code></pre><h3 id="3-创建Topic"><a href="#3-创建Topic" class="headerlink" title="3. 创建Topic"></a>3. 创建Topic</h3><pre><code>sh kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test</code></pre><h3 id="4-启动Producer"><a href="#4-启动Producer" class="headerlink" title="4. 启动Producer"></a>4. 启动Producer</h3><pre><code>sh kafka-console-producer.sh --broker-list localhost:9092 --topic test</code></pre><p><img src="https://ws3.sinaimg.cn/large/006tNbRwgy1fyfqzagbuvj31me07cwfr.jpg" alt="">    </p><h3 id="5-启动Consumer"><a href="#5-启动Consumer" class="headerlink" title="5. 启动Consumer"></a>5. 启动Consumer</h3><pre><code>sh kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning</code></pre><p><img src="https://ws3.sinaimg.cn/large/006tNbRwgy1fyfr1m23mqj327o08s0vr.jpg" alt=""></p><p>对于新的kafka版本，可以使用如下的命令</p><pre><code>sh kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning</code></pre><h2 id="kafka配置"><a href="#kafka配置" class="headerlink" title="kafka配置"></a>kafka配置</h2><h3 id="broker-配置"><a href="#broker-配置" class="headerlink" title="broker 配置"></a>broker 配置</h3><h4 id="基本配置"><a href="#基本配置" class="headerlink" title="基本配置"></a>基本配置</h4><table><thead><tr><th>配置名称</th><th>配置说明</th></tr></thead><tbody><tr><td>broker.id</td><td>broker在集群中的唯一标识</td></tr><tr><td>listeners</td><td>kafka监听的地址，如果没有配置，则使用java.net.InetAddress.getCanonicalHostName()获取的值</td></tr><tr><td>num.network.threads</td><td>处理网络请求的线程数</td></tr><tr><td>num.io.threads</td><td>处理I/O的线程数</td></tr><tr><td>socket.send.buffer.bytes</td><td>发送缓存区的大小</td></tr><tr><td>socket.receive.buffer.bytes</td><td>接收缓冲区的大小</td></tr><tr><td>socket.request.max.bytes</td><td>kafka允许接收或发送消息的最大字节数</td></tr></tbody></table><h4 id="zookeeper-配置"><a href="#zookeeper-配置" class="headerlink" title="zookeeper 配置"></a>zookeeper 配置</h4><table><thead><tr><th>配置名称</th><th>配置说明</th></tr></thead><tbody><tr><td>zookeeper.connect</td><td>zookeeper的连接地址，多个Server间以逗号分隔</td></tr><tr><td>zookeeper.connection.timeout.ms</td><td>连接zookeeper的超时时间</td></tr></tbody></table><h4 id="日志刷新策略"><a href="#日志刷新策略" class="headerlink" title="日志刷新策略"></a>日志刷新策略</h4><table><thead><tr><th>配置名称</th><th>配置说明</th></tr></thead><tbody><tr><td>log.flush.interval.messages</td><td>每次刷新至磁盘的消息数</td></tr><tr><td>log.flush.interval.ms</td><td>在数据被写入到硬盘前的最大时间</td></tr></tbody></table><h4 id="日志持久化策略"><a href="#日志持久化策略" class="headerlink" title="日志持久化策略"></a>日志持久化策略</h4><table><thead><tr><th>配置名称</th><th>配置说明</th></tr></thead><tbody><tr><td>log.retention.hours</td><td>日志保留的最长时间</td></tr><tr><td>log.retention.bytes</td><td>日志最大字节数</td></tr><tr><td>log.segment.bytes</td><td>单个log segment文件的大小</td></tr><tr><td>log.retention.check.interval.ms</td><td>检查log失效的间隔</td></tr></tbody></table><h3 id="producer-配置"><a href="#producer-配置" class="headerlink" title="producer 配置"></a>producer 配置</h3><table><thead><tr><th>配置名称</th><th>配置说明</th></tr></thead><tbody><tr><td>bootstrap.servers</td><td>broker地址</td></tr><tr><td>compression.type</td><td>数据压缩策略，none,gzip,snappy,lz4</td></tr><tr><td>partitioner.class</td><td>处理分区的类，默认根据key的hash分发到对应的分区</td></tr><tr><td>request.timeout.ms</td><td>请求的超时时间</td></tr></tbody></table><h3 id="consumer-配置"><a href="#consumer-配置" class="headerlink" title="consumer 配置"></a>consumer 配置</h3><table><thead><tr><th>配置名称</th><th>配置说明</th></tr></thead><tbody><tr><td>zookeeper.connect</td><td>zookeeper连接地址</td></tr><tr><td>zookeeper.connection.timeout.ms</td><td>zookeeper连接超时时间</td></tr><tr><td>group.id</td><td>消费组id</td></tr><tr><td>consumer.timeout.ms</td><td>消费者超时时间</td></tr></tbody></table><h2 id="kafka脚本参数说明"><a href="#kafka脚本参数说明" class="headerlink" title="kafka脚本参数说明"></a>kafka脚本参数说明</h2><h3 id="kafka-config"><a href="#kafka-config" class="headerlink" title="kafka-config"></a>kafka-config</h3><p>用于查看并修改kafka的配置，–describe 查看配置， –alter 修改配置</p><table><thead><tr><th>参数名称</th><th>参数说明</th></tr></thead><tbody><tr><td>entity-type</td><td>配置类型，有topics/clients/users/brokers</td></tr><tr><td>entiey-name</td><td>配置名称，对于topics就是topic的名称</td></tr></tbody></table><p>可以通过以下命令查看可管理的配置</p><pre><code>sh kafka-config.sh --help</code></pre><p><img src="https://ws3.sinaimg.cn/large/006tNbRwgy1fyfuab7stej30u016pdod.jpg" alt="">    </p><h4 id="describe"><a href="#describe" class="headerlink" title="describe"></a>describe</h4><pre><code>sh kafka-configs.sh --zookeeper localhost:2181 --describe --entity-type topics</code></pre><p><img src="https://ws3.sinaimg.cn/large/006tNbRwgy1fyftxq5ao7j320s04g0uv.jpg" alt=""></p><h4 id="alter"><a href="#alter" class="headerlink" title="alter"></a>alter</h4><pre><code>sh kafka-configs.sh --zookeeper localhost:2181 --alter --entity-type topics --entity-name test --add-config retention.ms=600000</code></pre><p>这个时候在看topic test的配置，发现配置已修改</p><p><img src="https://ws1.sinaimg.cn/large/006tNbRwgy1fyfu4kxpczj321o034wfw.jpg" alt="">    </p><h3 id="kafka-console-consumer"><a href="#kafka-console-consumer" class="headerlink" title="kafka-console-consumer"></a>kafka-console-consumer</h3><p>启动一个consumer</p><table><thead><tr><th>参数名称</th><th>参数说明</th></tr></thead><tbody><tr><td>bootstrap-server</td><td>broker地址，localhost:9092</td></tr><tr><td>zookeeper</td><td>zookeeper地址，localhost:2181</td></tr><tr><td>topic</td><td>topic名称</td></tr><tr><td>formatter</td><td>格式化消息的类的名称</td></tr><tr><td>from-beginning</td><td>如果consumer没有设置offset，则从最开始的消息开始消费，而不是最新的数据</td></tr><tr><td>offset</td><td>指定offset的位置，可以是正整数，也可以是earliest/latest，默认是latest</td></tr><tr><td>partition</td><td>指定从哪个partition开始消费数据</td></tr></tbody></table><h3 id="kafka-topics"><a href="#kafka-topics" class="headerlink" title="kafka-topics"></a>kafka-topics</h3><p>创建，删除，修改topic</p><table><thead><tr><th>参数名称</th><th>参数说明</th></tr></thead><tbody><tr><td>config</td><td>topic配置</td></tr><tr><td>delete-config</td><td>删除配置</td></tr><tr><td>create</td><td>创建topic</td></tr><tr><td>delete</td><td>删除topic</td></tr><tr><td>partitions</td><td>topic的分区数</td></tr><tr><td>replication-factor</td><td>topic备份的数</td></tr><tr><td>topic</td><td>topic名称</td></tr></tbody></table><h4 id="create-topic"><a href="#create-topic" class="headerlink" title="create topic"></a>create topic</h4><pre><code>sh kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 2 --topic test-topic</code></pre><h4 id="delete-topic"><a href="#delete-topic" class="headerlink" title="delete topic"></a>delete topic</h4><pre><code>sh kafka-topics.sh --delete -zookeeper localhost:2181 --topic test-topic</code></pre><h4 id="describe-topic"><a href="#describe-topic" class="headerlink" title="describe topic"></a>describe topic</h4><pre><code>sh kafka-topics.sh --zookeeper localhost:2181 --describe --topic test-topic</code></pre><h4 id="alter-topic"><a href="#alter-topic" class="headerlink" title="alter topic"></a>alter topic</h4><p>修改partitions和replica的个数，只能增加</p><pre><code>sh kafka-topics.sh --alter -zookeeper localhost:2181 --topic test-topic --partitions 3                </code></pre><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://kafka.apache.org/documentation/#configuration" target="_blank" rel="noopener">https://kafka.apache.org/documentation/#configuration</a></li><li><a href="https://my.oschina.net/u/1757002/blog/868517" target="_blank" rel="noopener">https://my.oschina.net/u/1757002/blog/868517</a></li><li><a href="https://www.jianshu.com/p/f94bb7a70ab6" target="_blank" rel="noopener">https://www.jianshu.com/p/f94bb7a70ab6</a></li><li><a href="https://www.jianshu.com/p/3ed342a28a9d" target="_blank" rel="noopener">https://www.jianshu.com/p/3ed342a28a9d</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kafka—-入门介绍(1)</title>
      <link href="/2018/12/16/kafka-ru-men-jie-shao-1/"/>
      <url>/2018/12/16/kafka-ru-men-jie-shao-1/</url>
      
        <content type="html"><![CDATA[<h2 id="Kafka介绍"><a href="#Kafka介绍" class="headerlink" title="Kafka介绍"></a>Kafka介绍</h2><p>kafka是一个分布式的，基于发布/订阅的消息系统。简单的可以理解kafka是一个消息队列，可以往队列里面写入数据，也可以从队列里面取出数据进行处理。</p><h2 id="kafka关键概念"><a href="#kafka关键概念" class="headerlink" title="kafka关键概念"></a>kafka关键概念</h2><p>我以自来水厂的例子来解释kafka的相关概念，可能不够严谨，只为方便大家理解。</p><p>从前有一家自来水厂(producer)负责把水运输到不同的地方，以供当地的居民(consumer)使用。冬天大家用水较少，但是水厂又一直在送水，导致水浪费了；到了夏天大家用水多，自来水来不及生产，导致居民无水可用。因此需要一个蓄水池(broker),自来水厂将水运输到蓄水池中，居民从蓄水池取水使用。蓄水池通过一个管道(topic)将水运输到不同的小区中</p><h3 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h3><p>topic可以理解数据标签，kafka通过topic对数据进行分门别类，就好比上述例子中的管道，使得自来水可以流向不同的地方，而不导致水混在一起。</p><h3 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h3><p>生产者，数据的来源，就好比上述例子中自来水厂，水都是从自来水来的。</p><h3 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h3><p>消费者，数据的处理者，就好比上述例子中的居民，居民需要取水喝。</p><h3 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h3><p>数据保存的地方，多个broker构成一个kafka集群。就好比上述例子中的蓄水池，生成者生成的数据都保存在broker中。</p><h2 id="Topic抽象"><a href="#Topic抽象" class="headerlink" title="Topic抽象"></a>Topic抽象</h2><p><img src="http://img.orchome.com:8888/group1/M00/00/01/KmCudlf7DsaAVF0WAABMe0J0lv4158.png" alt=""></p><p>topic是一个大的管道，但是为了提供吞吐量，在管道中有设置了许多小的通道(partition)，也就是分区。每一个分区都是一个<strong>顺序的</strong>，不可变的消息队列，并且可以持续添加。每个分区通过一个唯一的offset来标识消息处理的进度。</p><p>消费者可以控制offset，例如消费可以控制从最新的数据开始消费，即设置offset为new，也可以从最早的数据开始消费，即设置offset为early</p><h2 id="生成者"><a href="#生成者" class="headerlink" title="生成者"></a>生成者</h2><p>生产者负责往某个topic写入数据。由于topic有多个分区，数据可能会按照分区的顺序写入，也可以按照某种算法写入对应的分区，这个可以有开发者自己控制。</p><h2 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h2><p>消费者负责从topic中读取数据。kafka为消费者提供了一个抽象模型-消费组(consumer group)。消费组可以对应上述例子中小区，每一个居民都是消费者(consumer)，同一个小区的居民就是属于同一个消费组。</p><p>kafka之所以抽象消费组的概念，是为了兼容两种消费模型，队列模型和发布-订阅模型。对于队列来说，一组消费者从同一个服务器消费数据，一个消息只能由一个消费者消费。在发布-订阅模型中，一个消息被广播给所有的消费者。如果所有的消费者都在一个消费组中，则变成了队列模型；如果每一个消费者都在不同的消费组中，则变成了发布-订阅模型。</p><p><img src="http://img.orchome.com:8888/group1/M00/00/01/KmCudlf7D-OAEjy8AABoxGLnMI4173.png" alt=""></p><p>在kafka中，一个分区中的消息只能被同一个消费组中一个消费者消费。例如一个topic中有三个分区p1,p2,p3。消费组groupA，只有一个消费者A1；消费者groupB，有4个消费者，B1,B2,B3,B4。则消费情况可能如下所示，</p><p>对于消费组groupA，</p><table><thead><tr><th>partition</th><th>consumer</th></tr></thead><tbody><tr><td>p1</td><td>A1</td></tr><tr><td>p2</td><td>A1</td></tr><tr><td>p3</td><td>A1</td></tr></tbody></table><p>由于groupA只有一个consumer，所以所有的分区都由这个consumer消费</p><p>对于消费组groupB</p><table><thead><tr><th>partition</th><th>consumer</th></tr></thead><tbody><tr><td>p1</td><td>B1</td></tr><tr><td>p2</td><td>B2</td></tr><tr><td>p3</td><td>B3</td></tr></tbody></table><p>groupB有4个consumer，但是这个topic只有3个partition，所以有一个consumer将消费不到任何数据，除非其中一个consumer挂掉了，剩下空闲的这个consumer才会上位。</p><p><strong>一个partition的数据，只能由一个consumer group的一个consumer消费</strong></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://kafka.apache.org/documentation/" target="_blank" rel="noopener">Apache Kafka</a></li><li><a href="https://www.infoq.cn/article/kafka-analysis-part-1" target="_blank" rel="noopener">Kafka 设计解析（一）：Kafka 背景及架构介绍</a></li><li><a href="http://orchome.com/5#/collapse-1005" target="_blank" rel="noopener">kafka入门介绍</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
