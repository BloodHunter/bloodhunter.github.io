<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>Kafka——QuickStart(2)</title>
      <link href="/2018/12/20/kafka-quickstart-2/"/>
      <url>/2018/12/20/kafka-quickstart-2/</url>
      
        <content type="html"><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="下载源码安装"><a href="#下载源码安装" class="headerlink" title="下载源码安装"></a>下载源码安装</h3><p><a href="https://kafka.apache.org/downloads" target="_blank" rel="noopener">下载地址</a></p><p>我用的kafka的版本是0.10.2.0，后续的例子都是使用这个版本</p><pre><code>tar -zxvf kafka-0.10.2.0-src.tgzcd kafka-0.10.2.0</code></pre><h3 id="Mac-Homebrew安装"><a href="#Mac-Homebrew安装" class="headerlink" title="Mac Homebrew安装"></a>Mac Homebrew安装</h3><pre><code>brew install kafka</code></pre><p>kafka的启动需要依赖zookeeper，用homebrew安装时，会自动安装zookeeper。安装完成之后，可以用以下命令查看安装信息</p><pre><code>brew info kafka</code></pre><p>kafka的安装路径，可以用以下命令查看</p><pre><code>brew list kakfa</code></pre><p>一般情况下，brew安装的项目路径为</p><pre><code>/usr/local/Cellar</code></pre><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><h3 id="1-启动zookeeper"><a href="#1-启动zookeeper" class="headerlink" title="1. 启动zookeeper"></a>1. 启动zookeeper</h3><pre><code>cd /usr/local/Cellar/kafka/0.10.2.0/libexec/binsh zookeeper-server-start.sh ../config/zookeeper.properties</code></pre><p><img src="https://ws4.sinaimg.cn/large/006tNbRwgy1fyfqs9ohd9j327o0patom.jpg" alt=""></p><h3 id="2-启动Kafka-Server"><a href="#2-启动Kafka-Server" class="headerlink" title="2. 启动Kafka Server"></a>2. 启动Kafka Server</h3><pre><code>sh kafka-server-start.sh ../config/server.properties</code></pre><h3 id="3-创建Topic"><a href="#3-创建Topic" class="headerlink" title="3. 创建Topic"></a>3. 创建Topic</h3><pre><code>sh kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test</code></pre><h3 id="4-启动Producer"><a href="#4-启动Producer" class="headerlink" title="4. 启动Producer"></a>4. 启动Producer</h3><pre><code>sh kafka-console-producer.sh --broker-list localhost:9092 --topic test</code></pre><p><img src="https://ws3.sinaimg.cn/large/006tNbRwgy1fyfqzagbuvj31me07cwfr.jpg" alt="">    </p><h3 id="5-启动Consumer"><a href="#5-启动Consumer" class="headerlink" title="5. 启动Consumer"></a>5. 启动Consumer</h3><pre><code>sh kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning</code></pre><p><img src="https://ws3.sinaimg.cn/large/006tNbRwgy1fyfr1m23mqj327o08s0vr.jpg" alt=""></p><p>对于新的kafka版本，可以使用如下的命令</p><pre><code>sh kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning</code></pre><h2 id="kafka配置"><a href="#kafka配置" class="headerlink" title="kafka配置"></a>kafka配置</h2><h3 id="broker-配置"><a href="#broker-配置" class="headerlink" title="broker 配置"></a>broker 配置</h3><h4 id="基本配置"><a href="#基本配置" class="headerlink" title="基本配置"></a>基本配置</h4><table><thead><tr><th>配置名称</th><th>配置说明</th></tr></thead><tbody><tr><td>broker.id</td><td>broker在集群中的唯一标识</td></tr><tr><td>listeners</td><td>kafka监听的地址，如果没有配置，则使用java.net.InetAddress.getCanonicalHostName()获取的值</td></tr><tr><td>num.network.threads</td><td>处理网络请求的线程数</td></tr><tr><td>num.io.threads</td><td>处理I/O的线程数</td></tr><tr><td>socket.send.buffer.bytes</td><td>发送缓存区的大小</td></tr><tr><td>socket.receive.buffer.bytes</td><td>接收缓冲区的大小</td></tr><tr><td>socket.request.max.bytes</td><td>kafka允许接收或发送消息的最大字节数</td></tr></tbody></table><h4 id="zookeeper-配置"><a href="#zookeeper-配置" class="headerlink" title="zookeeper 配置"></a>zookeeper 配置</h4><table><thead><tr><th>配置名称</th><th>配置说明</th></tr></thead><tbody><tr><td>zookeeper.connect</td><td>zookeeper的连接地址，多个Server间以逗号分隔</td></tr><tr><td>zookeeper.connection.timeout.ms</td><td>连接zookeeper的超时时间</td></tr></tbody></table><h4 id="日志刷新策略"><a href="#日志刷新策略" class="headerlink" title="日志刷新策略"></a>日志刷新策略</h4><table><thead><tr><th>配置名称</th><th>配置说明</th></tr></thead><tbody><tr><td>log.flush.interval.messages</td><td>每次刷新至磁盘的消息数</td></tr><tr><td>log.flush.interval.ms</td><td>在数据被写入到硬盘前的最大时间</td></tr></tbody></table><h4 id="日志持久化策略"><a href="#日志持久化策略" class="headerlink" title="日志持久化策略"></a>日志持久化策略</h4><table><thead><tr><th>配置名称</th><th>配置说明</th></tr></thead><tbody><tr><td>log.retention.hours</td><td>日志保留的最长时间</td></tr><tr><td>log.retention.bytes</td><td>日志最大字节数</td></tr><tr><td>log.segment.bytes</td><td>单个log segment文件的大小</td></tr><tr><td>log.retention.check.interval.ms</td><td>检查log失效的间隔</td></tr></tbody></table><h3 id="producer-配置"><a href="#producer-配置" class="headerlink" title="producer 配置"></a>producer 配置</h3><table><thead><tr><th>配置名称</th><th>配置说明</th></tr></thead><tbody><tr><td>bootstrap.servers</td><td>broker地址</td></tr><tr><td>compression.type</td><td>数据压缩策略，none,gzip,snappy,lz4</td></tr><tr><td>partitioner.class</td><td>处理分区的类，默认根据key的hash分发到对应的分区</td></tr><tr><td>request.timeout.ms</td><td>请求的超时时间</td></tr></tbody></table><h3 id="consumer-配置"><a href="#consumer-配置" class="headerlink" title="consumer 配置"></a>consumer 配置</h3><table><thead><tr><th>配置名称</th><th>配置说明</th></tr></thead><tbody><tr><td>zookeeper.connect</td><td>zookeeper连接地址</td></tr><tr><td>zookeeper.connection.timeout.ms</td><td>zookeeper连接超时时间</td></tr><tr><td>group.id</td><td>消费组id</td></tr><tr><td>consumer.timeout.ms</td><td>消费者超时时间</td></tr></tbody></table><h2 id="kafka脚本参数说明"><a href="#kafka脚本参数说明" class="headerlink" title="kafka脚本参数说明"></a>kafka脚本参数说明</h2><h3 id="kafka-config"><a href="#kafka-config" class="headerlink" title="kafka-config"></a>kafka-config</h3><p>用于查看并修改kafka的配置，–describe 查看配置， –alter 修改配置</p><table><thead><tr><th>参数名称</th><th>参数说明</th></tr></thead><tbody><tr><td>entity-type</td><td>配置类型，有topics/clients/users/brokers</td></tr><tr><td>entiey-name</td><td>配置名称，对于topics就是topic的名称</td></tr></tbody></table><p>可以通过以下命令查看可管理的配置</p><pre><code>sh kafka-config.sh --help</code></pre><p><img src="https://ws3.sinaimg.cn/large/006tNbRwgy1fyfuab7stej30u016pdod.jpg" alt="">    </p><h4 id="describe"><a href="#describe" class="headerlink" title="describe"></a>describe</h4><pre><code>sh kafka-configs.sh --zookeeper localhost:2181 --describe --entity-type topics</code></pre><p><img src="https://ws3.sinaimg.cn/large/006tNbRwgy1fyftxq5ao7j320s04g0uv.jpg" alt=""></p><h4 id="alter"><a href="#alter" class="headerlink" title="alter"></a>alter</h4><pre><code>sh kafka-configs.sh --zookeeper localhost:2181 --alter --entity-type topics --entity-name test --add-config retention.ms=600000</code></pre><p>这个时候在看topic test的配置，发现配置已修改</p><p><img src="https://ws1.sinaimg.cn/large/006tNbRwgy1fyfu4kxpczj321o034wfw.jpg" alt="">    </p><h3 id="kafka-console-consumer"><a href="#kafka-console-consumer" class="headerlink" title="kafka-console-consumer"></a>kafka-console-consumer</h3><p>启动一个consumer</p><table><thead><tr><th>参数名称</th><th>参数说明</th></tr></thead><tbody><tr><td>bootstrap-server</td><td>broker地址，localhost:9092</td></tr><tr><td>zookeeper</td><td>zookeeper地址，localhost:2181</td></tr><tr><td>topic</td><td>topic名称</td></tr><tr><td>formatter</td><td>格式化消息的类的名称</td></tr><tr><td>from-beginning</td><td>如果consumer没有设置offset，则从最开始的消息开始消费，而不是最新的数据</td></tr><tr><td>offset</td><td>指定offset的位置，可以是正整数，也可以是earliest/latest，默认是latest</td></tr><tr><td>partition</td><td>指定从哪个partition开始消费数据</td></tr></tbody></table><h3 id="kafka-topics"><a href="#kafka-topics" class="headerlink" title="kafka-topics"></a>kafka-topics</h3><p>创建，删除，修改topic</p><table><thead><tr><th>参数名称</th><th>参数说明</th></tr></thead><tbody><tr><td>config</td><td>topic配置</td></tr><tr><td>delete-config</td><td>删除配置</td></tr><tr><td>create</td><td>创建topic</td></tr><tr><td>delete</td><td>删除topic</td></tr><tr><td>partitions</td><td>topic的分区数</td></tr><tr><td>replication-factor</td><td>topic备份的数</td></tr><tr><td>topic</td><td>topic名称</td></tr></tbody></table><h4 id="create-topic"><a href="#create-topic" class="headerlink" title="create topic"></a>create topic</h4><pre><code>sh kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 2 --topic test-topic</code></pre><h4 id="delete-topic"><a href="#delete-topic" class="headerlink" title="delete topic"></a>delete topic</h4><pre><code>sh kafka-topics.sh --delete -zookeeper localhost:2181 --topic test-topic</code></pre><h4 id="describe-topic"><a href="#describe-topic" class="headerlink" title="describe topic"></a>describe topic</h4><pre><code>sh kafka-topics.sh --zookeeper localhost:2181 --describe --topic test-topic</code></pre><h4 id="alter-topic"><a href="#alter-topic" class="headerlink" title="alter topic"></a>alter topic</h4><p>修改partitions和replica的个数，只能增加</p><pre><code>sh kafka-topics.sh --alter -zookeeper localhost:2181 --topic test-topic --partitions 3                </code></pre><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://kafka.apache.org/documentation/#configuration" target="_blank" rel="noopener">https://kafka.apache.org/documentation/#configuration</a></li><li><a href="https://my.oschina.net/u/1757002/blog/868517" target="_blank" rel="noopener">https://my.oschina.net/u/1757002/blog/868517</a></li><li><a href="https://www.jianshu.com/p/f94bb7a70ab6" target="_blank" rel="noopener">https://www.jianshu.com/p/f94bb7a70ab6</a></li><li><a href="https://www.jianshu.com/p/3ed342a28a9d" target="_blank" rel="noopener">https://www.jianshu.com/p/3ed342a28a9d</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kafka—-入门介绍(1)</title>
      <link href="/2018/12/16/kafka-ru-men-jie-shao-1/"/>
      <url>/2018/12/16/kafka-ru-men-jie-shao-1/</url>
      
        <content type="html"><![CDATA[<h2 id="Kafka介绍"><a href="#Kafka介绍" class="headerlink" title="Kafka介绍"></a>Kafka介绍</h2><p>kafka是一个分布式的，基于发布/订阅的消息系统。简单的可以理解kafka是一个消息队列，可以往队列里面写入数据，也可以从队列里面取出数据进行处理。</p><h2 id="kafka关键概念"><a href="#kafka关键概念" class="headerlink" title="kafka关键概念"></a>kafka关键概念</h2><p>我以自来水厂的例子来解释kafka的相关概念，可能不够严谨，只为方便大家理解。</p><p>从前有一家自来水厂(producer)负责把水运输到不同的地方，以供当地的居民(consumer)使用。冬天大家用水较少，但是水厂又一直在送水，导致水浪费了；到了夏天大家用水多，自来水来不及生产，导致居民无水可用。因此需要一个蓄水池(broker),自来水厂将水运输到蓄水池中，居民从蓄水池取水使用。蓄水池通过一个管道(topic)将水运输到不同的小区中</p><h3 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h3><p>topic可以理解数据标签，kafka通过topic对数据进行分门别类，就好比上述例子中的管道，使得自来水可以流向不同的地方，而不导致水混在一起。</p><h3 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h3><p>生产者，数据的来源，就好比上述例子中自来水厂，水都是从自来水来的。</p><h3 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h3><p>消费者，数据的处理者，就好比上述例子中的居民，居民需要取水喝。</p><h3 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h3><p>数据保存的地方，多个broker构成一个kafka集群。就好比上述例子中的蓄水池，生成者生成的数据都保存在broker中。</p><h2 id="Topic抽象"><a href="#Topic抽象" class="headerlink" title="Topic抽象"></a>Topic抽象</h2><p><img src="http://img.orchome.com:8888/group1/M00/00/01/KmCudlf7DsaAVF0WAABMe0J0lv4158.png" alt=""></p><p>topic是一个大的管道，但是为了提供吞吐量，在管道中有设置了许多小的通道(partition)，也就是分区。每一个分区都是一个<strong>顺序的</strong>，不可变的消息队列，并且可以持续添加。每个分区通过一个唯一的offset来标识消息处理的进度。</p><p>消费者可以控制offset，例如消费可以控制从最新的数据开始消费，即设置offset为new，也可以从最早的数据开始消费，即设置offset为early</p><h2 id="生成者"><a href="#生成者" class="headerlink" title="生成者"></a>生成者</h2><p>生产者负责往某个topic写入数据。由于topic有多个分区，数据可能会按照分区的顺序写入，也可以按照某种算法写入对应的分区，这个可以有开发者自己控制。</p><h2 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h2><p>消费者负责从topic中读取数据。kafka为消费者提供了一个抽象模型-消费组(consumer group)。消费组可以对应上述例子中小区，每一个居民都是消费者(consumer)，同一个小区的居民就是属于同一个消费组。</p><p>kafka之所以抽象消费组的概念，是为了兼容两种消费模型，队列模型和发布-订阅模型。对于队列来说，一组消费者从同一个服务器消费数据，一个消息只能由一个消费者消费。在发布-订阅模型中，一个消息被广播给所有的消费者。如果所有的消费者都在一个消费组中，则变成了队列模型；如果每一个消费者都在不同的消费组中，则变成了发布-订阅模型。</p><p><img src="http://img.orchome.com:8888/group1/M00/00/01/KmCudlf7D-OAEjy8AABoxGLnMI4173.png" alt=""></p><p>在kafka中，一个分区中的消息只能被同一个消费组中一个消费者消费。例如一个topic中有三个分区p1,p2,p3。消费组groupA，只有一个消费者A1；消费者groupB，有4个消费者，B1,B2,B3,B4。则消费情况可能如下所示，</p><p>对于消费组groupA，</p><table><thead><tr><th>partition</th><th>consumer</th></tr></thead><tbody><tr><td>p1</td><td>A1</td></tr><tr><td>p2</td><td>A1</td></tr><tr><td>p3</td><td>A1</td></tr></tbody></table><p>由于groupA只有一个consumer，所以所有的分区都由这个consumer消费</p><p>对于消费组groupB</p><table><thead><tr><th>partition</th><th>consumer</th></tr></thead><tbody><tr><td>p1</td><td>B1</td></tr><tr><td>p2</td><td>B2</td></tr><tr><td>p3</td><td>B3</td></tr></tbody></table><p>groupB有4个consumer，但是这个topic只有3个partition，所以有一个consumer将消费不到任何数据，除非其中一个consumer挂掉了，剩下空闲的这个consumer才会上位。</p><p><strong>一个partition的数据，只能由一个consumer group的一个consumer消费</strong></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://kafka.apache.org/documentation/" target="_blank" rel="noopener">Apache Kafka</a></li><li><a href="https://www.infoq.cn/article/kafka-analysis-part-1" target="_blank" rel="noopener">Kafka 设计解析（一）：Kafka 背景及架构介绍</a></li><li><a href="http://orchome.com/5#/collapse-1005" target="_blank" rel="noopener">kafka入门介绍</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
