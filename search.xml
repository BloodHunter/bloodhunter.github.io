<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>JVM Garbage Collector——CMS</title>
      <link href="/2020/01/04/jvm-garbage-collector-cms/"/>
      <url>/2020/01/04/jvm-garbage-collector-cms/</url>
      
        <content type="html"><![CDATA[<h2 id="CMS定义"><a href="#CMS定义" class="headerlink" title="CMS定义"></a>CMS定义</h2><p>CMS的全称是Concurrent Mark Sweep。</p><p>从名称上可以看出CMS的特点，可并发，使用标记-清除算法。CMS是针对老年代垃圾回收的收集器</p><h2 id="CMS目标"><a href="#CMS目标" class="headerlink" title="CMS目标"></a>CMS目标</h2><p>CMS设计时的目标就是获取最小的停顿时间，也就是低延迟。对于响应时间比较敏感的应用比较适合使用CMS</p><h2 id="CMS过程"><a href="#CMS过程" class="headerlink" title="CMS过程"></a>CMS过程</h2><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20200104154332.png" alt=""><br>CMS的执行过程可以分为以下几个阶段</p><ol><li>Initial Mark(STW)</li><li>Concurrent Mark</li><li>Concurrent Preclean</li><li>Final Remark(STW)</li><li>Concurrent Sweep</li><li>Reset</li></ol><h3 id="Initial-Mark-初始标记"><a href="#Initial-Mark-初始标记" class="headerlink" title="Initial Mark(初始标记)"></a>Initial Mark(初始标记)</h3><p>在这个阶段会进行可达性分析，因此需要Stop the world，暂停应用程序。</p><p>初始标记仅仅标记两类对象，因此速度很多，STW的时间很短</p><ol><li>GC ROOT<strong>直接关联</strong>的对象</li><li>新生代引用的老年代对象</li></ol><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20200105142725.png" alt=""></p><h3 id="Concurrent-Mark-并发标记"><a href="#Concurrent-Mark-并发标记" class="headerlink" title="Concurrent Mark(并发标记)"></a>Concurrent Mark(并发标记)</h3><p>在这个阶段GC线程与用户并发进行，从初始标记阶段标记的对象出发，标记所有可达的对象。</p><h3 id="Concurrent-Preclean-并发预清理"><a href="#Concurrent-Preclean-并发预清理" class="headerlink" title="Concurrent Preclean(并发预清理)"></a>Concurrent Preclean(并发预清理)</h3><p>由于Concurrent Mark阶段是应用线程和GC线程并发执行的，那么在这个期间，可能会有对象从新生代晋升到老年代，也有一些引用会发生改变，所有在这个阶段会标记<strong>新生代晋升的对象</strong>、<strong>新分配到老年代的对象</strong>以及在<strong>并发阶段被修改了的对象</strong></p><p>我们知道CMS的目标是获取最短的停顿时间，如果不在这个阶段进行这些标记，那么下一个remark阶段就需要更多的工作，而这个阶段是需要STW，因此要把一些复杂的操作在预清理阶段完成。</p><p>归根结底，在这个阶段主要处理一个问题</p><ul><li>如何确定老年代的对象是活着的</li></ul><p>答案也很简单，通过GC ROOT可达的对象就是活着的，因此需要扫描新生代和老年代。但是全量扫描新生代和老年代肯定会非常耗时，因此需要一个能够快速识别新生代和老年代活着对象的机制。</p><h4 id="新生代识别活着对象"><a href="#新生代识别活着对象" class="headerlink" title="新生代识别活着对象"></a>新生代识别活着对象</h4><p>对于新生代来说，经过一次Young GC后剩下的对象肯定都是活着的，并且活着的对象很少。</p><p>可想而知，如果在扫描新生代之前发生一次Young GC，那么扫描的效率将大大提高。</p><p>CMS有两个参数：</p><ol><li>CMSScheduleRemarkEdenSizeThreshold 默认2M</li><li>CMSScheduleRemarkEdenPenetration 默认值50%</li></ol><p>这两个参数的意思，在Eden空间的大小超过2M时，启动可中断的并发预清理(CMS-concurrent-abortable-preclean), 直到Eden的空间利用率超过50%时中断，进入到下一个阶段(remark)。</p><p>可中断的并发预清理是为了等待一次Young GC的发生，但是我们知道这个是不可控的，因此需要控制这个阶段的执行时间，CMS通过以下两个参数来控制</p><ol><li>CMSMaxAbortablePrecleanLoops 可中断的并发预清理的执行次数超过这个值，默认是0</li><li>CMSMaxAbortablePrecleanTime 执行可中断的并发预清理的时间超过这个值，默认是5S</li></ol><p>另外CMS还提供了CMSScavengeBeforeRemark参数，使在进入remark阶段之前强制执行一次Young GC。</p><h4 id="老年代识别活着对象"><a href="#老年代识别活着对象" class="headerlink" title="老年代识别活着对象"></a>老年代识别活着对象</h4><p>老年代会维护一个叫CARD TABLE的数组，数组中每个位置存的是个byte，CMS将老年代的空间分成512bytes的块，card table中的每一个元素对应一块。</p><p>在并发标记阶段，如果某个对象的引用发生了变化，那么就标记这个对象所在的块为dirty card。</p><p>在并发预清理阶段就会重新扫描这个块，将该对象引用的对象标记为可达。</p><p>card table还有一个作用，如果一个老年代对象引用了新生代的对象，那么它对应的块也会被标记为dirty card，这样在<strong>Young GC阶段通过扫描card table就可以快速识别老年代引用的对象</strong></p><h3 id="Final-Remark-重新标记"><a href="#Final-Remark-重新标记" class="headerlink" title="Final Remark(重新标记)"></a>Final Remark(重新标记)</h3><p>暂停所有应用线程，重新扫描堆中的对象，进行可达性分析，标记活着的对象。注意这个阶段是<strong>多线程</strong>的</p><h3 id="Concurrent-Sweep-并发清理"><a href="#Concurrent-Sweep-并发清理" class="headerlink" title="Concurrent Sweep(并发清理)"></a>Concurrent Sweep(并发清理)</h3><p>应用线程被激活，同时清理哪些无效的对象</p><h3 id="Reset-重置"><a href="#Reset-重置" class="headerlink" title="Reset(重置)"></a>Reset(重置)</h3><p>CMS清除内部状态，为下次回收做准备</p><h2 id="CMS存在的问题"><a href="#CMS存在的问题" class="headerlink" title="CMS存在的问题"></a>CMS存在的问题</h2><h3 id="1-抢占CPU资源"><a href="#1-抢占CPU资源" class="headerlink" title="1. 抢占CPU资源"></a>1. 抢占CPU资源</h3><p>CMS是并发的，而并发就意味着CPU资源，即GC线程与应用线程抢占CPU，这样可能会造成应用执行效率下降。</p><p>CMS默认的回收线程数是<strong>(CPU个数+3)/4</strong>，可以看到如果CPU个数为2，CMS会启动一个GC线程，相当于GC线程占用了50%的CPU资源。</p><p>但是对于目前的场景来说，PC至少都是双核处理器，更别说大型的服务器了。</p><h3 id="2-Concurrent-Mode-Failure"><a href="#2-Concurrent-Mode-Failure" class="headerlink" title="2. Concurrent Mode Failure"></a>2. Concurrent Mode Failure</h3><p>由于并发清理阶段，用户线程还在运行，所以必须预留出一定的空间提供给用户线程，不能像其他收集器那样等到老年代满了在进行GC。</p><p>CMS提供了CMSInitiatingOccupancyFraction参数来设置老年代空间使用百分比，达到了百分比就进行垃圾回收，默认值是92%。</p><p>可以想象，如果这个参数设置过小，那么就会导致频繁的GC，如果设置的过高呢？假设将参数设置为99%，若用户线程所需的空间大于1%，那么就会产生Concurrent Mode Failure，意思是并发模式失败了。</p><p>这时，虚拟机就会启动备案：使用Serial Old收集器重新对老年代进行垃圾回收.如此一来，停顿时间变得更长</p><p>CMS还提供了动态检测机制，可以根据历史记录，来预测老年代还要多久填满以及进行一次回收所需的时间。这个特性可用通过<strong>UseCMSInitiatingOccupancyOnly</strong>来关闭</p><h3 id="3-Floating-Garbage"><a href="#3-Floating-Garbage" class="headerlink" title="3. Floating Garbage"></a>3. Floating Garbage</h3><p>在并发清理阶段，用户线程还在运行，那么就有可能产生新的垃圾，新的垃圾在此次GC无法清除，只能等到下次GC处理，这些垃圾就成为Floating Garbage(浮动垃圾)</p><h3 id="4-空间碎片"><a href="#4-空间碎片" class="headerlink" title="4. 空间碎片"></a>4. 空间碎片</h3><p>CMS使用的是mark-sweep算法，可能会造成大量的空间碎片，空间碎片过多，会导致无法分配大对象，此时就不得不进行一次full gc</p><p>CMS的解决方案是使用<strong>UseCMSCompactAtFullCollection</strong>参数(默认开启)，在顶不住要进行Full GC时开启内存碎片整理</p><p>同时还有另外一个参数<strong>CMSFullGCsBeforeCompaction</strong>，用于设置执行多少次不压缩的Full GC后，跟着来一次带压缩的（默认为0，每次进入Full GC时都进行碎片整理）。</p><h2 id="相关参数"><a href="#相关参数" class="headerlink" title="相关参数"></a>相关参数</h2><table><thead><tr><th>参数</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td>UseConcMarkSweepGC</td><td></td><td>使用CMS</td></tr><tr><td>CMSScheduleRemarkEdenSizeThreshold</td><td>2M</td><td>Eden空间大于2M，则开启可中断并发预清理</td></tr><tr><td>CMSScheduleRemarkEdenPenetration</td><td>50%</td><td>Eden空间利用率大于50%，则中断预清理，进入remark</td></tr><tr><td>CMSMaxAbortablePrecleanLoops</td><td>0</td><td>执行可中断预清理的次数超过阈值，则进入remark</td></tr><tr><td>CMSMaxAbortablePrecleanTime</td><td>5S</td><td>执行可中断预清理的时间超过5秒，则进入remark</td></tr><tr><td>CMSInitiatingOccupancyFraction</td><td>92%</td><td>老年代空间利用率达到92%，则进行GC</td></tr><tr><td>UseCMSInitiatingOccupancyOnly</td><td>true</td><td>是否开启自动预测GC时机</td></tr><tr><td>UseCMSCompactAtFullCollection</td><td>true</td><td>是否在full gc时进行碎片整理</td></tr><tr><td>CMSFullGCsBeforeCompaction</td><td>0</td><td>执行几次不压缩的full gc后，执行一次带压缩的full gc</td></tr></tbody></table><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/cms.html" target="_blank" rel="noopener">Concurrent Mark Sweep (CMS) Collector</a></li><li><a href="https://www.jianshu.com/p/2a1b2f17d3e4" target="_blank" rel="noopener">图解CMS垃圾回收机制，你值得拥有</a></li><li><a href="https://www.jianshu.com/p/78017c8b8e0f" target="_blank" rel="noopener">不可错过的CMS学习笔记</a></li><li><a href="https://www.cnblogs.com/littleLord/p/5380624.html" target="_blank" rel="noopener">详解CMS垃圾回收机制</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title></title>
      <link href="/2019/11/07/log-stat-admin/"/>
      <url>/2019/11/07/log-stat-admin/</url>
      
        <content type="html"><![CDATA[<ul><li style="list-style: none"><input type="checkbox" checked> APM管理后台域名切换</li><li style="list-style: none"><input type="checkbox" checked> APM processor华为云正式环境部署</li><li style="list-style: none"><input type="checkbox"> flink 配置更新</li><li style="list-style: none"><input type="checkbox"> 告警平台告警启动</li><li style="list-style: none"><input type="checkbox"> Grafana报表数据源修改</li></ul><h2 id="chaos-monitor"><a href="#chaos-monitor" class="headerlink" title="chaos-monitor"></a>chaos-monitor</h2><table><thead><tr><th>job</th><th>IDC datasource</th><th>HW</th></tr></thead><tbody><tr><td>chaos_domain_monitor</td><td><a href="http://192.168.135.186:8086" target="_blank" rel="noopener">http://192.168.135.186:8086</a></td><td>m8086.influxdb.m.com:8086</td></tr><tr><td>chaos-monitor</td><td><a href="http://192.168.135.186:8086" target="_blank" rel="noopener">http://192.168.135.186:8086</a></td><td>m8086.influxdb.m.com:8086</td></tr><tr><td>chaos_gid_buffer_error</td><td><a href="http://192.168.135.186:8086" target="_blank" rel="noopener">http://192.168.135.186:8086</a></td><td>m8086.influxdb.m.com:8086</td></tr><tr><td>chaos-monitor-transcode</td><td><a href="http://192.168.135.186:8086" target="_blank" rel="noopener">http://192.168.135.186:8086</a></td><td>m8086.influxdb.m.com:8086</td></tr><tr><td>chaos-monitor-file</td><td><a href="http://10.12.128.158:8116" target="_blank" rel="noopener">http://10.12.128.158:8116</a></td><td>m8116.influxdb.m.com</td></tr></tbody></table><h2 id="upload-sdk"><a href="#upload-sdk" class="headerlink" title="upload_sdk"></a>upload_sdk</h2><table><thead><tr><th>job</th><th>IDC datasource</th><th>HW</th></tr></thead><tbody><tr><td>upload_file_monitor</td><td><a href="http://m8886.bx.influxdb.m.com:8886" target="_blank" rel="noopener">http://m8886.bx.influxdb.m.com:8886</a></td><td>m8886.influxdb.m.com:8886</td></tr></tbody></table><h2 id="pic-cloud"><a href="#pic-cloud" class="headerlink" title="pic_cloud"></a>pic_cloud</h2><table><thead><tr><th>job</th><th>IDC datasource</th><th>HW</th></tr></thead><tbody><tr><td>pic_cloud_flink</td><td><a href="http://10.12.128.112:8076" target="_blank" rel="noopener">http://10.12.128.112:8076</a></td><td>m8076.influxdb.m.com:8076</td></tr></tbody></table><h2 id="hubble"><a href="#hubble" class="headerlink" title="hubble"></a>hubble</h2><table><thead><tr><th>job</th><th>IDC datasource</th><th>HW</th></tr></thead><tbody><tr><td>hubble_h5</td><td><a href="http://192.168.21.7:8106" target="_blank" rel="noopener">http://192.168.21.7:8106</a></td><td>m8206.influxdb.m.com:8206</td></tr><tr><td>hubble</td><td><a href="http://10.12.128.158:8096,http://10.12.128.158:8106,http://m8586.bx.influxdb.m.com:8586" target="_blank" rel="noopener">http://10.12.128.158:8096,http://10.12.128.158:8106,http://m8586.bx.influxdb.m.com:8586</a></td><td>m8096.influxdb.m.com:8096,m8106.influxdb.m.com:8106,m8586.influxdb.m.com:8586    </td></tr></tbody></table>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>JVM Garbage Collector——Parallel Collector</title>
      <link href="/2019/10/27/jvm-garbage-collector-parallel-collector/"/>
      <url>/2019/10/27/jvm-garbage-collector-parallel-collector/</url>
      
        <content type="html"><![CDATA[<h2 id="内存模型"><a href="#内存模型" class="headerlink" title="内存模型"></a>内存模型</h2><p><img src="https://docs.oracle.com/en/java/javase/12/gctuning/img/jsgct_dt_002_armgnt_gn_pl_new.png" alt=""></p><p>Java中的内存模型如上图所示，分为两大块old(老年代)和young(新生代)，新生代又分为三个区，分别是Eden(伊甸园)，from Survivor(幸存者)，to Survivor。为什么要这么设计呢，其实和垃圾回收算法有关。</p><h2 id="回收算法"><a href="#回收算法" class="headerlink" title="回收算法"></a>回收算法</h2><h3 id="标记-清除算法-Mark-Sweep"><a href="#标记-清除算法-Mark-Sweep" class="headerlink" title="标记-清除算法(Mark-Sweep)"></a>标记-清除算法(Mark-Sweep)</h3><p>标记清除算法将垃圾收集分为两个步骤，第一步是标记，标记的对象也就是即将要回收的垃圾对象。那么如何判定一个对象是垃圾对象呢。一个对象如果不存在任何引用就可以认为它是一个垃圾对象。第二步是清除，将第一步中找出的垃圾对象进行清除。</p><p>从上述的描述可知，标记-清除算法容易导致大量的空间碎片，因为回收后的空间是不连续的。</p><h3 id="复制算法-Copying"><a href="#复制算法-Copying" class="headerlink" title="复制算法(Copying)"></a>复制算法(Copying)</h3><p>针对标记清除算法的缺点，有人提出了复制算法。复制算法的核心在于将内存分为两块，在进行对象分配时，只使用其中一块内存(from)，当这块内存满了就进行垃圾回收：将存活的对象复制到另一块内存(to)中，此时可以清除from中的所有对象，完成此次垃圾收集。若to满了，便将对象复制到from，清除to中的对象，如此反复。</p><p>复制算法保证了空间的连续性，避免出现大量的空间碎片，但是它的空间利用率却不高，相当于只利用了50%的空间。</p><h3 id="标记-压缩算法-Mark-Compact"><a href="#标记-压缩算法-Mark-Compact" class="headerlink" title="标记-压缩算法 (Mark-Compact)"></a>标记-压缩算法 (Mark-Compact)</h3><p>在存活对象少，垃圾对象多的情况下，复制算法的效率很高，但是如果存活对象多并且对象较大，此时在使用复制算法，复制成本高，效率很低。</p><p>标记-压缩算法可以解决上述的问题，它是基于标记-清除算法进行改进的一种算法。在完成标记之后，标记-压缩算法并不会马上进入清除阶段，而是将存活对象压缩到内存的另一端，之后再将边界外的对象进行清除。</p><p>这种方法既避免了碎片的产生，又不需要两块相同的内存空间，因此，其性价比比较高。</p><h2 id="并行收集线程数"><a href="#并行收集线程数" class="headerlink" title="并行收集线程数"></a>并行收集线程数</h2><p>并行垃圾收集器的垃圾收集线程数与机器的CPU相关。当CPU小于8时，线程数与CPU的数量相等，当CPU大于8时，线程数等于5/8的CPU数</p><pre><code>thread = N (N &lt;= 8)thread = 5/8 * N (N &gt; 8)</code></pre><p>可以使用<strong>-XX:ParallelGCThreads</strong>参数来指定线程数。</p><h2 id="设置参数"><a href="#设置参数" class="headerlink" title="设置参数"></a>设置参数</h2><p>并行垃圾收集器可以设置的参数有三点</p><ol><li>最大停顿时间</li><li>吞吐量</li><li>堆大小</li></ol><h3 id="最大停顿时间"><a href="#最大停顿时间" class="headerlink" title="最大停顿时间"></a>最大停顿时间</h3><p>-XX:+MaxGCPauseMills:\<n> 设置最大垃圾收集停顿时间，单位是毫秒。N是一个大于0的整数，收集器在工作时会调整堆大小或者其他参数，尽可能的把停顿时间控制在N毫秒以内。如果希望减少停顿时间，而把这个值设置的很小，JVM为了实现这个目标，可能会设置一个较小的堆(一个小堆比一个大堆回收的快)，而这会导致垃圾收集变得频繁，从而增加了垃圾回收的总时间，降低了吞吐量。</n></p><h3 id="吞吐量"><a href="#吞吐量" class="headerlink" title="吞吐量"></a>吞吐量</h3><p>-XX:+GCTimeRatio:\<n> 设置吞吐量大小。N是一个0-100的整数，收集器将不会花费超过1/(N+1)的时间来用于垃圾收集。例如，假设N=19，那么系统用于收集垃圾的时间将不超过1/(19+1) =5%。默认情况下，N=99，表示不超过1%的时间用于垃圾收集</n></p><h3 id="堆大小"><a href="#堆大小" class="headerlink" title="堆大小"></a>堆大小</h3><p>-Xmx表示最大的堆内存，堆的大小也会影响垃圾收集。并行收集器会通过调整堆的大小来实现最大停顿时间以及吞吐量这两个目标。</p><h2 id="heap调整"><a href="#heap调整" class="headerlink" title="heap调整"></a>heap调整</h2><p>并行收集器会通过调整堆的大小来实现最大停顿时间以及吞吐量这两个目前。收集器通过一定的比例来扩大或缩小堆的大小，默认情况扩大的比例是20%，缩小的比例是5%。这两个比例可以通过参数来调整。</p><p>XX:YoungGenerationSizeIncrement=\<y> 表示的新生代扩大的比例</y></p><p>XX:TenuredGenerationSizeIncrement=\<t> 表示的老年代扩大的比例</t></p><p>XX:AdaptiveSizeDecrementScaleFactor=\<d> 用来控制缩小的比例，假设扩大的比例为X，那么缩小的比例就为X/D</d></p><h2 id="OutOfMemoryError"><a href="#OutOfMemoryError" class="headerlink" title="OutOfMemoryError"></a>OutOfMemoryError</h2><p>当花费在垃圾收集的时间过多时，收集器将抛出OutOfMemoryError的异常。默认情况下，如果超过98%的时间用于垃圾收集，而回收的堆大小小于2%，那么系统将抛出OutOfMemoryError。</p><p>之所以这样设置是为了避免系统花费了大量的时间用于垃圾收集，但是得到的收益却很小。可以用-XX:-UseGCOverheadLimit这个参数来关闭这个特性。</p><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。</p><p>并行收集器可以通过设置参数来设置对应的目标。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://docs.oracle.com/en/java/javase/12/gctuning/parallel-collector1.html#GUID-ECF0EE1D-C39E-453D-9B3D-603E25ADB9AD" target="_blank" rel="noopener">The Parallel Collector</a></li><li><a href="https://www.ibm.com/developerworks/cn/java/j-lo-JVMGarbageCollection/index.html" target="_blank" rel="noopener">JVM 垃圾回收器工作原理及使用实例介绍</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Prometheus Counter</title>
      <link href="/2019/10/11/prometheus-counter/"/>
      <url>/2019/10/11/prometheus-counter/</url>
      
        <content type="html"><![CDATA[<p>我曾经以为Counter是prometheus中最简单的一种metric，直到我在Grafana中配置counter相关的dashboard之后，才发现自己对于counter的理解有一些偏差。因此这篇博客将会详细的介绍counter的用法。</p><h2 id="创建Demo"><a href="#创建Demo" class="headerlink" title="创建Demo"></a>创建Demo</h2><p>为了更好的说明，我们需要创建一个简单的demo，用来构建一个简单可控的counter以便prometheus采集。在我之前的一篇博客<a href="https://bloodhunter.github.io/2019/09/27/spring-boot-zheng-he-prometheus/" target="_blank" rel="noopener">Spring Boot整合Prometheus</a>中，详细介绍了SpringBoot如何整合prometheus，在这里就不做详细的说明</p><p>首先，在pom文件引入Micrometer Prometheus的依赖</p><pre><code>&lt;dependency&gt;    &lt;groupId&gt;io.micrometer&lt;/groupId&gt;    &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>然后，在application.properties中进行prometheus的相关配置</p><pre><code>management.endpoint.prometheus.enabled=truemanagement.metrics.export.prometheus.enabled=true</code></pre><p>之后，在prometheus.yml配置采集路径以及采集间隔</p><pre><code>scrape_configs: - job_name: prometheus-test   scrape_interval: 10s   metrics_path: /actuator/prometheus   static_configs:   - targets: [&#39;172.16.22.50:8080&#39;]</code></pre><h2 id="Counter定义"><a href="#Counter定义" class="headerlink" title="Counter定义"></a>Counter定义</h2><p>在<a href="https://prometheus.io/docs/concepts/metric_types/#counter" target="_blank" rel="noopener">prometheus文档</a>中counter的定义如下</p><blockquote><p>A counter is a cumulative metric that represents a single monotonically increasing counter whose value can only increase or be reset to zero on restart</p></blockquote><p>monotonically increasing表示counter的值是单调递增的，cumulative metric表示counter表示的是当前整体的值。</p><p>根据上述定义，我们定义一个counter用来记录http请求数</p><pre><code>@Componentpublic class HttpCounterJob {    private final Counter httpCounter;    public HttpCounterJob(MeterRegistry meterRegistry){        httpCounter = meterRegistry.counter(&quot;http.processed&quot;);    }}</code></pre><p>Micrometer会将metric转化为prometheus的metric，我们可以在prometheus中看到一个名为http_processed_total的metric.其中_total是Micrometer 将Counter metric转为prometheus Counter metric的后缀</p><p>重启项目之后，我们可以在prometheus graph中看到刚刚定义的counter</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20191022175939.png" alt=""></p><p>为了更好的观察counter的逻辑，我们让counter每隔5秒加1</p><pre><code>@Scheduled(fixedDelay = 5000)public void increase(){    httpCounter.increment();}</code></pre><p>随着时间counter的值逐渐递增，我们可以看到counter包含从创建之初到当前时刻所有的值。但是在实际应用中，我们可能并不关心这个整体的值，而是增长趋势</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20191024235750.png" alt=""></p><blockquote><p>counter当前的值并不重要，重要的在一段时间内counter增长的量以及速率，也可以理解为增长趋势</p></blockquote><h2 id="increase"><a href="#increase" class="headerlink" title="increase"></a>increase</h2><p>我们已经知道counter来说，更关注的是在一段时间中增长的量，那么如何获得这个量呢？其实很简单，例如我们想获得最近5分钟增长的量，只需要用counter当前的值减去5分钟前counter的值即可。</p><p>在prometheus中有专门的函数来计算这个值，也就是<strong>increase</strong></p><pre><code>increate(http_processed_total[5m])</code></pre><p>increase的具体用法可以参考<a href="https://prometheus.io/docs/prometheus/latest/querying/functions/#increase" target="_blank" rel="noopener">prometheus 文档</a></p><p>执行上述的语句，我们得到的结果应该为60，因为我们是每隔5s对counter加1，5m内增长的量为5 * 60 /5 = 60, 但是实际上得到的并不是60。这是为什么呢？</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20191024235828.png" alt=""></p><p>根据之前prometheus.yml中配置可知，prometheus每隔10s采集一次，而demon中，counter每隔5s加1，所以对于prometheus采集的值来说是每次加2。假设prometheus从10:30:00开始抓取数据，此时counter的值假设为18，那么可以得到如下的数据</p><pre><code>10:30:00   http_processed_total 1810:30:10   http_processed_total 2010:30:20   http_processed_total 22...10:34:50   http_processed_total 7610:35:00   http_processed_total 7810:35:10   http_processed_total 8010:35:20   http_processed_total 82</code></pre><p>如果我们在10:35:13查询最近5m的数据，可以得到</p><pre><code>10:30:20   http_processed_total 22...10:34:50   http_processed_total 7610:35:00   http_processed_total 7810:35:10   http_processed_total 80</code></pre><p>10:30:10的数据已经超过了5m中，所以取不到，因此value=(80-22)=58，但是实际上prometheus并不会返回这个值。因为<a href="https://prometheus.io/docs/prometheus/latest/querying/functions/#increase" target="_blank" rel="noopener">increase函数</a>会推缺失值并估计边界点的值，<strong>所以prometheus返回的值比我们预想的要更精确，但是却不是最终正确的值</strong>。</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20191025002115.png" alt=""></p><h2 id="rate"><a href="#rate" class="headerlink" title="rate"></a>rate</h2><p>Counter另一个值得关注的值是平均每秒增长的个数，例如在10:30:00 counter的值为10，在10:30:10 counter的值为20，那么平均每秒增长的值为(20 - 10)/10 = 1</p><p>prometheus提供了rate函数来计算这个值</p><pre><code>rate(http_processed_total[5m])</code></pre><p>上述表达式计算的过去5m中平均每秒处理的http请求，如果想知道每分钟处理的http请求数，只要乘以60即可</p><pre><code>rate(http_processed_total[5m]) * 60</code></pre><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20191027222458.png" alt=""></p><p>上图乍一看比较奇怪，因为数值在上下波动，其实是因为Y轴的粒度较细，如果我们将时间区间有5m调整到15m，则可以看到一条直线</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20191027222839.png" alt="">    </p><p>对于rate来说，如果当前时间为t，若计算过去5m的值，那么时间范围就为t - 5m。在上面曲线图中14:17分的值表示[14:16,14:17]这一段时间增长的值，因为range为1m</p><h2 id="aggregation"><a href="#aggregation" class="headerlink" title="aggregation"></a>aggregation</h2><p>上述示例的指标较为简单，但是在实际应用中，一个指标可能存在多个属性。在Micrometer称为tag，而在prometheus中则称为label。以http request为例，一个request我们会关注它的返回code,它的method。我们创建一个名为http.request的metric，它有code和method两个tag</p><pre><code>@Autowiredprivate MeterRegistry meterRegistry;private List&lt;String&gt; methods = Arrays.asList(&quot;GET&quot;,&quot;POST&quot;);private List&lt;Integer&gt; codes = Arrays.asList(200,204,404,500);@Scheduled(fixedDelay = 5000)public void httpRequest(){    meterRegistry.counter(&quot;http.request&quot;,            &quot;method&quot;,getMethod(),            &quot;code&quot;,String.valueOf(getCode())).increment();}private String getMethod(){    return methods.get(ThreadLocalRandom.current().nextInt(methods.size()));}private int getCode(){    return codes.get(ThreadLocalRandom.current().nextInt(codes.size()));}</code></pre><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20191027223807.png" alt=""></p><p>我们之所以可以看到多条查询结果，是因为prometheus为每一个label之间的组合都创建了一个vector，在结合时间，就成了一个时间序列(time series)，在Graph中我们可以看到多条曲线</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20191027224142.png" alt=""></p><p>prometheus允许我们根据label来过滤不同的metric，例如</p><pre><code>http_request_total{code=&quot;200&quot;}</code></pre><p>同时prometheus提供了相应的聚合函数，帮助我们对相同label的metric进行聚合操作，例如</p><pre><code>sum(increase(http_request_total{method=&quot;GET&quot;})) by (code)</code></pre><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20191027224805.png" alt=""></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在第一印象中，我们总是认为Counter是prometheus最简单的一个metric，但实际上它使用起来比想象中要来的复杂。关于Counter我们要记住以下几点</p><ol><li>Counter的当前值意义不大，我们更关注的是Counter在一段时间内增长的数量以及速率</li><li>increase函数可以计算一段时间内增长的值，但是它会对时间边界的值进行估计，因此得到的是一个近似值</li><li>rate函数可以计算一段时间内增长的平均速率</li></ol><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://www.innoq.com/en/blog/prometheus-counters/" target="_blank" rel="noopener">Prometheus Counters and how to deal with them</a></li><li><a href="https://www.innoq.com/en/blog/prometheus-counters/" target="_blank" rel="noopener">Prometheus 官方文档</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 监控 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring Boot整合Prometheus</title>
      <link href="/2019/09/27/spring-boot-zheng-he-prometheus/"/>
      <url>/2019/09/27/spring-boot-zheng-he-prometheus/</url>
      
        <content type="html"><![CDATA[<h2 id="Micrometer简介"><a href="#Micrometer简介" class="headerlink" title="Micrometer简介"></a>Micrometer简介</h2><p>Micrometer 为 Java 平台上的性能数据收集提供了一个通用的 API，应用程序只需要使用 Micrometer 的通用 API 来收集性能指标即可。Micrometer 会负责完成与不同监控系统的适配工作。这就使得切换监控系统变得很容易。Micrometer 还支持推送数据到多个不同的监控系统。Micrometer类似日志系统中SLF4J。</p><p>Micrometer目前支持的监控系统有<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190927204237.png" alt=""></p><p>Micrometer中有两个最核心的概念，分别是是计量器(Meter)和计量器注册表(MeterRegistry),下面来分别看下这两个概念。</p><h3 id="计量器-Meter"><a href="#计量器-Meter" class="headerlink" title="计量器(Meter)"></a>计量器(Meter)</h3><p>Meter用来收集性能指标数据(Metris)，总共有四种类型的Meter，分别是Counter，Gauge，Timer，Summary。</p><p>每个Meter都有自己的名称，同时Meter可以指定一系列的tag。tag是以key-value的形式出现，这样我们就可以根据tag对指标进行过滤。除了每个Meter独有的标签外，也可以通过MeterRegistry添加通用的tag。</p><pre><code>MeterRegistry.Config config = simpleMeterRegistry.config();    config.commonTags(&quot;tag1&quot;,&quot;value1&quot;,&quot;tag2&quot;,&quot;value2&quot;);</code></pre><h4 id="Counter"><a href="#Counter" class="headerlink" title="Counter"></a>Counter</h4><p>Counter只允许增加值，Counter所表示的计数值是double类型，默认情况下增加的值是1.0</p><pre><code>@Autowiredprivate SimpleMeterRegistry simpleMeterRegistry;@Beanpublic Counter counter1(){    return Counter.builder(&quot;test.count1&quot;).register(simpleMeterRegistry);}@Beanpublic Counter counter2(){    return simpleMeterRegistry.counter(&quot;test.count2&quot;);}@Testpublic void test(){    counter1.increment();}</code></pre><h4 id="Gauge"><a href="#Gauge" class="headerlink" title="Gauge"></a>Gauge</h4><p>Cauge是表示单个的变化的值，例如温度，气压。与Counter的区别在于，Gauge的值不总是增加的</p><pre><code>public void guage(){    Gauge.builder(&quot;guaua1&quot;, this::getValue).register(simpleMeterRegistry);}public double getValue(){    return ThreadLocalRandom.current().nextDouble();}</code></pre><p><strong>Gauge对象一旦被创建，就不能手动对其中的值进行修改</strong>。在每次取样时，Gauge 会返回当前值</p><h4 id="Timer"><a href="#Timer" class="headerlink" title="Timer"></a>Timer</h4><p>Timer通常用来记录事件的持续时间。Timer会记录两类的数据，事件的数量和总的持续时间。Timer提供了不同方式来记录持续时间。第一种方式是使用record()方法来记录Runnable和Callable对象的运行时间，第二种方式是使用Timer.Sample来保存计时状态</p><pre><code>public void record(){    Timer timer = simpleMeterRegistry.timer(&quot;record&quot;);    timer.record(() -&gt; {        try {            Thread.sleep(3000);        }catch (Exception e){            e.printStackTrace();        }    });}public void sample(){    Timer.Sample sample = Timer.start();    new Thread(()-&gt;{        try {            Thread.sleep(3000);        }catch (Exception e){            e.printStackTrace();        }        sample.stop(simpleMeterRegistry.timer(&quot;sample&quot;));    });}</code></pre><h4 id="summary"><a href="#summary" class="headerlink" title="summary"></a>summary</h4><p>summary用来记录指标的分布，summary根据每个指标的值，把值分配到对应的bucket中。Micrometer默认的bucket的值从1到Long.MAX_VALUE，可以通过minimumExpectedValue和maximumExpectedValue来控制bucket的范围，如果指标的值较小，还可以通过scale来设置一个值对数值进行放大</p><pre><code>public void summary(){    DistributionSummary summary = DistributionSummary.builder(&quot;summary&quot;)            .maximumExpectedValue(10L)            .minimumExpectedValue(1L)            .publishPercentiles(0.5, 0.75, 0.9)            .register(simpleMeterRegistry);    summary.record(1.0);    summary.record(5.0);    summary.record(4.5);    summary.record(3.0);    System.out.println(summary.takeSnapshot());}</code></pre><h3 id="计量器注册表-MeterRegistry"><a href="#计量器注册表-MeterRegistry" class="headerlink" title="计量器注册表(MeterRegistry)"></a>计量器注册表(MeterRegistry)</h3><p>MeterRegistry负责创建和维护Meter。每一个监控系统有自己独有的registry</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190929095502.png" alt=""></p><p>其中SimpleMeterRegistry是一个基于内存的注册表，它不支持导出数据到监控系统，主要用来进行本地开发和测试。</p><p>Micrometer支持多个不同的监控系统，通过CompositeMeterRegistry可以把多个计量器注册表组合起来，从而允许同时发布数据到多个监控系统中。</p><pre><code>public void compositeRegistry(){        CompositeMeterRegistry compositeMeterRegistry = new CompositeMeterRegistry();        compositeMeterRegistry.add(new SimpleMeterRegistry());        compositeMeterRegistry.add(new SimpleMeterRegistry(new SimpleConfig() {            @Override            public String get(String s) {                return null;            }            //增加前缀            @Override            public String prefix() {                return &quot;simple&quot;;            }        },Clock.SYSTEM));        Counter counter = compositeMeterRegistry.counter(&quot;test&quot;);        counter.increment();    }</code></pre><p>Micrometer本身提供了一个静态的全局注册表Metrics.golbalRegistry。这个注册表一个组合注册表，使用Metrics类中的静态方法创建的计量器，都会被添加到这个全局注册表中</p><pre><code>public void globalRegistry(){    Metrics.addRegistry(simpleMeterRegistry);    Counter global = Metrics.counter(&quot;global&quot;);    global.increment();}</code></pre><h2 id="SpringBoot-Actuator"><a href="#SpringBoot-Actuator" class="headerlink" title="SpringBoot Actuator"></a>SpringBoot Actuator</h2><p>上述介绍了Micrometer的一些简单使用，从Spring Boot2.0开始，Micrometer就是Spring Boot默认提供的性能指标收集库。SpringBoot Actuator提供了对Micrometer的自动配置。在项目中引入SpringBoot Actuator，</p><pre><code>&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>并在配置文件中，增加如下配置</p><pre><code>Actuator可对外默认的服务，*表示显示所有management.endpoints.web.exposure.include=*</code></pre><p>启动项目，访问<a href="http://8080/actuator,就可以看到Actuator提供的所有监控" target="_blank" rel="noopener">http://8080/actuator,就可以看到Actuator提供的所有监控</a></p><pre><code>{  &quot;_links&quot;: {    &quot;self&quot;: {      &quot;href&quot;: &quot;http://localhost:8080/actuator&quot;,      &quot;templated&quot;: false    },    &quot;auditevents&quot;: {      &quot;href&quot;: &quot;http://localhost:8080/actuator/auditevents&quot;,      &quot;templated&quot;: false    },    &quot;beans&quot;: {      &quot;href&quot;: &quot;http://localhost:8080/actuator/beans&quot;,      &quot;templated&quot;: false    },    &quot;caches-cache&quot;: {      &quot;href&quot;: &quot;http://localhost:8080/actuator/caches/{cache}&quot;,      &quot;templated&quot;: true    },    &quot;caches&quot;: {      &quot;href&quot;: &quot;http://localhost:8080/actuator/caches&quot;,      &quot;templated&quot;: false    },    &quot;health&quot;: {      &quot;href&quot;: &quot;http://localhost:8080/actuator/health&quot;,      &quot;templated&quot;: false    },    &quot;health-component&quot;: {      &quot;href&quot;: &quot;http://localhost:8080/actuator/health/{component}&quot;,      &quot;templated&quot;: true    },    &quot;health-component-instance&quot;: {      &quot;href&quot;: &quot;http://localhost:8080/actuator/health/{component}/{instance}&quot;,      &quot;templated&quot;: true    },    &quot;conditions&quot;: {      &quot;href&quot;: &quot;http://localhost:8080/actuator/conditions&quot;,      &quot;templated&quot;: false    },    &quot;configprops&quot;: {      &quot;href&quot;: &quot;http://localhost:8080/actuator/configprops&quot;,      &quot;templated&quot;: false    },    &quot;env&quot;: {      &quot;href&quot;: &quot;http://localhost:8080/actuator/env&quot;,      &quot;templated&quot;: false    },    &quot;env-toMatch&quot;: {      &quot;href&quot;: &quot;http://localhost:8080/actuator/env/{toMatch}&quot;,      &quot;templated&quot;: true    },    &quot;info&quot;: {      &quot;href&quot;: &quot;http://localhost:8080/actuator/info&quot;,      &quot;templated&quot;: false    },    &quot;loggers&quot;: {      &quot;href&quot;: &quot;http://localhost:8080/actuator/loggers&quot;,      &quot;templated&quot;: false    },    &quot;loggers-name&quot;: {      &quot;href&quot;: &quot;http://localhost:8080/actuator/loggers/{name}&quot;,      &quot;templated&quot;: true    },    &quot;heapdump&quot;: {      &quot;href&quot;: &quot;http://localhost:8080/actuator/heapdump&quot;,      &quot;templated&quot;: false    },    &quot;threaddump&quot;: {      &quot;href&quot;: &quot;http://localhost:8080/actuator/threaddump&quot;,      &quot;templated&quot;: false    },    &quot;prometheus&quot;: {      &quot;href&quot;: &quot;http://localhost:8080/actuator/prometheus&quot;,      &quot;templated&quot;: false    },    &quot;metrics&quot;: {      &quot;href&quot;: &quot;http://localhost:8080/actuator/metrics&quot;,      &quot;templated&quot;: false    },    &quot;metrics-requiredMetricName&quot;: {      &quot;href&quot;: &quot;http://localhost:8080/actuator/metrics/{requiredMetricName}&quot;,      &quot;templated&quot;: true    },    &quot;scheduledtasks&quot;: {      &quot;href&quot;: &quot;http://localhost:8080/actuator/scheduledtasks&quot;,      &quot;templated&quot;: false    },    &quot;httptrace&quot;: {      &quot;href&quot;: &quot;http://localhost:8080/actuator/httptrace&quot;,      &quot;templated&quot;: false    },    &quot;mappings&quot;: {      &quot;href&quot;: &quot;http://localhost:8080/actuator/mappings&quot;,      &quot;templated&quot;: false    }  }}</code></pre><p>访问<a href="http://localhost:8080/actuator/metrics，可以看到Actuator默认收集的监控指标，包括JVM相关指标(内存使用，垃圾收集)，tomcat相关指标，数据库连接池还是系统相关指标" target="_blank" rel="noopener">http://localhost:8080/actuator/metrics，可以看到Actuator默认收集的监控指标，包括JVM相关指标(内存使用，垃圾收集)，tomcat相关指标，数据库连接池还是系统相关指标</a></p><pre><code>{  &quot;names&quot;: [    &quot;jvm.memory.max&quot;,    &quot;jvm.threads.states&quot;,    &quot;process.files.max&quot;,    &quot;jvm.gc.memory.promoted&quot;,    &quot;system.load.average.1m&quot;,    &quot;jvm.memory.used&quot;,    &quot;jvm.gc.max.data.size&quot;,    &quot;jvm.gc.pause&quot;,    &quot;jvm.memory.committed&quot;,    &quot;system.cpu.count&quot;,    &quot;logback.events&quot;,    &quot;tomcat.global.sent&quot;,    &quot;jvm.buffer.memory.used&quot;,    &quot;tomcat.sessions.created&quot;,    &quot;jvm.threads.daemon&quot;,    &quot;system.cpu.usage&quot;,    &quot;jvm.gc.memory.allocated&quot;,    &quot;tomcat.global.request.max&quot;,    &quot;tomcat.global.request&quot;,    &quot;tomcat.sessions.expired&quot;,    &quot;jvm.threads.live&quot;,    &quot;jvm.threads.peak&quot;,    &quot;tomcat.global.received&quot;,    &quot;process.uptime&quot;,    &quot;tomcat.sessions.rejected&quot;,    &quot;process.cpu.usage&quot;,    &quot;http.server.requests&quot;,    &quot;tomcat.threads.config.max&quot;,    &quot;jvm.classes.loaded&quot;,    &quot;jvm.classes.unloaded&quot;,    &quot;tomcat.global.error&quot;,    &quot;tomcat.sessions.active.current&quot;,    &quot;tomcat.sessions.alive.max&quot;,    &quot;jvm.gc.live.data.size&quot;,    &quot;tomcat.threads.current&quot;,    &quot;process.files.open&quot;,    &quot;jvm.buffer.count&quot;,    &quot;jvm.buffer.total.capacity&quot;,    &quot;tomcat.sessions.active.max&quot;,    &quot;tomcat.threads.busy&quot;,    &quot;process.start.time&quot;  ]}</code></pre><p>我们可以通过以下链接来查看具体某个指标</p><pre><code>http://localhost:8080/actuator/metrics/metricName</code></pre><p>其中metricName为需要查看指标的名称，例如查看jvm内存</p><pre><code> http://localhost:8080/actuator/metrics/jvm.memory.used</code></pre><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190929110225.png" alt=""></p><p>从上图中我们可以看到jvm.memory.used有两个tag，area和id，area指定内存位置(堆内存和非堆内存)，id指定内存分类，我们可以指定tag来查看更细致的指标</p><pre><code>http://localhost:8080/actuator/metrics/jvm.memory.used?tag=area:heaphttp://localhost:8080/actuator/metrics/jvm.memory.used?tag=area:heap&amp;tag=id:PS%20Eden%20Space</code></pre><h2 id="Prometheus"><a href="#Prometheus" class="headerlink" title="Prometheus"></a>Prometheus</h2><p>Micrometer支持Prometheus，Micrometer提供PrometheusMeterRegistry注册表，用于将指标转为Prometheus格式的指标。首先需要在pom文件引入依赖</p><pre><code>&lt;dependency&gt;    &lt;groupId&gt;io.micrometer&lt;/groupId&gt;    &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>其次在配置文件中，配置暴露Prometheus，并允许将指标导入到Prometheus中</p><pre><code>management.endpoint.prometheus.enabled=truemanagement.metrics.export.prometheus.enabled=true</code></pre><p>项目启动后，我们访问<a href="http://localhost:8080/actuator/prometheus，可以看到指标以变成Prometheus格式的指标" target="_blank" rel="noopener">http://localhost:8080/actuator/prometheus，可以看到指标以变成Prometheus格式的指标</a><br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190929113443.png" alt=""></p><p>可以安装Prometheus来采集这些指标</p><pre><code>docker run -d -p 9090:9090 -v ~/Documents/config/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus</code></pre><p>其中prometheus.yml配置了采集地址及路径</p><pre><code>scrape_configs: - job_name: prometheus-test   metrics_path: /actuator/prometheus   static_configs:   - targets: [&#39;172.16.22.50:8080&#39;]</code></pre><p>172.16.22.50是我本机的地址，你们可以修改为自己的ip地址即可，访问<a href="http://localhost:9090/targets可以看到Prometheus采集配置" target="_blank" rel="noopener">http://localhost:9090/targets可以看到Prometheus采集配置</a><br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190929135104.png" alt=""></p><h2 id="自定义Metric"><a href="#自定义Metric" class="headerlink" title="自定义Metric"></a>自定义Metric</h2><p>我们可以利用Prometheus client自定义metric</p><pre><code>package com.wbl.spingbootdemo.prometheus;import io.prometheus.client.CollectorRegistry;import io.prometheus.client.Counter;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import javax.annotation.PostConstruct;/** * @author wbl * @date 2019-09-29 */@Servicepublic class PrometheusMeter {    @Autowired    private CollectorRegistry collectorRegistry;    // 定义name为prometheus_counter的counter    public Counter prometheusCounter(){        return Counter.build().name(&quot;prometheus_counter&quot;).help(&quot;prometheus counter test&quot;)                .register(collectorRegistry);    }    @PostConstruct    public void init(){        Counter counter = prometheusCounter();        new Thread(()-&gt; {            while (true){                counter.inc();                try {                    Thread.sleep(5000);                } catch (InterruptedException e) {                    e.printStackTrace();                }            }        }).start();    }}</code></pre><p>启动项目之后，可以在Prometheus查询页面看到刚刚定义的指标prometheus_counter</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190929135241.png" alt=""></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>Micrometer整合了多个监控系统，包括Prometheus。Micrometer利用Meter收集数据，利用不同的MeterRegistry与不同的监控系统整合</li><li>SpringBoot Actuator集成了Micrometer，定义了许多默认的metric，可以在<a href="http://localhost:8080/actuator/metrics查看" target="_blank" rel="noopener">http://localhost:8080/actuator/metrics查看</a></li><li>SpringBoot Actuator可以通过Micrometer将采集的指标导入到Prometheus中</li></ol><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="http://micrometer.io/docs" target="_blank" rel="noopener">Micrometer</a></li><li><a href="https://www.baeldung.com/micrometer" target="_blank" rel="noopener">Quick Guide to Micrometer</a></li><li><a href="https://mucahit.io/2018/08/27/instrumenting-and-monitoring-spring-boot-2-applications/" target="_blank" rel="noopener">Instrumenting And Monitoring Spring Boot 2 Applications</a></li><li><a href="http://ylzheng.com/2018/01/24/use-prometheus-monitor-your-spring-boot-application/" target="_blank" rel="noopener">自定义Metrics：让Prometheus监控你的应用程序</a></li><li><a href="https://www.ibm.com/developerworks/cn/java/j-using-micrometer-to-record-java-metric/index.html" target="_blank" rel="noopener">使用 Micrometer 记录 Java 应用性能指标</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Spring Boot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Boot </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Redis cache with Spring Boot</title>
      <link href="/2019/09/12/redis-cache-with-spring-boot/"/>
      <url>/2019/09/12/redis-cache-with-spring-boot/</url>
      
        <content type="html"><![CDATA[<p>Spring Boot支持使用redis作为cache缓存，下面会详细介绍具体的用法</p><h2 id="maven-依赖"><a href="#maven-依赖" class="headerlink" title="maven 依赖"></a>maven 依赖</h2><pre><code>    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt;    &lt;/dependency&gt;</code></pre><h2 id="简单示例"><a href="#简单示例" class="headerlink" title="简单示例"></a>简单示例</h2><p>在使用redis作为cache之前，首先需要在Application中增加注解<strong>@EnableCaching</strong></p><pre><code>@SpringBootApplication@EnableCachingpublic class Application{    public static void main(String[] args) {        SpringApplication springApplication = new SpringApplication(Application.class);        springApplication.run(args);    }}</code></pre><p>使用@Cacheable注解来表示使用cache</p><pre><code>@Slf4j@Servicepublic class CacheService {    @Cacheable(cacheNames = &quot;myCache&quot;)    public String cacheThis(){        log.info(&quot;Returning NOT from cache!&quot;);        return &quot;this Is it&quot;;    }}</code></pre><p>测试下cache的效果</p><pre><code>@Testpublic void run() throws Exception {    String firstString = cacheService.cacheThis();    log.info(&quot;First: {}&quot;, firstString);    String secondString = cacheService.cacheThis();    log.info(&quot;Second: {}&quot;, secondString)}</code></pre><p>在测试之前需要启动本地的redis，因为spring boot会将cache的值保持在redis中</p><pre><code>spring.redis.host=localhostspring.redis.port=6379</code></pre><p>运行测试用例可以看到如下结果<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190919193624.png" alt=""></p><p>此时连接到redis上，可以看到刚刚创建的cache</p><pre><code>redis-cli127.0.0.1:6379&gt; keys *myCache::SimpleKey []127.0.0.1:6379&gt; get &quot;myCache::SimpleKey []&quot;&quot;\xac\xed\x00\x05t\x00\nthis is it&quot;</code></pre><p>我们发现value的值有乱码，这个问题我们先放下，在后面会详细说明</p><p>通过上诉的例子，我们简单地了解了spring boot如何整合redis作为cache</p><h2 id="Cache的写入与读取"><a href="#Cache的写入与读取" class="headerlink" title="Cache的写入与读取"></a>Cache的写入与读取</h2><h3 id="Cacheable"><a href="#Cacheable" class="headerlink" title="@Cacheable"></a>@Cacheable</h3><p>根据方法的请求参数对其结果进行缓存，如果缓存存在，则直接返回缓存结果，如果不存在，则执行实际的方法。</p><table><thead><tr><th>name</th><th>explain</th></tr></thead><tbody><tr><td>cacheName</td><td>cache的名称</td></tr><tr><td>value</td><td>cacheName的别名，也表示cache的名称</td></tr><tr><td>key</td><td>可以用spel表示式，对应redis中key</td></tr><tr><td>keyGenerator</td><td>对应于生成key的bean</td></tr><tr><td>condition</td><td>可以用spel表达式，当返回为true时，则进行缓存</td></tr><tr><td>unless</td><td>可以用spel表达式，当返回为true时，则不进行缓存</td></tr></tbody></table><pre><code>/*** 当参数的长度大于3时才进行缓存，并且key的格式为参数加上后缀_condition**/     @Cacheable(cacheNames = &quot;cache1&quot;,condition = &quot;#value.length() &gt; 3&quot;,key = &quot;#value.concat(&#39;_condition&#39;)&quot;)    public String cacheCondition(String value){        return &quot;test cache condition&quot;;    }    @Override    public void run(String... args) throws Exception {        // 参数长度小于3，不进行缓存        cacheService.cacheCondition(&quot;a&quot;);        // 参数长度大于3，进行缓存，且key为test_condition        cacheService.cacheCondition(&quot;test&quot;);    }    </code></pre><p>运行上述例子，可以看到redis的key只有一个</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190922150815.png" alt=""></p><h3 id="CachePut"><a href="#CachePut" class="headerlink" title="@CachePut"></a>@CachePut</h3><p>根据方法的请求参数对其结果进行缓存，<strong>和 @Cacheable 不同的是，它每次都会触发真实方法的调用</strong></p><pre><code>    @CachePut(cacheNames = &quot;cache2&quot;,key = &quot;#value&quot;)    public String cachePut(String value){        log.info(&quot;Returning NOT from cache!&quot;);        return value;    }    @Override    public void run(String... args) throws Exception {        cacheService.cachePut(&quot;a&quot;);        cacheService.cachePut(&quot;b&quot;);    }</code></pre><p>运行上述例子，可以看到Returning NOT from cache!打印了两次，表示@CachePut不会使用缓存结果，每次都重新生成缓存值</p><h2 id="清除Cache"><a href="#清除Cache" class="headerlink" title="清除Cache"></a>清除Cache</h2><p>@CacheEvict可以根据一定的条件清空缓存</p><pre><code>    @CacheEvict(cacheNames = &quot;cache2&quot;, key = &quot;#value&quot;)    public void cacheEvict(String value){    }    @Override    public void run(String... args) throws Exception {        cacheService.cacheEvict(&quot;a&quot;);    }</code></pre><p>在运行示例前，redis中存在的key如下</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190922153756.png" alt=""></p><p>执行完毕后，a的缓存被清空，redis中存在的key如下</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190922153900.png" alt=""></p><h2 id="Cache-key的管理"><a href="#Cache-key的管理" class="headerlink" title="Cache key的管理"></a>Cache key的管理</h2><p>spring boot默认生成的cache key一般的比较长，也不好理解，所以一般我们都会自己定义cache key的生成。</p><p>cache相关的注解中，都有两个参数key，keyGenerator，都可以用来控制cache key的生成</p><p>key使用spel表示式</p><pre><code> public String getCacheKey(String key){        return &quot;my_cache_&quot; + key;    }    //从getCacheKey方法中获取key    @Cacheable(cacheNames = &quot;myCache&quot;, key = &quot;cacheService.getCacheKey(&#39;test&#39;)&quot;)    public String cacheThis(){        log.info(&quot;Returning NOT from cache!&quot;);        return &quot;this is it&quot;;    }</code></pre><p>keyGenerator对应于实现了org.springframework.cache.interceptor.KeyGenerator的bean</p><pre><code>public interface KeyGenerator {    /**     * Generate a key for the given method and its parameters.     * @param target the target instance     * @param method the method being called     * @param params the method parameters (with any var-args expanded)     * @return a generated key     */    Object generate(Object target, Method method, Object... params);}</code></pre><pre><code>@Servicepublic class MyCacheKeyGenerator implements KeyGenerator {    @Override    public Object generate(Object target, Method method, Object... params) {        //若参数不为空，则将第一个参数作为key        return params == null ? &quot;[]&quot;: params[0];    }}@Cacheable(cacheNames = &quot;cache4&quot;,keyGenerator = &quot;myCacheKeyGenerator&quot;)public String keyGeneratorCache(String value){    return value;}@Overridepublic void run(String... args) throws Exception {    cacheService.keyGeneratorCache(&quot;bbbb&quot;);}</code></pre><p>运行上述示例可以redis生成了如下的key</p><pre><code>127.0.0.1:6379&gt; keys *1) &quot;cache4::bbbb&quot;</code></pre><h2 id="过期时间"><a href="#过期时间" class="headerlink" title="过期时间"></a>过期时间</h2><p>每一个cache可以设置一个过期时间，同时也可以设置一个全局的过期时间，即默认的过期时间</p><ol><li>cache配置</li></ol><pre><code>@ConfigurationProperties(prefix = &quot;cache&quot;)@Datapublic class CacheConfigurationProperties {    private long timeoutSeconds = 60;    private int redisPort = 6379;    private String redisHost = &quot;localhost&quot;;    /**     * key: cache 名称     * value：过期时间，单位为秒     */    private Map&lt;String, Long&gt; cacheExpirations = new HashMap&lt;&gt;();}</code></pre><p>@ConfigurationProperties(prefix = “cache”)表示从配置文件中读取前缀为cache的配置。cacheExpirations可以保存每一个cache的过期时间</p><ol start="2"><li>根据property生成对应的cache配置</li></ol><pre><code>@Configuration@EnableConfigurationProperties(CacheConfigurationProperties.class)public class CacheConfig extends CachingConfigurerSupport {    /**     * 生成RedisCacheConfiguration，并设置过期时间     * @param timeoutInSeconds 过期时间     * @return     */    private static RedisCacheConfiguration createCacheConfiguration(long timeoutInSeconds) {        return RedisCacheConfiguration.defaultCacheConfig()                .entryTtl(Duration.ofSeconds(timeoutInSeconds))                .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer()));    }    /**     * 根据配置生成RedisCacheConfiguration     * @param properties cache配置     * @return     */    @Bean    public RedisCacheConfiguration cacheConfiguration(CacheConfigurationProperties properties) {        return createCacheConfiguration(properties.getTimeoutSeconds());    }    @Bean    public RedisTemplate&lt;String, String&gt; redisTemplate(RedisConnectionFactory cf) {        RedisTemplate&lt;String, String&gt; redisTemplate = new RedisTemplate&lt;String, String&gt;();        redisTemplate.setConnectionFactory(cf);        redisTemplate.setKeySerializer(new StringRedisSerializer());        redisTemplate.setValueSerializer(new StringRedisSerializer());        return redisTemplate;    }    /**     * 根据配置生成CacheManager     * @param redisConnectionFactory redis连接配置     * @param properties cache配置文件     * @return     */    @Bean    public CacheManager cacheManager(RedisConnectionFactory redisConnectionFactory, CacheConfigurationProperties properties) {        Map&lt;String, RedisCacheConfiguration&gt; cacheConfigurations = new HashMap&lt;&gt;();        /**         * 从配置文件中读取每一个cache的过期时间，并生成对应的RedisCacheConfiguration         */        for (Map.Entry&lt;String, Long&gt; cacheNameAndTimeout : properties.getCacheExpirations().entrySet()) {            cacheConfigurations.put(cacheNameAndTimeout.getKey(), createCacheConfiguration(cacheNameAndTimeout.getValue()));        }        return RedisCacheManager                .builder(redisConnectionFactory)                .cacheDefaults(cacheConfiguration(properties))                .withInitialCacheConfigurations(cacheConfigurations).build();    }}</code></pre><ol start="3"><li>在property文件中设置过期时间</li></ol><pre><code>#默认过期时间cache.timeoutSeconds=60#cache名称为cache5的过期时间cache.cacheExpirations.cache5=180</code></pre><ol start="4"><li>测试</li></ol><pre><code>@Cacheable(cacheNames = &quot;cache5&quot;)public String expireTimeCache(String value){    return value;} @Overridepublic void run(String... args) throws Exception {    cacheService.keyGeneratorCache(&quot;bbbb&quot;);    cacheService.expireTimeCache(&quot;eeee&quot;);}    </code></pre><p>运行上述示例，可以看到redis中有两个key</p><pre><code>127.0.0.1:6379&gt; keys *1) &quot;cache5::eeee&quot;2) &quot;cache4::bbbb&quot;127.0.0.1:6379&gt; ttl cache5::eeee(integer) 173127.0.0.1:6379&gt; ttl cache4::bbbb(integer) 49</code></pre><p>其中cache5::eeee的过期时间为180，而cache4::bbbb的过期时间为60</p><h2 id="关于乱码"><a href="#关于乱码" class="headerlink" title="关于乱码"></a>关于乱码</h2><p>在最初的示例中，value的值总会出现乱码，这是因为cache value默认的序列化策略为SerializationPair<object></object></p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190923230603.png" alt=""></p><p>为了解决乱码问题，只需要自己指定相应的序列化策略即可</p><pre><code>private static RedisCacheConfiguration createCacheConfiguration(long timeoutInSeconds) {        return RedisCacheConfiguration.defaultCacheConfig()                .entryTtl(Duration.ofSeconds(timeoutInSeconds))                // 指定value的序列化策略                .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer()));    }</code></pre><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://www.iteye.com/blog/rickgong-2414263" target="_blank" rel="noopener">SpringBoot2.0的CacheManager配置</a></li><li><a href="https://www.concretepage.com/spring-boot/spring-boot-redis-cache" target="_blank" rel="noopener">Home  &gt;  Spring Boot<br>Spring Boot Redis Cache</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Spring Boot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Boot </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>计算机编码</title>
      <link href="/2019/08/19/ji-suan-ji-bian-ma/"/>
      <url>/2019/08/19/ji-suan-ji-bian-ma/</url>
      
        <content type="html"><![CDATA[<p>在计算机中，整数有两种类型的编码，一种只能表示非负数，即无符号编码，另外一种可以表示负数，即有符号编码。</p><p>在C语言中支持有符号数和无符号数，而Java只支持有符号数，下面就来看下它们是如何编码的。</p><h2 id="无符号数编码"><a href="#无符号数编码" class="headerlink" title="无符号数编码"></a>无符号数编码</h2><p>假设一个整数用二进制表示的话有w位，[Xw-1,Xw-2,….,X0]，那么用函数B2U(Binary to Unsigned)表示无符号数，则</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190824221223.png" alt=""></p><pre><code>B2U([0001]) = 0 * 2^3 + 0 * 2^2 + 0 * 2^1 + 1 * 2^1 = 0 + 0 + 0 + 0 = 1B2U([0101]) = 0 * 2^3 + 1 * 2^2 + 0 * 2^1 + 1 * 2^1 = 0 + 4 + 0 + 0 = 5</code></pre><p>下面我们来看下无符号数的范围，对于w为的无符号数，它的最小值就是[000000…000]，也就是0，对于最大值就是[1111…111]，也就是2^w-1</p><p>以w为4为例</p><pre><code>B2Umax = 2^4 - 1 = 15B2Umin = 0</code></pre><h2 id="有符号数编码"><a href="#有符号数编码" class="headerlink" title="有符号数编码"></a>有符号数编码</h2><h3 id="补码"><a href="#补码" class="headerlink" title="补码"></a>补码</h3><p>补码(two’s-complement)是最常见的有符号数编码，在补码中，符号的最高位表示负权，如果用函数B2T(Binary to Two’s-complement)表示,则</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190824222440.png" alt=""></p><p>最高位Xw-1也称为符号位，它的权重为-2^w-1，所以当符号位被设置为1时，表示值为负，当被设置为0时，值为非负</p><pre><code>B2T([0001]) = -0 * 2^3 + 0 * 2^2 + 0 * 2^1 + 1 * 2^1 = 0 + 0 + 0 + 0 = 1B2T([1001]) = -1 * 2^3 + 0 * 2^2 + 0 * 2^1 + 1 * 2^1 = -8 + 0 + 0 + 1 = -7</code></pre><p>下面来看下补码所能表示的范围。对于补码来说，它的最小值为[1000…00]，也就是最高位设置为负权，同时清除其他为0，而最大值为[0111..11]，清除负权，其他值设置为1.</p><pre><code>Tmin = -2^(w-1)Tmax = 1 * 2^(w-2) + 1 * 2^(w-3) + ... + 1 * 2^0 = 2^(w-1) - 1</code></pre><p>以w为4为例</p><pre><code>Tmax = - 2^(4-1) = -8Tmin = 2^(w-1) - 1 = 7</code></pre><h3 id="反码"><a href="#反码" class="headerlink" title="反码"></a>反码</h3><p>反码(one’s complement)，除了最高位的权是-(2^(w-1) - 1)，而不是-2^(w-1)，其他和补码一样</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190824225808.png" alt=""></p><p>可以看到当Xw-1=0时，反码也补码一致，也就是对于正整数，反码和补码一直，而当Xw-1=1，也就是负数时，反码比补码大1，</p><h3 id="原码"><a href="#原码" class="headerlink" title="原码"></a>原码</h3><p>原码(sign-magnitude),最高位是符号位，用来决定剩下的位应该是负权还是正权</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190824225325.png" alt=""></p><p>在原码和反码中，0都有两种表示方式。它们都把[000…000]解释为+0，而-0在原码中表示[1000…000],而在反码中表示[1111…11]</p><h2 id="无符号数与有符号数转换"><a href="#无符号数与有符号数转换" class="headerlink" title="无符号数与有符号数转换"></a>无符号数与有符号数转换</h2><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190824231111.png" alt=""></p><p>补码转为无符号数<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190824231815.png" alt=""></p><p>无符号数转为补码<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190824231942.png" alt=""></p><p>例如</p><pre><code>T2U16(-12345) = -12345 + 2 ^ 16 = 53191U2T16(53191) = 53191 - 2 ^ 16 = -12345</code></pre><p>也就是16进制0xCFC7既是-12345的补码表示，也是53191的无符号数表示</p>]]></content>
      
      
      <categories>
          
          <category> 计算机基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机系统 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分布式锁</title>
      <link href="/2019/08/11/fen-bu-shi-suo/"/>
      <url>/2019/08/11/fen-bu-shi-suo/</url>
      
        <content type="html"><![CDATA[<h2 id="分布式锁的应用场景"><a href="#分布式锁的应用场景" class="headerlink" title="分布式锁的应用场景"></a>分布式锁的应用场景</h2><p>为什么需要用到分布式锁呢？在讨论这个问题之前，我们先看下一个业务场景：</p><p>系统A是一个电商系统，目前是一台机器部署，系统中有一个用户下订单的接口，但是用户下订单之前一定要去检查一下库存，确保库存足够了才会给用户下单。</p><p>由于系统有一定的并发，所以会预先将商品的库存保存在redis中，用户下单的时候会更新redis的库存，此时系统架构如下：</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190811144210.png" alt=""></p><p>但是这样会存在一个问题：假如某个时刻，redis里面某个商品库存为1，此时两个请求同时到来，其中一个请求执行到上图中的第三步，更新数据库的库存为0，但是第四步还没有执行。</p><p>而另外一个请求执行到第二步，发现库存还是1，就继续执行第三步。</p><p>这样的结果，将会导致卖出了2个商品，然而库存其实只有一个。这就是典型的<strong>超卖问题</strong>。</p><p>此时我们很容易想到解决方案：用锁把2，3，4锁住，让他们执行完之后，另一个线程才能进来执行第二步。</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190811144724.png" alt=""></p><p>按照上图，在执行第二步，使用Java提供的synchronized或者ReentrantLock来锁住，然后在第四步执行完之后才释放锁。</p><p>这样2，3，4这三个步骤就被锁住了，多个线程之间只能串行化执行。</p><p>但是随着整个系统并发飙升，一台机器扛不住了，现在增加一个机器，如下图：</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190811145042.png" alt=""></p><p>假设此时两个用户的请求同时到来，但是落在了不同的机器上，那么这两个请求是可以同时执行的，还是会出现超卖问题。</p><p>原因就是因为对于上图的两个A系统，运行在两个不同的JVM里面，他们加的锁只对属于自己JVM里面的线程有效，对于其他JVM的线程是无效的。也即<strong>Java提供的原生锁机制在多机部署场景下失效了</strong></p><p>那么如何解决这个问题呢？方案其实很简单，只要我们保证两台机器加的锁是同一个锁就可以了。</p><p>所以就有了分布式锁的用武之地了，分布式锁的思路是：</p><blockquote><p>在整个系统中提供一个全局，唯一的获取锁的”东西”，然后在每个系统加锁时，都去这个”东西”拿到一把锁，这样不同系统拿到的就可以认为是同一把锁</p></blockquote><p>至于这个东西，可以是MySQL，Redis或者zookeeper，也即分布式锁不同的实现方式</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190811150010.png" alt=""></p><h2 id="分布式锁的特点"><a href="#分布式锁的特点" class="headerlink" title="分布式锁的特点"></a>分布式锁的特点</h2><p>上面分析了为啥需要使用分布式锁，那么在讲如何实现分布式锁之前，我们首先需要明确分布式锁需要满足的一些特性</p><ul><li>互斥性：和原生锁一样，互斥性是最基本的，只不过分布式锁需要保证的是在<strong>不同节点的不同线程</strong>中保持互斥性</li><li>可重入性：同一个节点上的同一个线程如果获取了锁之后，那么也可以再次获得这个锁</li><li>锁超时：防止死锁</li><li>高效，高可用：加锁和解锁需要高效，同时也需要保证高可用防止分布式锁失效</li><li>支持阻塞和非阻塞：和ReentrantLock一样支持lock和trylock<h2 id="基于MySQL实现分布式锁"><a href="#基于MySQL实现分布式锁" class="headerlink" title="基于MySQL实现分布式锁"></a>基于MySQL实现分布式锁</h2><h3 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h3>在数据库中创建一张锁表，通过操作该表中的数据来实现</li></ul><p>当需要锁住某个资源时，就在表中增加一条记录，想要释放锁就删除这条记录</p><pre><code>CREATE TABLE `resourceLock` (  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &#39;主键&#39;,  `resource_name` varchar(64) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;资源名称&#39;,  `node_info` varchar(128) DEFAULT NULL COMMENT &#39;机器名称&#39;,  `count` int(11) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;锁的次数&#39;  `desc` varchar(1024) NOT NULL DEFAULT &#39;备注信息&#39;,  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#39;保存数据时间，自动生成&#39;,  `create_time` timestamp NOT NULL DEFAULT NULL COMMENT &#39;创建时间&#39;  PRIMARY KEY (`id`),  UNIQUE KEY `uidx_resource` (`resource_name `)) ENGINE=InnoDB DEFAULT CHARSET=utf8;</code></pre><p>当我们需要锁住某个资源，执行以下SQL</p><pre><code>insert into resourceLock(resource_name,count,create_time) values(&#39;name&#39;,1,&#39;timestamp&#39;)</code></pre><p>由于对resource_name做了唯一性约束，如果有多个请求同时提交到数据库，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该资源的锁。</p><p>当方法执行完毕之后，想要释放锁，需要判断count是否大于1，大于1则count减1，否者则删除这条记录</p><pre><code>delete from resourceLock where resource_name = &#39;xxx&#39;</code></pre><p>前面分析过分布式锁需要满足几个特性，那么我们来看下，上述实现是否都满足</p><ol><li>互斥性：通过数据库的唯一性约束来实现</li><li>锁超时：数据库自身无法提供这个功能，需要起一个定时任务，每隔一定时间把数据库中超时数据删除</li><li>可重入性：字段count自己了锁的次数，已获得锁的线程只要把count+1即可再次获得锁</li><li>非阻塞：设置一个while循坏，直到insert成功在返回</li></ol><p>下面看下几个操作的伪代码实现</p><h3 id="lock"><a href="#lock" class="headerlink" title="lock"></a>lock</h3><p>lock一般是阻塞的，也就意味着会一直尝试获得锁，直到成功为止</p><pre><code>public void lock(){    while(true){        if(mysqlLock.lock(resouce)){            return;        }        //休眠一段时间之后在重试        sleep(3)    }}</code></pre><p>下面是mysqlLock.lock的实现，为了实现可重入性，需要判断node_info是否一致，如果一致，则count+1，如果不一致则返回false，如果不存在，则直接插入一条数据。上述这些操作需要在一个事务中</p><pre><code>@Transcationpublic boolean lock(){    // 节点是否存在    if(select * from resourceLock where resource_name=&#39;xx&#39; for update){        //节点信息是否一致        if(currentNodeInfo == resultNodeInfo){            update resourceLock set count = count + 1 where resource_name = &#39;xx&#39;            return true;        }else{            return false;        }    }else{        //插入新数据        insert into resourceLock    }}</code></pre><h3 id="unlock"><a href="#unlock" class="headerlink" title="unlock"></a>unlock</h3><p>如果count为1可以直接删除，如果大于1则减1</p><pre><code>@Transcationpublic boolean unlock(){    if(select * from resourceLock where resource_name=&#39;xx&#39; for update){        if(currentNodeInfo == resultNodeInfo){            if(count &gt; 1){                update count = count - 1                return true            }else{                delete from resourceLock where resource_name=&#39;xx&#39;                return true            }        }else{            return false;        }    }else{        return false;    }}</code></pre><h2 id="基于Redis实现分布式锁"><a href="#基于Redis实现分布式锁" class="headerlink" title="基于Redis实现分布式锁"></a>基于Redis实现分布式锁</h2><h3 id="实现原理-1"><a href="#实现原理-1" class="headerlink" title="实现原理"></a>实现原理</h3><p>使用redis实现分布式锁时，如果设置了一个值表示了加锁，然后释放锁，就把这个key删除</p><pre><code>//获取锁//NX表示如果key不存在才创建key，若存在则直接返回false，PX指定了key的过期时间SET anyLock unique_value NX PX ms//释放锁：通过执行一段lua脚本//释放锁涉及到两条指令，这两条指令不是原子性的//redis执行lua脚本是原子性的if redis.call(&quot;get&quot;, KEYS[1] == ARGV[1]) then    return redis.call(&quot;del&quot;, KEYS[1])else    return 0end    </code></pre><p>上述实现方式有几个注意点</p><ol><li>一定要用SET key value NX PX milliseconds 命令，也即要保证设置值和过期时间这两个操作一起执行。如果先设置了值，在设置过期时间，这个不是原子性操作，有可能在设置过期时间之前机器宕机，则key会永久存在，造成死锁。</li><li><p>value要具有一致性</p><p> 这个是为了在解锁时，需要验证value和加锁一致才删除key。这是为了避免一种情况，假设A获取了锁，过期时间为30s，此时35s之后，锁已经自动释放了，A去释放锁，但是此时B可能获得了锁，那么A就不能删除B的锁了</p></li></ol><h3 id="RedLock"><a href="#RedLock" class="headerlink" title="RedLock"></a>RedLock</h3><p>使用redis实现分布式锁，还有需要特别考虑到redis的部署方式，因为这关系到分布式锁的高可用</p><p>redis有三种部署方式：</p><ul><li>单机模式</li><li>master-slave + sentinel选举模式</li><li>redis cluster模式</li></ul><p>如果采用单机部署模式，会存在单点问题，只要redis挂了，加锁就会失败</p><p>如果采用master-slave，加锁的时候就只对一个节点加锁，即使通过sentinel做了高可用，但是如果master节点挂了，发生主从切换，此时就有可能出现所丢失的问题</p><p>基于以上的考虑，redis作者提出了一个RedLock的算法：</p><p>假设redis的部署模式是redis cluster，总共有5个master节点，通过以下步骤来获取一把锁</p><ol><li>获取当前时间戳，单位是毫秒</li><li>轮流尝试在每个master节点上创建锁，过期时间设置较短，一般就几十毫秒</li><li>尝试在大多数节点建立锁，比如5个节点就要求是3个节点(n/2+1)</li><li>客户端计算好建锁的时间，如果建立锁的时间小于超时时间，则建立成功。例如超时时间为5ms，在第一个节点建锁就耗时5ms，那么建锁也就失败了</li><li>要是建锁失败，则依次删除这个锁</li><li>只要别人建立了一把分布式锁，需要不断轮询去尝试获取锁</li></ol><h3 id="Redisson"><a href="#Redisson" class="headerlink" title="Redisson"></a>Redisson</h3><p>Redisson是基于redis实现分布式锁的一个开源框架，封装了底层细节，使用起来非常方便</p><pre><code>Config config = new Config();config.useClusterServers().addNodeAddress(&quot;redis://192.168.31.101:7001&quot;)    .addNodeAddress(&quot;redis://192.168.31.101:7002&quot;)    .addNodeAddress(&quot;redis://192.168.31.101:7003&quot;)    .addNodeAddress(&quot;redis://192.168.31.102:7001&quot;)    .addNodeAddress(&quot;redis://192.168.31.102:7002&quot;)    .addNodeAddress(&quot;redis://192.168.31.102:7003&quot;);RedissonClient redisson = Redisson.create(config);RLock lock = redisson.getLock(&quot;anyLock&quot;);lock.lock();lock.unlock();</code></pre><p>我们只需要通过使用api中的lock和unlock就可以完成分布式锁，它帮我们考虑了很多细节</p><ul><li>redisson所有指令都通过lua脚本执行，redis支持lua脚本原子性执行</li><li><p>redisson设置一个key的默认过期时间为30s，如果某个客户端持有一个锁超过30s，会有什么问题</p><p>  假设业务超过30s都没有完成业务逻辑，key会过期，其他线程有可能会获取到锁。redisson有一个watchdog的概念，它会在你获取到锁之后，每隔10s帮你把key的超时时间设为30s。这样的话，就算一直持有锁也不会出现key过期，其他线程获取到锁的问题了。</p></li><li><p>redisson的watchdog机制保证了没有死锁发生</p><p>  如果机器宕机了，watchdog也没有了，此时就不会延长key的过期时间，到了30s之后锁就会自动过期</p></li></ul><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190811163753.png" alt="">        </p><h2 id="基于Zookeeper实现分布式锁"><a href="#基于Zookeeper实现分布式锁" class="headerlink" title="基于Zookeeper实现分布式锁"></a>基于Zookeeper实现分布式锁</h2><p>首先来看下zk的模型：zk包含一系列的节点，叫做znode，就好像文件系统一样，每个znode表示一个目录，然后znode有一些特性</p><ul><li><p>有序节点：假如当前有个父节点为/lock,我们可以在父节点下创建子节点</p><p>  zookeeper提供了可选的有序特性，例如我们可以创建子节点”/lock/node-“并且指明有序，那么zookeeper在生成子节点时会根据档期子节点数据自动添加整数序号</p><p>  也就是说，如果第一个字节点是lock/node-1，那么下个节点就是lock/node-2</p></li><li><p>临时节点：客户端可以建立一个临时节点，在会话结束或者会话超时后，zookeeper会自动删除该节点</p></li><li><p>事件监听：在读取数据时，我们可以同时对节点设置事件监听，当节点数据或者结构发生变化时，zookeeper会通知客户端，当前zookeeper有如下四种事件：</p><ul><li>节点创建</li><li>节点删除</li><li>节点数据修改</li><li>子节点变更</li></ul></li></ul><h3 id="实现原理-2"><a href="#实现原理-2" class="headerlink" title="实现原理"></a>实现原理</h3><p>看完zk的特性之后，我们来看下如何利用zk来实现分布式锁</p><ol><li>使用zk的临时节点和有序节点，每个线程获取锁就是在zk创建一个临时有序的节点，比如在/lock目录下</li><li>创建界定啊成功之后，获取/lock目录下所有临时节点，在判断当前线程创建的节点是否是所有节点的序号中最小的节点</li><li>如果当前线程创建的节点是所有节点序号最小的节点，则认为获取锁成功</li><li><p>如果当前线程创建的节点不是所有节点序号最小的节点，则对节点序号的前一个节点添加一个事件监听</p><p> 比如当前线程获取到的节点序号为/lock/003,然后所有节点列表为[/lock/001,/lock/002,/lock/003],则对/lock/002这个节点添加一个事件监听器</p><p> 如果锁释放了，会唤醒下一个序号的节点，然后重新执行第3步，判断是否自己的节点序号是最小。</p></li></ol><p>比如/lock/001释放了，/lock/002监听到时间，此时节点集合为[/lock/002,/lock/003],则/lock/002为最小序号节点，获取到锁。    </p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190811165302.png" alt=""></p><h3 id="Curator"><a href="#Curator" class="headerlink" title="Curator"></a>Curator</h3><p>Curator是一个zookeeper的开源客户端，也提供了分布式锁的实现</p><pre><code>InterProcessMutex interProcessMutex = new InterProcessMutex(client,&quot;/anyLock&quot;);interProcessMutex.acquire();interProcessMutex.release();    </code></pre><p>curator的实现原理和上面分析的差不多</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190811195531.png" alt=""></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><table><thead><tr><th>实现方式</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>数据库</td><td>实现原理理解简单，不需要额外维护第三方的组件</td><td>实现复杂，需要自己考虑锁超时，加事务等等。</td></tr><tr><td>Redis</td><td>实现简单，性能较好</td><td>1. 获取锁的方式简单粗暴，获取不到锁直接不断尝试，比较消耗性能<br>2. redis 的设计定位决定了它的数据并不是强一致性的，在某些极端情况下，可能会出现问题，锁的模型不够健壮</td></tr><tr><td>Zookeeper</td><td>1. 强一直性，锁的模型健壮，简单易用<br> 2. 如果获取不到锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小</td><td>性能较差，如果有较多的客户端频繁的申请加锁，释放锁，对于zk集群的压力较大</td></tr></tbody></table><p>从理解的难易程度(从低到高)</p><blockquote><p>数据库 &gt; redis &gt; Zookeeper</p></blockquote><p>从实现的复杂性角度（从低到高）</p><blockquote><p>Zookeeper &gt;= redis &gt; 数据库</p></blockquote><p>从性能角度（从高到低）</p><blockquote><p>redis &gt; Zookeeper &gt;= 数据库</p></blockquote><p>从可靠性角度（从高到低）</p><blockquote><p>Zookeeper &gt; redis &gt; 数据库</p></blockquote><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://juejin.im/post/5bbb0d8df265da0abd3533a5#heading-18" target="_blank" rel="noopener">再有人问你分布式锁，这篇文章扔给他</a></li><li><a href="https://www.hollischuang.com/archives/1716" target="_blank" rel="noopener">分布式锁的几种实现方式</a></li><li><a href="https://mp.weixin.qq.com/s/fGYDuvpuuNu7WcHKKs4pIg" target="_blank" rel="noopener">面试不懂分布式锁？那得多吃亏</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> JAVA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>TCP之拥塞控制</title>
      <link href="/2019/07/30/tcp-zhi-yong-sai-kong-zhi/"/>
      <url>/2019/07/30/tcp-zhi-yong-sai-kong-zhi/</url>
      
        <content type="html"><![CDATA[<h2 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h2><p>如果发送方发送数据过快，那么接收方来不及接收，就会丢弃数据。为了避免分组丢失，需要进行流量控制，避免发送方的数据将接收方淹没。</p><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>流量控制的实现是基于滑动窗口。接收方在发送给发送方的ACK中包含了自己的接收窗口大小，当接收窗口为0时，发送方将暂停发送数据。</p><p>例如下图中，在连接建立时，发送方B告知接收方A，它的接收窗口大小为400，那么发送方发送的数据不能超过这个大小。<br><img src="https://img-blog.csdn.net/20140509220855687?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveWVjaGFvZGVjaHVudGlhbg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p><h3 id="Nagle算法"><a href="#Nagle算法" class="headerlink" title="Nagle算法"></a>Nagle算法</h3><p>此算法主要是为了避免发送方频繁地向接收方发送较小的数据。如果发送方发送1字节的数据，每次发送的IP包大小为20 + 20 + 1，分别是IP头部 + TCP头部 + 数据，这样会造成带宽的浪费。</p><p>Nagle算法流程</p><ol><li>发送方先发送1字节的数据</li><li>对于后面需要发送的数据，发送方会先缓存起来</li><li>当收到前一个发送数据的ACK时，才发送缓存的数据</li><li>若缓存的数据达到发送窗口的一半或者达到报文段的最大长度，也会发送数据</li></ol><h3 id="愚笨窗口综合症-silly-window-syndrome"><a href="#愚笨窗口综合症-silly-window-syndrome" class="headerlink" title="愚笨窗口综合症(silly window syndrome)"></a>愚笨窗口综合症(silly window syndrome)</h3><p>此算法主要是为了避免接收方频繁地向发送方发送ACK。当接收方的接收窗口满时，应用层每次从接收窗口读取1字节的数据，此时接口方立即向发送方发送ACK，告知发送方此时接收窗口为1，可以发送1字节的数据，那么发送方不得不发送1字节的数据，此时接收窗口又满了。如此反复使得传输效率低下</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190731001655.png" alt=""></p><p>为了避免上述情况，接收方需要等待一段时间，当接收窗口有一半空闲的大小或者可以容纳一个最长的报文，则发送ACK到发送方，告知其接收窗口大小。</p><h2 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h2><p>路由器有一个数据队列，用来保存接收到的数据，当路由器接收到太多的数据，导致队列满了，就会无条件地丢弃新到来的数据。此时上层的TCP认为数据在网络中丢失了，又会重传这些数据，而路由器又会丢弃这些重传的数据，如此反复，导致网络性能下降。因此TCP需要进行拥塞控制</p><h3 id="流量控制与拥塞控制的区别"><a href="#流量控制与拥塞控制的区别" class="headerlink" title="流量控制与拥塞控制的区别"></a>流量控制与拥塞控制的区别</h3><p>拥塞控制是防止过多的数据<strong>涌入到网络</strong>中，它是一个<strong>全局性的过程</strong>，它涉及到所有主机，所有的路由器。</p><p>流量控制针对的是<strong>点对点之间的通信</strong>，它主要是防止接收方被发送方的数据淹没，即控制发送方发送数据的速率，使得接收方来得及接收。</p><h2 id="拥塞算法"><a href="#拥塞算法" class="headerlink" title="拥塞算法"></a>拥塞算法</h2><p>TCP通过拥塞窗口(cwnd)来控制拥塞，发送方可以发送的数据大小为,其中rwnd表示接收窗口</p><pre><code>min(cwnd,rwnd)</code></pre><p>在不同的阶段，cwnd具有不同的计算方式    </p><h3 id="慢启动阶段-Slow-Start-Phase"><a href="#慢启动阶段-Slow-Start-Phase" class="headerlink" title="慢启动阶段(Slow Start Phase)"></a>慢启动阶段(Slow Start Phase)</h3><p>在慢启动阶段，初始时，cwnd被设置为1，但是每经过一个RTT，cwnd变成指数增长，直到cwnd&gt;=阈值(ssthresh)</p><pre><code>Initially cwnd = 1After 1 RTT, cwnd = 2^(1) = 22 RTT, cwnd = 2^(2) = 43 RTT, cwnd = 2^(3) = 8</code></pre><h3 id="拥塞避免阶段-Congestion-Avoidance-Phase"><a href="#拥塞避免阶段-Congestion-Avoidance-Phase" class="headerlink" title="拥塞避免阶段(Congestion Avoidance Phase)"></a>拥塞避免阶段(Congestion Avoidance Phase)</h3><p>当cwnd&gt;=ssthresh，进入拥塞避免阶段。因为此时网络拥塞的可能性变大，cwnd不在指数增长，而变成线性增长，每经过一个RTT，cwnd = cwnd + 1</p><pre><code>Initially cwnd = iAfter 1 RTT, cwnd = i+12 RTT, cwnd = i+23 RTT, cwnd = i+3</code></pre><h3 id="拥塞检测阶段-Congestion-Detection-Phase"><a href="#拥塞检测阶段-Congestion-Detection-Phase" class="headerlink" title="拥塞检测阶段(Congestion Detection Phase)"></a>拥塞检测阶段(Congestion Detection Phase)</h3><p>当网络出现拥塞时，TCP需要判断是什么情况导致了拥塞，对于不同的情况，cwnd的计算不同。</p><p>（1）由于超时而导致的重传</p><pre><code>1. ssthresh变成cwnd的一半，ssthresh=cwnd/22. cwnd重置为13. 进入到慢启动阶段</code></pre><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190805231926.png" alt=""></p><p>如上图所示，当cwnd=24时，发生超时，ssthresh被重置为cwnd的一半，即ssthresh=cwnd/2=12.同时cwnd被重置为1，再次进入慢启动阶段</p><p>(2) 连续收到3个重复的ACK(数据丢失了)</p><pre><code>1. ssthresh变成cwnd的一半，ssthresh=cwnd/22. cwnd重置为ssthresh3. 进入到拥塞避免阶段</code></pre><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190805231849.png" alt=""></p><p>如上图，当收到3个重复的ACK，ssthresh被重置为cwnd的一半，即ssthresh=cwnd/2=12，同时cwnd被重置为ssthresh，即12，同时开始进入拥塞检测阶段，cwnd开始线性增长。    </p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://www.geeksforgeeks.org/computer-network-tcp-congestion-control/" target="_blank" rel="noopener">Computer Network | TCP Congestion Control</a></li><li><a href="https://www.jianshu.com/p/97e5d7e73ba0" target="_blank" rel="noopener">TCP/IP 拥塞控制</a></li><li><a href="https://zhuanlan.zhihu.com/p/37379780" target="_blank" rel="noopener">TCP流量控制、拥塞控制</a></li><li><a href="https://blog.csdn.net/wdscq1234/article/details/52517420" target="_blank" rel="noopener">TCP-IP详解: 慢启动和拥塞控制</a></li><li><a href="https://blog.csdn.net/yechaodechuntian/article/details/25429143" target="_blank" rel="noopener">TCP的流量控制和拥塞控制</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 计算机基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>MySQL Explain详解</title>
      <link href="/2019/07/27/mysql-explain-xiang-jie/"/>
      <url>/2019/07/27/mysql-explain-xiang-jie/</url>
      
        <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>explain命令可以对Select语句进行分析，并输出 SELECT 执行的详细信息, 以供开发人员针对性优化.</p><p>explain的用法，只需要在Select语句之前加入explain即可</p><pre><code>explain SELECT * from user where id=1</code></pre><h2 id="建立测试表"><a href="#建立测试表" class="headerlink" title="建立测试表"></a>建立测试表</h2><p>为了方便测试explain的功能，需要建立一些测试表</p><h3 id="user-info"><a href="#user-info" class="headerlink" title="user_info"></a>user_info</h3><pre><code>CREATE TABLE `user_info` (  `id`   BIGINT(20)  NOT NULL AUTO_INCREMENT,  `name` VARCHAR(50) NOT NULL DEFAULT &#39;&#39;,  `age`  INT(11)              DEFAULT NULL,      PRIMARY KEY (`id`),      KEY `name_index` (`name`)    )ENGINE = InnoDB DEFAULT CHARSET = utf8;INSERT INTO user_info (name, age) VALUES (&#39;xys&#39;, 20);INSERT INTO user_info (name, age) VALUES (&#39;a&#39;, 21);INSERT INTO user_info (name, age) VALUES (&#39;b&#39;, 23);INSERT INTO user_info (name, age) VALUES (&#39;c&#39;, 50);INSERT INTO user_info (name, age) VALUES (&#39;d&#39;, 15);INSERT INTO user_info (name, age) VALUES (&#39;e&#39;, 20);INSERT INTO user_info (name, age) VALUES (&#39;f&#39;, 21);INSERT INTO user_info (name, age) VALUES (&#39;g&#39;, 23);INSERT INTO user_info (name, age) VALUES (&#39;h&#39;, 50);INSERT INTO user_info (name, age) VALUES (&#39;i&#39;, 15);</code></pre><h3 id="order-info"><a href="#order-info" class="headerlink" title="order_info"></a>order_info</h3><pre><code>CREATE TABLE `order_info` (  `id`           BIGINT(20)  NOT NULL AUTO_INCREMENT,  `user_id`      BIGINT(20)  DEFAULT NULL,  `product_name` VARCHAR(50) NOT NULL DEFAULT &#39;&#39;,  `productor`    VARCHAR(30) DEFAULT NULL,  PRIMARY KEY (`id`),  KEY `user_product_detail_index` (`user_id`, `product_name`, `productor`))  ENGINE = InnoDB  DEFAULT CHARSET = utf8INSERT INTO order_info (user_id, product_name, productor) VALUES (1, &#39;p1&#39;, &#39;WHH&#39;);INSERT INTO order_info (user_id, product_name, productor) VALUES (1, &#39;p2&#39;, &#39;WL&#39;);INSERT INTO order_info (user_id, product_name, productor) VALUES (1, &#39;p1&#39;, &#39;DX&#39;);INSERT INTO order_info (user_id, product_name, productor) VALUES (2, &#39;p1&#39;, &#39;WHH&#39;);INSERT INTO order_info (user_id, product_name, productor) VALUES (2, &#39;p5&#39;, &#39;WL&#39;);INSERT INTO order_info (user_id, product_name, productor) VALUES (3, &#39;p3&#39;, &#39;MA&#39;);INSERT INTO order_info (user_id, product_name, productor) VALUES (4, &#39;p1&#39;, &#39;WHH&#39;);INSERT INTO order_info (user_id, product_name, productor) VALUES (6, &#39;p1&#39;, &#39;WHH&#39;);INSERT INTO order_info (user_id, product_name, productor) VALUES (9, &#39;p8&#39;, &#39;TE&#39;);    </code></pre><h2 id="Explain-输出分析"><a href="#Explain-输出分析" class="headerlink" title="Explain 输出分析"></a>Explain 输出分析</h2><pre><code>mysql&gt; explain select * from user_info where id = 2\G*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: user_info   partitions: NULL         type: constpossible_keys: PRIMARY          key: PRIMARY      key_len: 8          ref: const         rows: 1     filtered: 100.00        Extra: NULL1 row in set, 1 warning (0.00 sec)</code></pre><p>下面逐一的分析各个字段的含义</p><h3 id="select-type"><a href="#select-type" class="headerlink" title="select_type"></a>select_type</h3><p>表示查询类型，在MySQL中常见的查询类型有以下几种</p><table><thead><tr><th style="text-align:center">type</th><th>explain</th></tr></thead><tbody><tr><td style="text-align:center">SIMPLE</td><td>查询不包含UNION查询以及子查询</td></tr><tr><td style="text-align:center">PRIMARY</td><td>表示此查询是最外层的查询</td></tr><tr><td style="text-align:center">UNION</td><td>表示此查询是 UNION 的第二或随后的查询</td></tr><tr><td style="text-align:center">DEPENDENT UNION</td><td>UNION 中的第二个或后面的查询语句, 取决于外面的查询</td></tr><tr><td style="text-align:center">UNION RESULT</td><td>UNION 的结果</td></tr><tr><td style="text-align:center">SUBQUERY</td><td>子查询中的第一个 SELECT</td></tr><tr><td style="text-align:center">DEPENDENT SUBQUERY</td><td>子查询中的第一个 SELECT, 取决于外面的查询. 即子查询依赖于外层查询的结果</td></tr></tbody></table><p>最常见的就是查询类型就是SIMPLE</p><pre><code>mysql&gt; explain select * from user_info where id = 2;+----+-------------+-----------+------------+-------+---------------+---------+---------+-------+------+----------+-------+| id | select_type | table     | partitions | type  | possible_keys | key     | key_len | ref   | rows | filtered | Extra |+----+-------------+-----------+------------+-------+---------------+---------+---------+-------+------+----------+-------+|  1 | SIMPLE      | user_info | NULL       | const | PRIMARY       | PRIMARY | 8       | const |    1 |   100.00 | NULL  |+----+-------------+-----------+------------+-------+---------------+---------+---------+-------+------+----------+-------+</code></pre><p>UNION查询</p><pre><code>mysql&gt; explain select * from user_info where id = 2 union select * from user_info where id = 4;+----+--------------+------------+------------+-------+---------------+---------+---------+-------+------+----------+-----------------+| id | select_type  | table      | partitions | type  | possible_keys | key     | key_len | ref   | rows | filtered | Extra           |+----+--------------+------------+------------+-------+---------------+---------+---------+-------+------+----------+-----------------+|  1 | PRIMARY      | user_info  | NULL       | const | PRIMARY       | PRIMARY | 8       | const |    1 |   100.00 | NULL            ||  2 | UNION        | user_info  | NULL       | const | PRIMARY       | PRIMARY | 8       | const |    1 |   100.00 | NULL            || NULL | UNION RESULT | &lt;union1,2&gt; | NULL       | ALL   | NULL          | NULL    | NULL    | NULL  | NULL |     NULL | Using temporary |+----+--------------+------------+------------+-------+---------------+---------+---------+-------+------+----------+-----------------+</code></pre><h3 id="table"><a href="#table" class="headerlink" title="table"></a>table</h3><p>表示查询涉及的表或者中间表</p><h3 id="type"><a href="#type" class="headerlink" title="type"></a>type</h3><p>type 字段比较重要, 它提供了判断查询是否高效的重要依据依据. 通过 type 字段, 我们判断此次查询是 全表扫描还是索引扫描等.</p><table><thead><tr><th style="text-align:center">type</th><th>explain</th></tr></thead><tbody><tr><td style="text-align:center">system</td></tr><tr><td style="text-align:center">const</td><td>针对主键或唯一索引的等值查询扫描, 最多只返回一行数据</td></tr><tr><td style="text-align:center">eq_ref</td><td>此类型通常出现在多表的 join 查询, 表示对于前表的每一个结果, 都只能匹配到后表的一行结果. 并且查询的比较操作通常是 =</td></tr><tr><td style="text-align:center">ref</td><td>此类型通常出现在多表的 join 查询, 针对于非唯一或非主键索引, 或者是使用了 最左前缀 规则索引的查询</td></tr><tr><td style="text-align:center">range</td><td>范围扫描</td></tr><tr><td style="text-align:center">index</td><td>表示全索引扫描(full index scan), 和 ALL 类型类似, 只不过 ALL 类型是全表扫描, 而 index 类型则仅仅扫描所有的索引, 而不扫描数据</td></tr><tr><td style="text-align:center">All</td><td>表示全表扫描, 这个类型的查询是性能最差的查询之一</td></tr></tbody></table><p>各查询类型的效率如下</p><pre><code>ALL &lt; index &lt; range &lt; ref &lt; eq_ref &lt; const &lt; system</code></pre><p>下面我们测试一下各类型</p><h4 id="const"><a href="#const" class="headerlink" title="const"></a>const</h4><p>const扫描的条件为</p><ol><li>命中主键或者唯一索引</li><li><p>连接的部分是常量</p><pre><code> mysql&gt; explain select * from user_info where id=1; +----+-------------+-----------+------------+-------+---------------+---------+---------+-------+------+----------+-------+ | id | select_type | table     | partitions | type  | possible_keys | key     | key_len | ref   | rows | filtered | Extra | +----+-------------+-----------+------------+-------+---------------+---------+---------+-------+------+----------+-------+ |  1 | SIMPLE      | user_info | NULL       | const | PRIMARY       | PRIMARY | 8       | const |    1 |   100.00 | NULL  | +----+-------------+-----------+------------+-------+---------------+---------+---------+-------+------+----------+-------+</code></pre></li></ol><h4 id="eq-ref"><a href="#eq-ref" class="headerlink" title="eq_ref"></a>eq_ref</h4><p>eq_res扫描的条件</p><ol><li>join操作</li><li>命中主键或者非空唯一索引</li><li><p>等值连接</p><pre><code> mysql&gt; explain select * from user_info,order_info where user_info.id=order_info.user_id; +----+-------------+------------+------------+--------+---------------------------+---------------------------+---------+-------------------------+------+----------+--------------------------+ | id | select_type | table      | partitions | type   | possible_keys             | key                       | key_len | ref                     | rows | filtered | Extra                    | +----+-------------+------------+------------+--------+---------------------------+---------------------------+---------+-------------------------+------+----------+--------------------------+ |  1 | SIMPLE      | order_info | NULL       | index  | user_product_detail_index | user_product_detail_index | 254     | NULL                    |    9 |   100.00 | Using where; Using index | |  1 | SIMPLE      | user_info  | NULL       | eq_ref | PRIMARY                   | PRIMARY                   | 8       | test.order_info.user_id |    1 |   100.00 | NULL                     | +----+-------------+------------+------------+--------+---------------------------+---------------------------+---------+-------------------------+------+----------+--------------------------+        </code></pre><h4 id="ref"><a href="#ref" class="headerlink" title="ref"></a>ref</h4><p>req扫描条件</p></li><li><p>多表join</p></li><li><p>命中非主键或者非唯一索引</p><pre><code> mysql&gt; explain select * from user_info,order_info where user_info.id=order_info.user_id and order_info.user_id=1; +----+-------------+------------+------------+-------+---------------------------+---------------------------+---------+-------+------+----------+-------------+ | id | select_type | table      | partitions | type  | possible_keys             | key                       | key_len | ref   | rows | filtered | Extra       | +----+-------------+------------+------------+-------+---------------------------+---------------------------+---------+-------+------+----------+-------------+ |  1 | SIMPLE      | user_info  | NULL       | const | PRIMARY                   | PRIMARY                   | 8       | const |    1 |   100.00 | NULL        | |  1 | SIMPLE      | order_info | NULL       | ref   | user_product_detail_index | user_product_detail_index | 9       | const |    1 |   100.00 | Using index | +----+-------------+------------+------------+-------+---------------------------+---------------------------+---------+-------+------+----------+-------------+ 2 rows in set, 1 warning (0.00 sec)</code></pre></li></ol><h4 id="range"><a href="#range" class="headerlink" title="range"></a>range</h4><pre><code>mysql&gt; explain select * from user_info where id in(1,2);+----+-------------+-----------+------------+-------+---------------+---------+---------+------+------+----------+-------------+| id | select_type | table     | partitions | type  | possible_keys | key     | key_len | ref  | rows | filtered | Extra       |+----+-------------+-----------+------------+-------+---------------+---------+---------+------+------+----------+-------------+|  1 | SIMPLE      | user_info | NULL       | range | PRIMARY       | PRIMARY | 8       | NULL |    2 |   100.00 | Using where |+----+-------------+-----------+------------+-------+---------------+---------+---------+------+------+----------+-------------+                </code></pre><h4 id="index"><a href="#index" class="headerlink" title="index"></a>index</h4><p>扫描的数据是索引</p><pre><code>mysql&gt; explain select name from user_info;+----+-------------+-----------+------------+-------+---------------+------------+---------+------+------+----------+-------------+| id | select_type | table     | partitions | type  | possible_keys | key        | key_len | ref  | rows | filtered | Extra       |+----+-------------+-----------+------------+-------+---------------+------------+---------+------+------+----------+-------------+|  1 | SIMPLE      | user_info | NULL       | index | NULL          | name_index | 152     | NULL |   10 |   100.00 | Using index |+----+-------------+-----------+------------+-------+---------------+------------+---------+------+------+----------+-------------+</code></pre><h4 id="All"><a href="#All" class="headerlink" title="All"></a>All</h4><p>全表扫描，效率低下，需要进行优化</p><pre><code>mysql&gt; explain select * from user_info where age = 20;+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----------+-------------+| id | select_type | table     | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra       |+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----------+-------------+|  1 | SIMPLE      | user_info | NULL       | ALL  | NULL          | NULL | NULL    | NULL |   10 |    10.00 | Using where |+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----------+-------------+        </code></pre><h3 id="possible-keys"><a href="#possible-keys" class="headerlink" title="possible_keys"></a>possible_keys</h3><p>表示查询中可能用到的索引，有些索引在possible_keys中出现，不代表此索引会真正的被用到。MySQL中真正用的索引需要看key字段</p><h3 id="key"><a href="#key" class="headerlink" title="key"></a>key</h3><p> MySQL 在当前查询时所真正使用到的索引.</p><h3 id="key-len"><a href="#key-len" class="headerlink" title="key_len"></a>key_len</h3><p>表示查询优化器使用了索引的字节数. 这个字段可以评估组合索引是否完全被使用, 或只有最左部分字段被使用到.</p><h4 id="计算规则"><a href="#计算规则" class="headerlink" title="计算规则"></a>计算规则</h4><ul><li><p>字符串</p><ul><li>char(n): n字节长度</li><li>varchar(n): 如果是utf-8编码，则是3n+2</li></ul></li><li><p>数值类型</p><ul><li>TINYINT: 1字节</li><li>SMALLINT: 2字节</li><li>MEDIUMINT: 3字节</li><li>INT: 4字节</li><li>BIGINT: 8字节</li></ul></li><li><p>时间类型</p><ul><li>DATE: 3字节</li><li>TIMESTAMP: 4字节</li><li>DATETIME: 8字节</li></ul></li><li><p>字段属性</p><p>  NULL 属性 占用一个字节. 如果一个字段是 NOT NULL 的, 则没有此属性</p></li></ul><p>示例如下：</p><pre><code>mysql&gt; EXPLAIN SELECT * FROM order_info WHERE user_id &lt; 3 AND product_name = &#39;p1&#39; AND productor = &#39;WHH&#39;;+----+-------------+------------+------------+-------+---------------------------+---------------------------+---------+------+------+----------+--------------------------+| id | select_type | table      | partitions | type  | possible_keys             | key                       | key_len | ref  | rows | filtered | Extra                    |+----+-------------+------------+------------+-------+---------------------------+---------------------------+---------+------+------+----------+--------------------------+|  1 | SIMPLE      | order_info | NULL       | range | user_product_detail_index | user_product_detail_index | 9       | NULL |    1 |    11.11 | Using where; Using index |+----+-------------+------------+------------+-------+---------------------------+---------------------------+---------+------+------+----------+--------------------------+    </code></pre><p>order_info中有个联合索引</p><pre><code>KEY `user_product_detail_index` (`user_id`, `product_name`, `productor`)</code></pre><p>在这个查询语句WHERE user_id &lt; 3 AND product_name = ‘p1’ AND productor = ‘WHH’中，因为先进行了user_id的范围查询，而根据 最左前缀匹配 原则, 当遇到范围查询时, 就停止索引的匹配, 因此实际上我们使用到的索引的字段只有user_id, 因此在EXPLAIN中, 显示的key_len为9. 因为 user_id字段是BIGINT, 占用8字节, 而NULL属性占用一个字节, 因此总共是9个字节. </p><p>来看下一个例子</p><pre><code>mysql&gt; EXPLAIN SELECT * FROM order_info WHERE user_id = 1 AND product_name = &#39;p1&#39;;+----+-------------+------------+------------+------+---------------------------+---------------------------+---------+-------------+------+----------+-------------+| id | select_type | table      | partitions | type | possible_keys             | key                       | key_len | ref         | rows | filtered | Extra       |+----+-------------+------------+------------+------+---------------------------+---------------------------+---------+-------------+------+----------+-------------+|  1 | SIMPLE      | order_info | NULL       | ref  | user_product_detail_index | user_product_detail_index | 161     | const,const |    1 |   100.00 | Using index |+----+-------------+------------+------------+------+---------------------------+---------------------------+---------+-------------+------+----------+-------------+    </code></pre><p>因为我们的查询条件 WHERE user_id = 1 AND product_name = ‘p1’ 中, 仅仅使用到了联合索引中的前两个字段, 因此 keyLen(user_id) + keyLen(product_name) = 9 + 50 * 3 + 2 = 161    ，因为是utf-8编码，所以是3n+2                </p><h3 id="rows"><a href="#rows" class="headerlink" title="rows"></a>rows</h3><p>rows也是一个重要的字段. MySQL查询优化器根据统计信息, 估算SQL要查找到结果集需要扫描读取的数据行数.</p><h3 id="extra"><a href="#extra" class="headerlink" title="extra"></a>extra</h3><p>explain很多额外信息会在extra中展示，常见的有以下几种内容</p><table><thead><tr><th style="text-align:center">type</th><th>explain</th></tr></thead><tbody><tr><td style="text-align:center">Using filesort</td><td>表示MySQL需额外的排序操作，建议优化</td></tr><tr><td style="text-align:center">Using index</td><td>SQL所需要返回的所有列数据均在一棵索引树上，而无需访问实际的行记录，性能较好</td></tr><tr><td style="text-align:center">Using temporary</td><td>需要建立临时表(temporary table)来暂存中间结果，性能较低，需要优化</td></tr></tbody></table><p>下面来看第一个例子</p><pre><code>mysql&gt; EXPLAIN SELECT * FROM order_info ORDER BY product_name;+----+-------------+------------+------------+-------+---------------+---------------------------+---------+------+------+----------+-----------------------------+| id | select_type | table      | partitions | type  | possible_keys | key                       | key_len | ref  | rows | filtered | Extra                       |+----+-------------+------------+------------+-------+---------------+---------------------------+---------+------+------+----------+-----------------------------+|  1 | SIMPLE      | order_info | NULL       | index | NULL          | user_product_detail_index | 254     | NULL |    9 |   100.00 | Using index; Using filesort |+----+-------------+------------+------------+-------+---------------+---------------------------+---------+------+------+----------+-----------------------------+</code></pre><p>product_name在联合索引中</p><pre><code>KEY `user_product_detail_index` (`user_id`, `product_name`, `productor`)</code></pre><p>但是使用product_name排序，不能利用索引进行优化，因此需要额外排序，进而变成using filesort。如果修改为 order by user_id,product_name则不会出现using filesort</p><pre><code>mysql&gt; EXPLAIN SELECT * FROM order_info ORDER BY user_id,product_name;+----+-------------+------------+------------+-------+---------------+---------------------------+---------+------+------+----------+-------------+| id | select_type | table      | partitions | type  | possible_keys | key                       | key_len | ref  | rows | filtered | Extra       |+----+-------------+------------+------------+-------+---------------+---------------------------+---------+------+------+----------+-------------+|  1 | SIMPLE      | order_info | NULL       | index | NULL          | user_product_detail_index | 254     | NULL |    9 |   100.00 | Using index |+----+-------------+------------+------------+-------+---------------+---------------------------+---------+------+------+----------+-------------+    </code></pre><p>出现Using temporary</p><pre><code>mysql&gt; explain select name,age from user_info group by name,age order by age;+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----------+---------------------------------+| id | select_type | table     | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra                           |+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----------+---------------------------------+|  1 | SIMPLE      | user_info | NULL       | ALL  | NULL          | NULL | NULL    | NULL |   10 |   100.00 | Using temporary; Using filesort |+----+-------------+-----------+------------+------+---------------+------+---------+------+------+----------+---------------------------------+</code></pre><p>典型的，group by和order by同时存在，且作用于不同的字段时，就会建立临时表，以便计算出最终的结果集</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://mp.weixin.qq.com/s/uenONvfT0ZcXl5-WIZtFHQ" target="_blank" rel="noopener">如何利用工具，迅猛定位低效SQL</a></li><li><a href="https://segmentfault.com/a/1190000008131735" target="_blank" rel="noopener">MySQL 性能优化神器 Explain 使用分析</a>        </li><li><a href="https://www.sitepoint.com/using-explain-to-write-better-mysql-queries/" target="_blank" rel="noopener">Using EXPLAIN to Write Better MySQL Queries</a></li><li><a href="https://dev.mysql.com/doc/refman/8.0/en/explain-output.html#explain_select_type" target="_blank" rel="noopener">官方文档</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>TCP三次握手与连接释放</title>
      <link href="/2019/07/25/tcp-san-ci-wo-shou-yu-lian-jie-shi-fang/"/>
      <url>/2019/07/25/tcp-san-ci-wo-shou-yu-lian-jie-shi-fang/</url>
      
        <content type="html"><![CDATA[<h2 id="TCP连接"><a href="#TCP连接" class="headerlink" title="TCP连接"></a>TCP连接</h2><h3 id="为什么需要三次握手"><a href="#为什么需要三次握手" class="headerlink" title="为什么需要三次握手"></a>为什么需要三次握手</h3><p>TCP是一个可靠的通信协议，所谓的可靠是指接收方收到的数据是完整的，有序的，无差错的。为了实现这个目标，TCP的通信双方需要判断自己的数据是否已经被对方接收，如果没有，那么需要重发。为了实现这个需求，TCP引入了序列号(Sequence number)和确认号(Acknowledgement number).</p><p>序列号用来表明发送了哪些数据，确认号用来表明已经收到了哪些数据。因此序列号的唯一性和有效性就显得尤为重要。TCP的通信双方在初始时都需要告知对方自己随机选择的初始序列号(Initial Sequence Number, ISN).<strong>而TCP三次握手的本质就在于同步双方初始的序列号</strong></p><h3 id="TCP连接过程"><a href="#TCP连接过程" class="headerlink" title="TCP连接过程"></a>TCP连接过程</h3><ol><li>client发送SYN=1，SEQ=x，表示它想与服务端建立连接，它初始的的序列号为x</li><li>server收到SEQ=x的数据，需要发送ACK=x+1给client，表示它已经收到了序列号为x的数据，它下一个希望收到数据的序列号是x+1</li><li>同时server也需要告知client它的初始序列号，因此server端发送SYN=1，SEQ=y到client</li><li>client收到ACK=x+1，就知道server收到了序列号为x的数据，所以它可以发送序列号为SEQ=x+1的数据。client收到SYN=1，SEQ=y，就知道server端的初始序列号为y，它需要发送ACK=y+1，告知服务端它已收到了数据</li></ol><p>上述2，3两步可以合并在一个包里发送，因此可以称为三次握手</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190726000902.png" alt=""></p><h2 id="TCP连接释放"><a href="#TCP连接释放" class="headerlink" title="TCP连接释放"></a>TCP连接释放</h2><h3 id="TCP连接释放过程"><a href="#TCP连接释放过程" class="headerlink" title="TCP连接释放过程"></a>TCP连接释放过程</h3><ol><li>client发送FYN=1，SEQ=u，表示client已经没有数据想要发送，想要关闭连接</li><li>server收到数据之后，明白了client想要关闭连接，但是它还有数据需要发送给客户端，于是它发送ACK=u+1,SEQ=v到client，表示它已经收到了连接关闭的请求</li><li>server端一直发送数据，直到它也没有数据发送了。于是它发送FYN=1,SEQ=w,ACK=u+1到client，表示它也要关闭连接了</li><li>client收到这个数据，需要发送ACK=w+1给server，表示它收到了连接关闭的请求，server可以关闭连接</li><li>client在等待2MSL(<strong>最大报文生存时间</strong>)时间后，两端连接全部释放</li></ol><p><img src="https://img-blog.csdn.net/20160914101234549?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></p><p>(1) TCP是<strong>全双工</strong>的，即数据可以同时在两个方向上传递，所以每个方向的连接需要单独释放</p><p>(2) 等待2MSL的时间是为了保证client最后一个ACK能够到server端。若ACK丢失，则server会超时重传。如果不设置等待时间，client直接关闭连接，若ACK丢失，则server会一直重传。另外一个原因是，经过报文最长生存时间的等待之后，此次连接的所有报文要么到达对端，要么失效，不会对下次连接造成干扰</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://blog.csdn.net/lengxiao1993/article/details/82771768" target="_blank" rel="noopener">TCP 为什么三次握手而不是两次握手</a></li><li><a href="https://www.zhihu.com/question/24853633" target="_blank" rel="noopener">TCP 为什么是三次握手，而不是两次或四次？</a></li><li><a href="https://blog.csdn.net/guyuealian/article/details/52535294" target="_blank" rel="noopener">TCP建立连接三次握手和释放连接四次握手</a></li><li><a href="https://www.geeksforgeeks.org/computer-network-tcp-3-way-handshake-process/" target="_blank" rel="noopener">Computer Network | TCP 3-Way Handshake Process</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 计算机基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>TCP与UDP协议</title>
      <link href="/2019/07/22/tcp-yu-udp-xie-yi/"/>
      <url>/2019/07/22/tcp-yu-udp-xie-yi/</url>
      
        <content type="html"><![CDATA[<h1 id="UDP-User-Data-Protocol"><a href="#UDP-User-Data-Protocol" class="headerlink" title="UDP(User Data Protocol)"></a>UDP(User Data Protocol)</h1><ol><li>UDP是位于<strong>传输层</strong>中的协议</li><li>UDP是一个<strong>无连接</strong>的协议，也就意味着UDP是<strong>不可靠的</strong></li><li>UDP不考虑错误控制，流控制</li></ol><h2 id="UDP-Header"><a href="#UDP-Header" class="headerlink" title="UDP Header"></a>UDP Header</h2><p><strong>UDP的头部固定只有8字节</strong></p><p><img src="https://media.geeksforgeeks.org/wp-content/uploads/UDP-header.png" alt=""></p><ol><li>源端口和目标端口都是2字节的长度</li><li>length表示了UDP报文的长度，包括<strong>头部以及数据部分</strong></li><li>checksum是可选的，如果不计算的话，则在该位存放0</li></ol><h2 id="UDP的应用"><a href="#UDP的应用" class="headerlink" title="UDP的应用"></a>UDP的应用</h2><ul><li>当数据较小，并且不关心流控制以及错误控制时，适合使用UDP协议，例如一些简单的响应</li><li>UDP用于一些路由更新协议例如RIP(Routing Information Protocol)</li><li>UDP被广泛应用于实时多媒体应用，例如RTP(Real-time transport protocol)协议</li><li>RPC(Remote Procedure Call)也是基于UDP协议</li><li>下面这些协议都是基于UDP协议<ul><li>NTP (Network Time Protocol)</li><li>DNS (Domain Name Service)</li><li>BOOTP, DHCP.</li><li>NNP (Network News Protocol)</li></ul></li></ul><h1 id="TCP-Transmission-Control-Protocol"><a href="#TCP-Transmission-Control-Protocol" class="headerlink" title="TCP(Transmission Control Protocol)"></a>TCP(Transmission Control Protocol)</h1><ol><li>TCP是位于<strong>传输层</strong>中的协议    </li><li>TCP提供了一种<strong>面向连接的、可靠的字节流</strong>服务</li><li>TCP提供重传，流控制以及错误控制等功能</li><li>TCP连接是全双工的，并且是点到点的，<strong>因此TCP不支持多播以及广播</strong></li></ol><h2 id="TCP-Header"><a href="#TCP-Header" class="headerlink" title="TCP Header"></a>TCP Header</h2><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190723001007.png" alt=""></p><table><thead><tr><th>name</th><th>length</th><th>explain</th></tr></thead><tbody><tr><td>source port</td><td>16 bits</td><td>源端口</td></tr><tr><td>destination port</td><td>16 bits</td><td>目标端口</td></tr><tr><td>sequence number</td><td>32 bits</td><td>序列号，用来标识每个数据字节</td></tr><tr><td>acknowledgement number</td><td>32 bits</td><td>确认号，用来表示下一个期望收到的字节</td></tr><tr><td>data offset</td><td>4 bits</td><td>表示TCP头部的长度，单位为32bits，也就是4字节。data offset也就是TCP数据(除去头部)的起始位置</td></tr><tr><td>Reserved</td><td>6 bits</td><td>暂未使用，必须设置为0</td></tr><tr><td>URG</td><td>1 bit</td><td>若urgent pointer被使用，则标识为1</td></tr><tr><td>ACK</td><td>1 bit</td><td>若acknowledgement number有效，则标识为1</td></tr><tr><td>PSH</td><td>1 bit</td><td>若标识为1，则接收方在收到数据后应立即将数据提交给应用层，而不是缓存起来</td></tr><tr><td>RST</td><td>1 bit</td><td>若标识为1，则重置连接</td></tr><tr><td>SYN</td><td>1 bit</td><td>若标识为1，则表示这是一个连接请求(connect request)或者连接接受(connect accept). SYN=1,ACK=0 表示连接请求，SYN=1，ACK=1，表示连接接受</td></tr><tr><td>Window</td><td>16 bits</td><td>从被确认的字节算起还可以发送多少个字节，若为0，表示接收方已经达到瓶颈，发送方可以暂缓发送数据</td></tr><tr><td>checksum</td><td>16 bits</td><td>校验和</td></tr><tr><td>urgent pointer</td><td>16 bits</td><td>用来标识紧急数据在当前数据段中的位置，它是相对于当前序列号的字节偏移值</td></tr></tbody></table><h2 id="TCP的应用"><a href="#TCP的应用" class="headerlink" title="TCP的应用"></a>TCP的应用</h2><ul><li>当要求可靠性时，使用TCP协议</li><li>下列协议都是基于TCP<ul><li>SMTP</li><li>HTTP</li><li>FTP</li></ul></li></ul><h1 id="TCP与UDP的区别"><a href="#TCP与UDP的区别" class="headerlink" title="TCP与UDP的区别"></a>TCP与UDP的区别</h1><ol><li>TCP协议在传送数据段的时候要给段标号；UDP协议不</li><li>TCP协议可靠；UDP协议不可靠</li><li>TCP协议是面向连接；UDP协议采用无连接</li><li>TCP协议负载较高，采用虚电路；UDP采用无连接</li><li>TCP协议的发送方要确认接收方是否收到数据段（3次握手协议）</li><li>TCP协议采用窗口技术和流控制</li></ol><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li><a href="https://www.geeksforgeeks.org/computer-network-user-datagram-protocol-udp/" target="_blank" rel="noopener">Computer Network | User Datagram Protocol (UDP)</a></li><li><a href="https://tools.ietf.org/html/rfc793#section-3.1" target="_blank" rel="noopener">TCP Protocol</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>DHCP协议原理及实现流程</title>
      <link href="/2019/07/13/dhcp-xie-yi-yuan-li-ji-shi-xian-liu-cheng/"/>
      <url>/2019/07/13/dhcp-xie-yi-yuan-li-ji-shi-xian-liu-cheng/</url>
      
        <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>DHCP(Dynamic Host Configuration Protocol) 动态主机配置协议，简单来说，DHCP主要功能是为自动为每一个Host分配IP协议。DHCP协议是在DHCP客户端和DHCP服务端之间运行的，客户端请求IP地址，服务端分配IP地址</p><h2 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h2><h3 id="1-发现阶段"><a href="#1-发现阶段" class="headerlink" title="1. 发现阶段"></a>1. 发现阶段</h3><p>即DHCP客户端寻找DHCP服务端的过程。首先，客户端广播DHCP Discover消息来寻找DHCP服务器，也就是向地址255.255.255.255发送特定的广播消息。网络中所有安装了TCP/IP协议的主机都会收到这个消息，但是只有DHCP服务器会响应</p><h3 id="2-提供阶段"><a href="#2-提供阶段" class="headerlink" title="2. 提供阶段"></a>2. 提供阶段</h3><p>即DHCP服务端提供IP地址的阶段。DHCP服务端收到DHCP discover消息后，它会从尚未出租的IP地址中挑选一个分配给客户端，它会发送一个包含分配的IP地址信息和其他配置信息的DHCP offer消息给客户端。</p><h3 id="3-选择阶段"><a href="#3-选择阶段" class="headerlink" title="3. 选择阶段"></a>3. 选择阶段</h3><p>即DHCP客户端选择某台DHCP服务端提供的IP地址阶段。如果有多台DHCP服务端向客户端发送offer消息，客户端只接受第一个收到的DHCP offer消息，同时DHCP客户端会广播发送DHCP Request请求信息，信息中包含了它选择的DHCP服务端的IP地址。</p><h3 id="4-确认阶段"><a href="#4-确认阶段" class="headerlink" title="4. 确认阶段"></a>4. 确认阶段</h3><p>即DHCP服务端确认IP地址的阶段。当DHCP服务端收到DHCP Request消息时，它就向客户端发送一个DHCP ack消息，告诉客户端他可以使用这个IP地址，然后客户端会将TCP/IP协议与网卡绑定。</p><h3 id="5-重新登录"><a href="#5-重新登录" class="headerlink" title="5. 重新登录"></a>5. 重新登录</h3><p>DHCP客户端每次重新登录网络之后，不需要再次发送discover消息，而是直接发送包含上次所分配的IP地址的Request消息，当DHCP服务端收到这个消息，如果这个IP地址可以继续被使用，则向客户端发送ack消息，如果不可用(可能已经分配给其他主机了)，此时DHCP服务端则发送一个NACK的消息给客户端。客户端收到NACK消息，则必须重新发起discover流程，来重新申请IP</p><h3 id="6-更新租约"><a href="#6-更新租约" class="headerlink" title="6. 更新租约"></a>6. 更新租约</h3><p>DHCP服务器向DHCP客户端分配的IP地址一般都有一个租借期限，超过期限之后，服务端将回收这个IP地址。如果DHCP客户端要延长其IP租约，则在租约过半时，DHCP客户端会自动向DHCP服务端发送更新租约的消息。</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190713224619.png" alt=""></p><p>##总结</p><table><thead><tr><th>消息</th><th>作用</th></tr></thead><tbody><tr><td>DHCP DISCOVER</td><td>客户端广播寻找DHCP服务端</td></tr><tr><td>DHCP OFFER</td><td>DHCP服务端为客户端分配IP地址</td></tr><tr><td>DHCP REQUEST</td><td>DHCP客户端向服务端确认IP地址</td></tr><tr><td>DHCP ACK</td><td>服务端告知客户端可以使用分配的IP地址</td></tr><tr><td>DHCP NAK</td><td>服务端告知客户端不可以使用该IP地址</td></tr><tr><td>DHCP RELEASE</td><td>客户端向服务端更新租约</td></tr></tbody></table><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li><a href="https://tools.ietf.org/html/rfc2131" target="_blank" rel="noopener">DHCP</a></li><li><a href="https://blog.csdn.net/wuruixn/article/details/8282554" target="_blank" rel="noopener">DHCP协议原理及其实现流程</a></li><li><a href="https://jiayu0x.com/2015/03/22/DHCP-protocol-and-offensive-and-defensive/" target="_blank" rel="noopener">DHCP 协议原理与攻防简介</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>网路层之IP协议</title>
      <link href="/2019/07/07/wang-lu-ceng-zhi-ip-xie-yi/"/>
      <url>/2019/07/07/wang-lu-ceng-zhi-ip-xie-yi/</url>
      
        <content type="html"><![CDATA[<p>IP协议提供一种尽力投递(best-effors,即不提供任何保证)的方法将数据从源端传递到目标端，它不关心源机器和目标机器是否在同样的网路中，也不关心他们之间是否还有其他网路。下面来看下IPv4协议头部组成。</p><h2 id="IPv4协议头部"><a href="#IPv4协议头部" class="headerlink" title="IPv4协议头部"></a>IPv4协议头部</h2><p>IPv4的头部有一个20字节的定长部分和一个可选的变成部分组成<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190707211642.png" alt=""></p><h3 id="Version"><a href="#Version" class="headerlink" title="Version"></a>Version</h3><p>version域(4bit)记录了数据报属于哪一个版本的协议，下图是version域值所对应的协议<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190707212106.png" alt=""></p><h3 id="IHL"><a href="#IHL" class="headerlink" title="IHL"></a>IHL</h3><p>IHL(Internet Header Length)表示IP协议头部的长度(以32bit为单位，也就是4字节)。最小值为5，因为定长部分是20个字节;最大值是15，因此头部最长为60字节，也就意味着option域(变长部分)最多有40字节。</p><h3 id="Differentiated-Service"><a href="#Differentiated-Service" class="headerlink" title="Differentiated Service"></a>Differentiated Service</h3><p>Differentiated Service用来表示不同的服务种类(通过服务质量来区分)，例如延迟(Delay),吞吐量(Throughput),可靠性(Reliability)等。该域共有8位，但是只使用了6位，具体如下图<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190707230540.png" alt=""></p><p>其中Precedence表示优先级，剩下三个标志位D(延迟),T(吞吐量),R(可靠性)表示关注的服务质量<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190707230815.png" alt=""><br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190707230909.png" alt=""></p><p>###Total length<br>表示数据报的总长度，也就是整个IP包的长度(头部+数据)，总共有16位，所以最大长度是65535字节</p><h3 id="Identification"><a href="#Identification" class="headerlink" title="Identification"></a>Identification</h3><p>Identification是一个数据报的唯一标识，它的作用是让目标主机确定一个新到达的分段(fragment)是属于哪个数据报的。同一数据报的所有分段都含有相同的标识。</p><h3 id="Flags"><a href="#Flags" class="headerlink" title="Flags"></a>Flags</h3><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190707231836.png" alt=""><br>Flags域有3个标志位，第一个标识位没有被使用，设置为0.第二个标志位DF(Don’t Fragment)表示不要进行分段；第三标识位MF(More Fragment)，用来标识最后一个分段。若分段为数据报中最后一个分段，则该位为0，其余分段为1。接收方可以通过它来确定一个数据报的所有分段是否已经全部到达。</p><h3 id="Fragment-Offset"><a href="#Fragment-Offset" class="headerlink" title="Fragment Offset"></a>Fragment Offset</h3><p>该域指明了分段在当前数据报的什么位置上。除了一个数据报的最后一个分段，其他分段的长度必须是8字节的倍数。8字节是基本的分段单位。由于该域共有13位，因此最多可以有2^13=8192个分段</p><h3 id="TTL"><a href="#TTL" class="headerlink" title="TTL"></a>TTL</h3><p>TTL(Time to Live)是用来追踪一个数据报的存活周期，计数单位是表，因此最大的存活周期是2^8=256秒。在每一跳上数值减1，如果为0，则该数据报被丢弃</p><h3 id="Protocol"><a href="#Protocol" class="headerlink" title="Protocol"></a>Protocol</h3><p>当网络层组装完成一个完整的数据报之后，它需要知道如何对数据报进行处理，Protocol表示了对该数据报进行处理的协议，可以是TCP协议，也可以是UDP协议，</p><h3 id="Header-checksum"><a href="#Header-checksum" class="headerlink" title="Header checksum"></a>Header checksum</h3><p>头部检验和，只用来校验头部，没到达一跳，都需要重新计算头部检验和。</p><h3 id="Source-IP-address"><a href="#Source-IP-address" class="headerlink" title="Source IP address"></a>Source IP address</h3><p>源地址，32位</p><h3 id="Destination-IP-address"><a href="#Destination-IP-address" class="headerlink" title="Destination IP address"></a>Destination IP address</h3><p>目标地址，32位</p><h2 id="IP地址"><a href="#IP地址" class="headerlink" title="IP地址"></a>IP地址</h2><p>IP地址共有32位，可以表示为XXX.XXX.XXX.XXX。IP地址包含网络号和主机号两个部分，根据网络号和主机号的分配方式，IP地址可以分为A,B,C,D,E五类。<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190709001240.png" alt=""></p><p>类别|前缀|网络号|主机号<br>|—|—|—|—|<br>|A|0|2^7=128|2^24|<br>|B|10|2^14|2^16|</p><h3 id="子网"><a href="#子网" class="headerlink" title="子网"></a>子网</h3><p>所谓的子网，是指将一个网络分成多个可供内部使用，但是对于外界仍然像单个网络一样。具体的做法其实就是从主机号中取出一些位作为子网号。</p><h3 id="子网掩码"><a href="#子网掩码" class="headerlink" title="子网掩码"></a>子网掩码</h3><p>为了实现对子网的支持，路由器需要一个子网掩码(subnet mask)，它表示的网络号+子网号+主机号的分隔方案<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190709002622.png" alt=""></p><p>通常情况下，子网掩码的表示方法和地址本身的表示方法是一样的。在IPv4中，就是点分十进制四组表示法（四个取值从0到255的数字由点隔开，比如255.128.0.0）</p><p>另一种更为简短的形式叫做无类别域间路由（CIDR）表示法，它给出的是一个地址加上一个斜杠以及网络掩码的二进制表示法中“1”的位数（即网络号中和网络掩码相关的是哪些位）。例如，192.0.2.96/28表示的是一个前28位被用作网络号的IP地址（和255.255.255.240的意思一样）</p><p><strong>子网掩码的好处就是：不管网络有没有划分子网，只要把子网掩码和IP地址进行逐位的“与”运算（AND）即得出网络地址来</strong></p><h3 id="CIDR"><a href="#CIDR" class="headerlink" title="CIDR"></a>CIDR</h3><p>CIDR的原理是将IP地址以可变大小的块的方式进行分配，而不管他们属于的类别(IP共有A,B,C,D,E)。比如一个站点需要2000个地址，那么它可以获得以2048作为字节边界的地址块，其中包含了2048个地址。</p><p>假设从194.24.0.0开始的地址都可以使用，A需要2048个地址，B需要4096个地址，C需要1024个地址。</p><p>对于A来说，需要2048个地址，那么主机号就需要2^11个，所以它的子网掩码是194.24.0.0/21，地址范围从11000010.00011000.00000000.00000000到11000010.00011000.00000111.11111111，即194.24.0.0 到194.24.7.255</p><p>对于B来说，需要4096个地址，那么主机号就需要2^12个，所以它的子网掩码长度为20位，所以它的起始地址为11000010.00011000.00010000.00000000即194.24.16.0，所以子网掩码位194.16.24.0/20</p><table><thead><tr><th>类别</th><th>首地址</th><th>末地址</th><th>地址个数</th><th>子网掩码</th></tr></thead><tbody><tr><td>A</td><td>194.24.0.0</td><td>194.24.7.255</td><td>2048</td><td>194.24.0.0/21</td></tr><tr><td>C</td><td>194.24.8.0</td><td>194.24.11.255</td><td>1024</td><td>194.24.8.0/22</td></tr><tr><td>可分配</td><td>194.24.12.0</td><td>194.24.15.255</td><td>1024</td><td>194.24.12.0/22</td></tr><tr><td>B</td><td>194.24.16.0</td><td>194.24.31.255</td><td>4096</td><td>194.24.16.0/20</td></tr></tbody></table><p>假设一个目标地址为194.24.17.4到达路由器，那么路由器会选择A，B，C中的哪个呢？</p><p>首先194.24.17.4 与A的子网掩码进行与操作</p><p>11000010.00011000.00010001.00000100 and 11111111.11111111.11111000.00000000</p><p>得到194.24.16.0与A的首地址不符合，所以该地址不属于A</p><p>194.24.17.4与C的子网掩码进行与操作</p><p>11000010.00011000.00010001.00000100 and 11111111.11111111.11111100.00000000</p><p>得到194.24.16.0与C的地址不符合，所以该地址不属于C</p><p>194.24.17.4与B的子网掩码进行与操作</p><p>11000010.00011000.00010001.00000100 and 11111111.11111111.11111000.00000000</p><p>得到194.24.16.0，与B首地址符合，所以属于B</p><h2 id="NAT-Network-Address-Translation-网络地址转换"><a href="#NAT-Network-Address-Translation-网络地址转换" class="headerlink" title="NAT(Network Address Translation)-网络地址转换"></a>NAT(Network Address Translation)-网络地址转换</h2><h3 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h3><blockquote><p>IP地址短缺</p></blockquote><h3 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h3><blockquote><p>公司或者机构以一个公用IP出现在公网上，内部则使用私有的IP。NAT把私有IP转换为公有IP，以便私有IP可以访问外部资源</p></blockquote><h3 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h3><p>NAT的基本工作原理是，当私有网主机和公共网主机通信的IP包经过NAT网关时，将IP包中的源IP或目的IP在私有IP和NAT的公共IP之间进行转换</p><p>如下图所示，NAT网关内有两个私有主机，其中公共网络IP为202.20.65.5。当私有主题192.168.1.2发送IP包给web server时，当IP经过NAT网关时，NAT会把IP包的源地址进行转换</p><pre><code>(src=192.168.1.2, dst=202.20.65.4) ---NAT---&gt;  (src=202.20.65.5, dst=202.20.65.4)</code></pre><p><img src="https://img-blog.csdn.net/20150414102310625" alt=""></p><p>同理，当web server向192.168.1.2发送IP包，经过NAT时，目的地址会被替换为私有地址</p><pre><code>(src=202.20.65.4, dst=202.20.65.5) ---NAT---&gt;  (src=202.20.65.4, dst=192.168.1.2)</code></pre><p><img src="https://img-blog.csdn.net/20150414102327723" alt=""></p><h3 id="NAT-分类"><a href="#NAT-分类" class="headerlink" title="NAT 分类"></a>NAT 分类</h3><p>从功能上来划分，NAT可以分为Basic NAT和PAT</p><p>Basic NAT</p><blockquote><p>只转化IP，不映射端口</p></blockquote><p>PAT    </p><blockquote><p>除了转化IP，还做端口映射，可以用于多个内部地址映射到少量（甚至一个）外部地址</p></blockquote><p>从映射的时效性可以分为静态NAT和动态NAT</p><p>静态NAT</p><blockquote><p>将内部网络中的每个主机都永久映射成外部网络中的某个合法的地址，多用于服务器。</p></blockquote><p>动态NAT</p><blockquote><p>外部网络中定义了一个或多个合法地址，采用动态分配的方法映射到内部网络。</p></blockquote><h2 id="ARP-Address-resolution-Protocol-地址解析协议"><a href="#ARP-Address-resolution-Protocol-地址解析协议" class="headerlink" title="ARP(Address resolution Protocol)地址解析协议"></a>ARP(Address resolution Protocol)地址解析协议</h2><h3 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h3><p>将IP地址映射到MAC地址上，网路层使用IP地址，数据链路层使用MAC地址</p><h3 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h3><ol><li>主机A向局域网中的主机B发送IP数据报时，先在自身的ARP缓冲表中查询主机B的MAC地址</li><li>如果有，即可以找出对应的MAC地址，将其写入帧中，再通过数据链路层的协议将数据发送到目的地址</li><li>如果没有，则主机A启动ARP服务</li><li>ARP服务首先在局域网中广播一个ARP请求分组，分组的内容为，我的IP地址是192.31.63.0，我的MAC地址是00-00-C0-15-AD-18，我想知道知道IP地址为192.31.63.1的MAC地址</li><li>主机B收到请求后，发现是自己的IP地址，则向主机A发送一个ARP响应分组，内容为我的IP地址是192.31.63.1，我的MAC地址是08-00-2B-00-EE-AA。局域网中其他主机则忽略这个请求<h2 id="RARP-Reverse-Address-Resolution-Protocol-反向地址解析协议"><a href="#RARP-Reverse-Address-Resolution-Protocol-反向地址解析协议" class="headerlink" title="RARP(Reverse Address Resolution Protocol)反向地址解析协议"></a>RARP(Reverse Address Resolution Protocol)反向地址解析协议</h2><h3 id="功能-1"><a href="#功能-1" class="headerlink" title="功能"></a>功能</h3>将MAC地址映射到IP地址上</li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>JAVA 泛型</title>
      <link href="/2019/07/06/java-fan-xing/"/>
      <url>/2019/07/06/java-fan-xing/</url>
      
        <content type="html"><![CDATA[<h2 id="为什么需要泛型"><a href="#为什么需要泛型" class="headerlink" title="为什么需要泛型"></a>为什么需要泛型</h2><p>想象以下的场景，我们需要编写一个容器类，支持对数据的简单操作，例如增删改查，那么实现可以如下</p><pre><code>public MyContainerOfString{    private String[] container = new String[10];    private int size;    public void add(String data){        container[size++] = data;    }    public String get(int index){        return container[index];    }    ...}</code></pre><p>如上述代码所示，我们实现了一个可以存储String类型的容器，如果要实现一个Integer，Double等类型的容器，我们会发现需要写很多重复的代码，于是我们可以修改上述的代码，让其更灵活</p><pre><code>public MyContainer{    private Object[] container = new Object[10];    private int size;    public void add(Object data){        container[size++] = data;    }    public Object get(int index){        return container[index];    }    ...}</code></pre><p>上述的实现确实很灵活，可以支持任何类型，但是它也有一个问题，就是类型安全</p><pre><code>MyContainer container = new MyContainer();container.add(1);container.add(&quot;A&quot;);int value = (Interger)container.get(2) //运行失败</code></pre><p>上述代码在编译期间不会报错，但是在运行时报错了，原因就是类型转换失败。</p><p>通过上述的场景我们不难看出使用泛型的好处</p><ol><li>可以减少样本代码</li><li>可以保证类型安全    </li></ol><h2 id="泛型类"><a href="#泛型类" class="headerlink" title="泛型类"></a>泛型类</h2><p>泛型被用于类的定义则称之为泛型类，泛型类的通用写法</p><pre><code>class 类名称&lt;泛型标识&gt;{}</code></pre><p>比较常见的泛型类可见于dao层，例如</p><pre><code>class BaseDao&lt;T&gt; {    public void save(T t){    }    public void delete(T t){    }}</code></pre><h2 id="泛型接口"><a href="#泛型接口" class="headerlink" title="泛型接口"></a>泛型接口</h2><p>泛型接口与泛型类相似，只不过用于定义接口，泛型类的通用写法</p><pre><code>interface 接口名称&lt;泛型标识&gt;{}</code></pre><p>最常见的泛型接口即是各种容器接口，例如</p><pre><code>public interface List&lt;E&gt; extends Collection&lt;E&gt;{}    </code></pre><h2 id="泛型方法"><a href="#泛型方法" class="headerlink" title="泛型方法"></a>泛型方法</h2><p>泛型方法相比于泛型类更为复杂，下面是泛型方法的通用写法</p><pre><code>public &lt;T&gt; 返回类型 方法名称(泛型标识){}</code></pre><p>其中<t>是用来声明该方法是一个泛型方法，是否是一个泛型方法就看它是否有这个标识，例如</t></p><pre><code>public void save(T t)  //不是泛型方法public &lt;T&gt; void save(T t) // 泛型方法</code></pre><p>下面是一个泛型方法的示例</p><pre><code>public &lt;T&gt; List&lt;T&gt; fromArrayToList(T[] a) {       return Arrays.stream(a).collect(Collectors.toList());}</code></pre><p>一个泛型方法可以处理多个泛型类型，但是有几个泛型类型就需要声明几个，例如</p><pre><code>public static &lt;T, G&gt; List&lt;G&gt; fromArrayToList(T[] a, Function&lt;T, G&gt; mapperFunction) {    return Arrays.stream(a)      .map(mapperFunction)      .collect(Collectors.toList());}    </code></pre><h2 id="泛型擦除-Type-Erasure"><a href="#泛型擦除-Type-Erasure" class="headerlink" title="泛型擦除(Type Erasure)"></a>泛型擦除(Type Erasure)</h2><p>泛型擦除可以简单理解为泛型只在编译阶段生效，在编译阶段，正确检验泛型结果后，会将泛型的相关信息擦除，在运行阶段是看不到泛型信息的</p><pre><code>List&lt;Integer&gt; list1 = new ArrayList&lt;&gt;();List&lt;String&gt; list2 = new ArrayList&lt;&gt;();Class&lt;? extends List&gt; list1Class = list1.getClass();Class&lt;? extends List&gt; list2Class = list2.getClass();if (list1Class.equals(list2Class)){    System.out.println(&quot;same class&quot;);}</code></pre><p>运行程序可以看到输出”same class”，由此可以证明泛型信息在运行间已被擦除。总结来说，<strong>泛型类型在逻辑上看以看成是多个不同的类型，实际上都是相同的基本类型。</strong></p><p>那么我们有办法在运行阶段拿到泛型信息吗？答案是有的，但是前提是泛型是类声明的一部分，</p><pre><code>public class CatCage implements Cage&lt;Cat&gt;</code></pre><p>此时我们可以通过反射获取泛型</p><pre><code>(Class&lt;T&gt;) ((ParameterizedType) getClass().getGenericSuperclass()).getActualTypeArguments()[0];    </code></pre><h2 id="泛型边界"><a href="#泛型边界" class="headerlink" title="泛型边界"></a>泛型边界</h2><p>在声明泛型时，我们可以指定泛型的边界，所谓边界其实就是子类与父类的关系，例如</p><pre><code>class Test&lt;T extends Number&gt; // T必须是Number的子类class Test&lt;T super Number&gt;  // T必须是Number的父类</code></pre><p>我们再来看下定义边界有什么用处</p><pre><code>class Cage&lt;T&gt; {}Cage&lt;Animal&gt; cage = new Cage&lt;Cat&gt;() //编译失败</code></pre><p>可以发现装猫的笼子无法转换为装动物的笼子。因此可以得出结论，虽然cat和animal是存在继承关系，但是泛型Cage<animal>和Cage<cat>却不存在继承关系，为了能够表示泛型间的继承关系，因此才有了泛型边界，可以把上述例子修改下，即可运行</cat></animal></p><pre><code>class Cage&lt;T extend Animal&gt;{}</code></pre><h3 id="PECS"><a href="#PECS" class="headerlink" title="PECS"></a>PECS</h3><p>我们如何选择使用上边界<t extends="">还是使用下边界<t super="">呢？原则就是PECS：Producer extend，Consumer super，</t></t></p><p>所谓的Producer extend是指当我们是”生产”泛型对象时，我们就用extend</p><pre><code>public static void makeLotsOfNoise(List&lt;? extends Animal&gt; animals) {    animals.forEach(Animal::makeNoise);   }</code></pre><p>对于上述例子中，我们不断的从animals中取出(生产)对象，执行makeNoise方法，因此使用extend</p><pre><code>public static void addCats(List&lt;? super Animal&gt; animals) {    animals.add(new Cat());   }    </code></pre><p>对于上述例子中，我们不断的往animals中增加(消费)对象，因此使用super    </p><h2 id="泛型通配符"><a href="#泛型通配符" class="headerlink" title="泛型通配符"></a>泛型通配符</h2><pre><code> public void print(List&lt;?&gt; list){    list.forEach(Object::toString);}</code></pre><p>其中?就是通配符，表示未知的类型，?代表的一种具体的类型，例如Number，Integer</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>使用泛型可以减少样本代码并保证类型安全</li><li>泛型方法一定需要用<t>进行声明</t></li><li>所谓泛型擦除是指泛型信息只在编译阶段生效，在运行阶段，已经看不到泛型信息</li><li>使用PECS原则来决定使用上边界还是下边界</li></ol><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li><a href="https://www.baeldung.com/java-generics-interview-questions" target="_blank" rel="noopener">Java Generics Interview Questions (+Answers)</a></li><li><a href="https://www.baeldung.com/java-generics" target="_blank" rel="noopener">The Basics of Java Generics</a></li><li><a href="https://blog.csdn.net/s10461/article/details/53941091" target="_blank" rel="noopener">java 泛型详解</a></li><li><a href="https://juejin.im/post/5b614848e51d45355d51f792" target="_blank" rel="noopener">深入理解Java泛型</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> JAVA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Floyd算法</title>
      <link href="/2019/07/03/floyd-suan-fa/"/>
      <url>/2019/07/03/floyd-suan-fa/</url>
      
        <content type="html"><![CDATA[<h2 id="算法概述"><a href="#算法概述" class="headerlink" title="算法概述"></a>算法概述</h2><p>弗洛伊德算法，是解决任意两点间的最短路径的一种算法。它的时间复杂度为 O(N^3）空间复杂度为 O(N^2)。</p><h2 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h2><p>弗洛伊德算法其实采用的是动态规划</p><p>设F(i,j,k)表示节点i到节点j只以(1,k)之间的节点作为中间节点的最短路径，那么</p><ol><li><p>如果最短路径进过k</p><pre><code> F(i,j,k) = F(i,k,k-1) + F(k,j,k-1)</code></pre></li><li><p>如果最短路径不经过k</p><pre><code> F(i,j,k) = F(i,j,k-1)</code></pre></li></ol><p>所以最短路径为两者之间的最小值</p><pre><code>F(i,j,k) = min[F(i,k,k-1) + F(k,j,k-1), F(i,j,k-1)]</code></pre><p>公式看起来很复杂，但是代码写起来很简单</p><p>首先，如果任意两个节点之间不允许经过第三个点，那么节点间的最短路径就是初始路径。</p><p>现在我们放松条件，允许经过1个节点，例如节点1，那么对于节点i到节点j的最短路径，只需要判断</p><pre><code>e[i][1] + e[1][j] &lt; e[i][j]</code></pre><p>代码如下</p><pre><code>//经过节点1for(int i =1; i &lt;= n; i++){    for(int j=1; j&lt;=n; j++){        if(e[i][1] + e[1][j] &lt; e[i][j]){            e[i][j] = e[i][1] + e[1][j]        }    }}    </code></pre><p>接下来继续求在只允许经过1和2号两个节点的情况下任意两点之间的最短路程。如何做呢？我们需要在只允许经过1号节点时任意两点的最短路程的结果下，再判断如果经过2号节点是否可以使得节点i到节点j之间的路程变得更短。即判断 e[i][2]+e[2][j]是否比 e[i][j]要小</p><pre><code>//经过节点2for(int i =1; i &lt;= n; i++){    for(int j=1; j&lt;=n; j++){        if(e[i][2] + e[2][j] &lt; e[i][j]){            e[i][j] = e[i][1] + e[1][j]        }    }}    </code></pre><p>以此类推，最后允许经过所有的节点，即可求出两两节点间的最短路径了</p><pre><code>for(k=1;k&lt;=n;k++)    for(i=1;i&lt;=n;i++)        for(j=1;j&lt;=n;j++)            if(e[i][j]&gt;e[i][k]+e[k][j])                 e[i][j]=e[i][k]+e[k][j];</code></pre><p>这段代码的基本思想就是：最开始只允许经过节点1进行中转，接下来只允许经过节点1和节点2进行中转……允许经过1~n所有节点进行中转，求任意两点之间的最短路程。也就是从节点i到节点j只经过前k号点的最短路程，这样也就对应到上述的公式中了                 </p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><pre><code>public class Floyd {    private static final Integer INF = Integer.MAX_VALUE;    public void floyd(int[][] edge){        for (int k = 0; k &lt; edge.length; k++){            for (int i = 0; i &lt; edge.length; i++){                for (int j = 0; j &lt; edge.length; j++){                    if (edge[i][k] &lt; INF &amp;&amp; edge[k][j] &lt; INF &amp;&amp;                    edge[i][k] + edge[k][j] &lt; edge[i][j]){                        edge[i][j] = edge[i][k] + edge[k][j];                    }                }            }        }    }    public static void main(String[] args) {        int[][] edge = new int[][]{                {0,2,6,4},                {INF,0,3,INF},                {7,INF,0,1},                {5,INF,12,0}        };        Floyd floyd = new Floyd();        floyd.floyd(edge);        for (int i  = 0; i &lt; edge.length; i++){            System.out.println(Arrays.toString(edge[i]));        }    }}</code></pre><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li><a href="https://zh.wikipedia.org/wiki/Floyd-Warshall%E7%AE%97%E6%B3%95" target="_blank" rel="noopener">Floyd-Warshall算法</a></li><li><a href="http://wiki.jikexueyuan.com/project/easy-learn-algorithm/floyd.html" target="_blank" rel="noopener">只有五行的 Floyd 最短路算法</a>    </li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>迪杰斯特拉算法</title>
      <link href="/2019/06/19/di-jie-si-te-la-suan-fa/"/>
      <url>/2019/06/19/di-jie-si-te-la-suan-fa/</url>
      
        <content type="html"><![CDATA[<h2 id="算法概述"><a href="#算法概述" class="headerlink" title="算法概述"></a>算法概述</h2><p>迪杰斯特拉算法解决了如何在一个图中，计算某一个节点到图中其他所有节点的最短路径。如果将全国所有城市当做节点，连接两个城市的铁路当做线，那么迪杰斯特拉算法可以求出，厦门到全国其他城市的最省时的出行路线。</p><p>维基百科中的专业描述</p><blockquote><p>算法的输入包含了一个有权重的有向图 G，以及G中的一个来源顶点 S。我们以 V 表示 G 中所有顶点的集合。每一个图中的边，都是两个顶点所形成的有序元素对。(u, v) 表示从顶点 u 到 v 有路径相连。我们以 E 表示G中所有边的集合，而边的权重则由权重函数 w: E → [0, ∞] 定义。因此，w(u, v) 就是从顶点 u 到顶点 v 的非负权重（weight）。边的权重可以想像成两个顶点之间的距离。任两点间路径的权重，就是该路径上所有边的权重总和。已知 V 中有顶点 s 及 t，Dijkstra 算法可以找到 s 到 t 的最低权重路径(例如，最短路径)。这个算法也可以在一个图中，找到从一个顶点 s 到任何其他顶点的最短路径。</p></blockquote><h2 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h2><ol><li>将图中的顶点分为两个部分，一个是已知最短路径的顶点，记为集合P，一个是暂时还未知最短路径的顶点，记为集合Q。数组ds[i]，表示源点到顶点i的最短路径,数组e[i][j]表示顶点i到j的距离</li><li>初始时，集合P中只有源点S，ds[0]=0，然后从集合Q中，找到离源点S最近的顶点u，并将u加入到集合P中。然后判断所有以u为起点的边，假设存在边uv，如果e[s][u] + e[u][v] &lt; e[s][v], 则更新源点S到顶点v的最短路径</li><li>重复步骤2，直到集合Q为空，算法结束</li></ol><h2 id="算法示例"><a href="#算法示例" class="headerlink" title="算法示例"></a>算法示例</h2><ol><li>初始时，集合P={1},Q={2,3,4,5,6}, ds={0,-,-,-,-,-},-表示距离无穷大</li><li>在Q中找到离顶点1最近的点，可以看到是顶点2，于是P={1,2}, Q={3,4,5,6} ds={0,1,12,-,-,-}</li><li>更新所有以顶点2为起点的边(e[2][3],e[2][4])，因为e[1][2] + e[2][3] &lt; e[1][3]，所以更新ds[3]=10, 同理e[1][2] + e[2][4] &lt; e[1][4], 所以更新ds[4]=4</li><li>在Q中找到离顶点2最近的点，可以看到是顶点4，于是P={1,2,4}, Q={3,5,6},在更新所有以顶点4为起点的边</li><li>重复上述过程</li></ol><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190621001657.png" alt=""></p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><pre><code>package com.wbl;import java.util.Arrays;import java.util.stream.StreamSupport;/** * @author wbl * @date 2019-06-30 */public class Dijkstra {    public int[] dijkstra(int[][] edge){        int[] ds = new int[edge.length];        //初始化最短路径，这里假设都是计算从顶点1到其他顶点的最短路径        for (int i = 1; i &lt; ds.length; i++){            ds[i] = Integer.MAX_VALUE;        }        //用来标志以找到最短路径的顶点，若flag[i] = 1，则表示已经找到由源点到顶点i的最短路径        int[] flag = new int[edge.length];        for (int i = 0; i &lt; edge.length; i++){            int minIndex = 0;            int minValue = Integer.MAX_VALUE;            // 找到离已知顶点最近的顶点，minIndex表示该顶点            for (int j = 0; j &lt; edge.length; j++){                if (flag[j] == 0 &amp;&amp; ds[j] &lt; minValue){                    minValue = ds[j];                    minIndex = j;                }            }            flag[minIndex] = 1;            for (int k = 0; k &lt; edge.length; k++){                // 收敛源点到各个顶点的距离                if (edge[minIndex][k]&gt;0 &amp;&amp; ds[minIndex] + edge[minIndex][k] &lt; ds[k]){                    ds[k] = ds[minIndex] + edge[minIndex][k];                }            }        }        return ds;    }    public static void main(String[] args) {        int [][] edge = new int[][]{                {0,1,12,-1,-1,-1},                {-1,0,9,3,-1,-1},                {-1,-1,0,-1,5,-1},                {-1,-1,4,0,13,15},                {-1,-1,-1,-1,0,4},                {-1,-1,-1,-1,-1,0},        };        Dijkstra dijkstra = new Dijkstra();        System.out.println(Arrays.toString(dijkstra.dijkstra(edge)));    }}</code></pre><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li><a href="https://wiki.jikexueyuan.com/project/easy-learn-algorithm/dijkstra.html" target="_blank" rel="noopener">Dijkstra 最短路算法</a></li><li><a href="https://zh.wikipedia.org/wiki/%E6%88%B4%E5%85%8B%E6%96%AF%E7%89%B9%E6%8B%89%E7%AE%97%E6%B3%95" target="_blank" rel="noopener">戴克斯特拉算法</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>初探Select,Poll,Epoll</title>
      <link href="/2019/06/16/chu-tan-select-poll-epoll/"/>
      <url>/2019/06/16/chu-tan-select-poll-epoll/</url>
      
        <content type="html"><![CDATA[<p>在一个高性能的网络服务中，一个进程往往需要同时处理多个socket。在上一篇博客<a href="">Linux IO模型</a>中提到的IO多路复用模型就是为了解决这个问题的。</p><p>Select，Poll，EPoll是IO多路复用的三种机制，下面来具体看下三者之间的联系和区别</p><h2 id="Select"><a href="#Select" class="headerlink" title="Select"></a>Select</h2><p>刚刚也说了IO多路复用模型是为了监视多个socket，显而易见，最简单的做法就是为维护一个socket列表，表示进程需要监视的socket。如果列表中的socket都没有数据，那么进程将被挂起；如果有<strong>一个以上</strong>的socket接收到数据，那么就唤起进程，进程遍历socket列表以便找出接收到数据的socket。</p><pre><code>int fds[] =  存放需要监听的socket;while(1){     //1. 检测是否有socket接收到数据    int n = select(..., fds, ...)    //2. 遍历列表，找出接收到数据的socket    for(int i=0; i &lt; fds.count; i++){        if(FD_ISSET(fds[i], ...)){            //fds[i]的数据处理        }    }}</code></pre><p>可以看到select的工作机制很简单，主要是两步</p><ol><li>监视socket列表，如果收到数据则返回，否则阻塞进程</li><li>遍历socket列表，找出接收到数据的socket</li></ol><p>因此我们可以知道select的效率不高，原因是显而易见的，select每次都要遍历列表才知道哪些socket接收到数据。另一方面，一个进程能够监视的文件描述符(fds)有限制，最大一般是1024，也就是说select最多只能同时监视1024个socket</p><pre><code>//select函数定义int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);    </code></pre><p>总结一下，select存在的问题</p><ol><li>被监控的fds集合大小被限制了1024，不够用</li><li>fds集合需要从用户空间拷贝到内核空间的问题，耗费性能</li><li>需要遍历fds集合才能知道有数据接收的fds列表    </li></ol><h2 id="Poll"><a href="#Poll" class="headerlink" title="Poll"></a>Poll</h2><p>Poll是为解决select的第一个问题</p><pre><code>int poll (struct pollfd *fds, unsigned int nfds, int timeout);</code></pre><p>poll不在用三个fds集合，而是使用一个pollfd的指针，指针指向了需要监视的fds，因此poll并没有最大数据量限制，但是它的性能同样不高，因为它没有解决select的第二，第三个问题。</p><h2 id="EPoll"><a href="#EPoll" class="headerlink" title="EPoll"></a>EPoll</h2><p>Epoll解决了select遗漏的第2，3个问题，主要的思路有两点</p><ol><li>功能分离，select中维护等待队列(socket列表)和阻塞进程两个步骤结合在一起了，对于频繁调用select的进程来说，socket列表变化的可能性很小，基本固定，并不需要每次都修改。EPoll将两个操作分开。<img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190616170617.png" alt=""></li><li>维护就绪列表，select低效的另一个原因在于程序不知道哪些socket收到数据，只能一个个遍历。如果内核维护一个“就绪列表”，引用收到数据的 socket，就能避免遍历。</li></ol><h3 id="EPoll操作流程"><a href="#EPoll操作流程" class="headerlink" title="EPoll操作流程"></a>EPoll操作流程</h3><p>EPoll操作中涉及三个接口</p><pre><code>int epoll_create(int size)int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);</code></pre><ol><li>epoll_create创建了eventpoll对象，用来维护就绪列表</li><li>epoll_ctl用来维护监视列表，可以添加或删除所要监听的 socket</li><li>当调用epoll_wait时，如果就绪列表中存在socket，则直接返回，如果没有，则阻塞进程</li></ol><p>可以看到epoll高效原因，主要是维护了两个队列，一个是监视队列，一个是就绪队列。监视队列解决了select中fds频繁拷贝的问题，就绪队列解决了select中需要遍历列表才能知道哪个socket接收到数据的问题</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://mp.weixin.qq.com/s/MzrhaWMwrFxKT7YZvd68jw" target="_blank" rel="noopener">epoll的本质</a></li><li><a href="https://segmentfault.com/a/1190000003063859" target="_blank" rel="noopener">Linux IO模式及 select、poll、epoll详解</a>        </li><li><a href="https://cloud.tencent.com/developer/article/1005481" target="_blank" rel="noopener">大话 Select、Poll、Epoll</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 计算机基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux IO模型</title>
      <link href="/2019/06/15/linux-io-mo-xing/"/>
      <url>/2019/06/15/linux-io-mo-xing/</url>
      
        <content type="html"><![CDATA[<h2 id="网络数据接收流程"><a href="#网络数据接收流程" class="headerlink" title="网络数据接收流程"></a>网络数据接收流程</h2><p>计算机接收网络数据的流程如下</p><ol><li>数据通过网线到达计算机</li><li>网卡接收到达的网络数据，将数据写入内核缓冲区</li><li>网卡向CPU发送一个中断信号，告知接收到数据</li><li>CPU收到中断信号后，先将数据由内核拷贝到用户空间</li><li>CPU唤醒对应进程，通知它处理数据<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190615211757.png" alt=""></li></ol><p>通过上图，我们可以知道，对于一次IO访问(以read为例)，它会经历两个阶段</p><ol><li>等待数据的到来</li><li>将数据从内核拷贝到用户空间</li></ol><p>根据不同阶段不同操作，Linux设计了4种不同的IO的模型。</p><h2 id="4种IO模型"><a href="#4种IO模型" class="headerlink" title="4种IO模型"></a>4种IO模型</h2><h3 id="阻塞IO-Blocking-IO"><a href="#阻塞IO-Blocking-IO" class="headerlink" title="阻塞IO(Blocking IO)"></a>阻塞IO(Blocking IO)</h3><p>对于阻塞IO，当进程调用recefrom这个系统调用，就进入了第一阶段，进程将被阻塞。当数据接收完成之后，内核开始拷贝数据，此时进入第二阶段。当数据拷贝完毕之后，将通知来处理数据。</p><blockquote><p>阻塞IO的特点就是在两个阶段进程都被阻塞了<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190615203851.png" alt=""></p></blockquote><h3 id="非阻塞IO-Nonblocking-IO"><a href="#非阻塞IO-Nonblocking-IO" class="headerlink" title="非阻塞IO(Nonblocking IO)"></a>非阻塞IO(Nonblocking IO)</h3><p>对于非阻塞IO，当进程调用recefrom系统调用时，此时若数据还没准备好，内核会返回一个ERROR，告知进程数据还没ready。进程收到结果之后，便知数据还未到达，于是它继续发送recefrom系统调用，直到数据ready，进入第二阶段</p><blockquote><p>非阻塞IO的非阻塞是指在第一阶段进程没有被阻塞，可以收到系统调用结果</p><p>非阻塞IO在第一阶段采用的轮询的方式，不断询问内核数据是否ready<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190615205127.png" alt=""></p></blockquote><h3 id="IO多路复用-IO-multiplexing"><a href="#IO多路复用-IO-multiplexing" class="headerlink" title="IO多路复用(IO multiplexing)"></a>IO多路复用(IO multiplexing)</h3><p>IO多路复用也就是常说的select，poll，epoll方式，是指进程可以同时处理多个网络IO请求。</p><p>当进程调用select时，进程将会被阻塞，直到select管理的socket中，有一个以上的socket接收到数据，此时进程将被唤醒，同时它遍历所有socket对象，以便确定是哪个socket接收到数据。关于select，poll，epoll的区别将在下一篇博客中进行分析。</p><blockquote><p>IO多路复用在两个阶段都是被阻塞的，与阻塞IO相比，唯一的区别是它可以处理多个IO连接<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190615205744.png" alt=""></p></blockquote><h3 id="异步IO-Asynchronous-IO"><a href="#异步IO-Asynchronous-IO" class="headerlink" title="异步IO(Asynchronous IO)"></a>异步IO(Asynchronous IO)</h3><p>对于异步IO，进程发起recefrom的系统调用后，会立即收到返回结果，此时进程可以继续处理其他事情。当内核把数据接收完毕，同时拷贝到用户空间后，便发出一个signal给进程，通知进程来处理数据。</p><blockquote><p>异步IO在两个阶段都没有被阻塞<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190615210451.png" alt=""></p></blockquote><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>对于一次IO请求来说，都需要经历两个阶段，一是等待数据到来，二是等到内核把数据拷贝到用户空间</li><li>阻塞IO，非阻塞IO，IO多路复用都可以归类于同步IO，因为他们在第一个阶段或者第二阶段都会被阻塞，而异步IO在两个阶段都不会被阻塞</li><li><p>以吃饭为例子，可以对上述模型进行类比</p><pre><code> 阻塞IO：我到饭店吃饭，点完餐之后就在餐桌上干等，之后饭做好我去拿 非阻塞IO：点完餐之后，我每隔一段时间就去厨房问厨师饭是否做好，知道厨师告诉饭做好了 异步IO：类似于点外卖，我告诉店家我要吃什么，店家做好之后直接把饭送到家里，在这段时间我可以干其他事情</code></pre></li></ol><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://www.jianshu.com/p/486b0965c296" target="_blank" rel="noopener">聊聊Linux 五种IO模型</a></li><li><a href="https://mp.weixin.qq.com/s/MzrhaWMwrFxKT7YZvd68jw" target="_blank" rel="noopener">epoll的本质</a></li><li><a href="https://segmentfault.com/a/1190000003063859" target="_blank" rel="noopener">Linux IO模式及 select、poll、epoll详解</a>        </li><li><a href="https://cloud.tencent.com/developer/article/1005481" target="_blank" rel="noopener">大话 Select、Poll、Epoll</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 计算机基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>数据链路层协议设计与实现(2)</title>
      <link href="/2019/06/02/shu-ju-lian-lu-ceng-xie-yi-she-ji-yu-shi-xian-2/"/>
      <url>/2019/06/02/shu-ju-lian-lu-ceng-xie-yi-she-ji-yu-shi-xian-2/</url>
      
        <content type="html"><![CDATA[<h2 id="捎带确认"><a href="#捎带确认" class="headerlink" title="捎带确认"></a>捎带确认</h2><p>在上一篇<a href="https://bloodhunter.github.io/2019/06/02/shu-ju-lian-lu-ceng-xie-yi-she-ji-yu-shi-xian-1/" target="_blank" rel="noopener">数据链路层协议设计与实现(1)</a>中，我们看到的几个协议，对于信道的利用率都不高，原因在于数据基本都是单向传输。对于停等协议和自动重传协议来说，其实数据已经是双向传输的，但是反向传输的都是ACK，这样利用率也不高。</p><p>针对上述的情况，更好的做法是使用捎带确认的方式，将ACK和将要发送的数据放在一帧里面一起发送，这样可以减少发送的帧数。</p><p>使用捎带确认有个问题需要解决。因为我们无法预期下次发送的数据是在什么时候，如果很久都没有数据要发送，这样会导致ACK超时，从而使发送方重发。为了避免等待过长的时间，需要设置一个ACK定时器。当定时器超时，则单独发送ACK，而不是继续等待下次发送的数据。</p><h2 id="滑动窗口协议"><a href="#滑动窗口协议" class="headerlink" title="滑动窗口协议"></a>滑动窗口协议</h2><p>滑动窗口协议是双向协议，信道两端既是发送方又是接收方，可以提高信道的利用率。</p><p>滑动窗口的本质在于任一时刻，发送方都保留一组序号，表示发送方可以发送的帧号，即认为这些帧落在了<strong>发送窗口</strong>中，同理，接收方也维护一组序号，表示可以接收的帧，认为这些帧落在了<strong>接收窗口</strong>中。</p><p>接收窗口和发送窗口不必有一样的上下界，甚至不需要有一样的大小。下面分别来看下几种滑动窗口协议。</p><p>协议的基本接口定义可以参见上篇<a href="https://bloodhunter.github.io/2019/06/02/shu-ju-lian-lu-ceng-xie-yi-she-ji-yu-shi-xian-1/" target="_blank" rel="noopener">数据链路层协议设计与实现(1)</a></p><h2 id="1位滑动窗口协议"><a href="#1位滑动窗口协议" class="headerlink" title="1位滑动窗口协议"></a>1位滑动窗口协议</h2><p>顾名思义，1位滑动窗口协议的发送窗口和接收窗口大小都为1</p><pre><code>public void protocol() {    Frame frame = new Frame();    // 当前正在发送的帧的序列号    int currentSeq = 0;    // 期望收到的帧的序列号    int exceptSeq = 0;    Packet packet = fromNetworkLayer();    frame.setSeq(currentSeq);    frame.setPacket(packet);    frame.setAck(1 - exceptSeq);    toPhysicalLayer(frame);    startTimer(frame.getSeq());    while (true){        EventType event = waitForEvent();        if (event == FRAME_ARRIVAL){            frame = fromPhysicalLayer();            //对于发送方来说，如果收到一个正确的ACK            if (frame.getAck() == currentSeq){                stopTimer(currentSeq);                packet = fromNetworkLayer();                currentSeq = inc(currentSeq);            }            //对于接收方来说，如果收到了期望收到的帧            if (frame.getSeq() == exceptSeq){                toNetworkLayer(frame.getPacket());                exceptSeq = inc(exceptSeq);            }            frame.setPacket(packet);            frame.setSeq(currentSeq);            frame.setAck(1 - exceptSeq);            toPhysicalLayer(frame);            startTimer(currentSeq);        }    }}</code></pre><h2 id="回退n帧协议"><a href="#回退n帧协议" class="headerlink" title="回退n帧协议"></a>回退n帧协议</h2><p>在上述的协议中都默认有一个假设，一个帧到达接收方所需的时间加上ACK返回的时间是可以忽略不计的。然而事实却不是如此。如果发送方在ACK到来之后，才发送下一帧，那么信道大部分时间都处于空闲状态。例如，从A端到B端的时间是250ms，那么实际上发送一帧的时间需要(250 + 250)=500ms，因为一帧发送过去需要250ms，ACK返回回来需要250ms</p><p>所以更好的方式是，在等待ACK返回的这段时间里，可以多发送几帧，也就是把发送窗口设置大一点。</p><p>回退n帧协议的本质是，发送窗口为n，接收窗口为1，发送方会保存已经发送的帧，当接收方没有收到期望的帧时，发送方会重新发送之前已经发送的帧</p><pre><code>发送窗口size = 2^n - 1 接收窗口size = 1 public static final int MAX_SEQ = 7;// 发送窗口，用来保存发送方发送过的帧private Packet[] packets = new Packet[MAX_SEQ + 1];public void protocol() {    // 发送方正打算发送帧的帧号    int nextSeq = 0;    // 接收方期望收到帧的帧号    int exceptSeq = 0;    // 发送方期望收到的ACK    int exceptAck = 0;    // 当前发送窗口的size，MAX_SEQ - currentWindowSize表示空闲窗口的大小    int currentWindowSize = 0;    while (true){        EventType event = waitForEvent();        switch (event){            case NETWORK_LAYER_READY:                Packet packet = fromNetworkLayer();                sendData(nextSeq,exceptSeq,packet);                currentWindowSize = currentWindowSize + 1;                nextSeq = inc(nextSeq);                break;            case FRAME_ARRIVAL:                Frame frame = fromPhysicalLayer();                // 接收方收到了期望的帧                if (frame.getSeq() == exceptSeq){                    //将数据发送到网络层                    toNetworkLayer(frame.getPacket());                    // 期望收到下一帧                    exceptSeq = inc(exceptSeq);                }                // 如果收到ACK为n，则帧号为n-1,n-2，……的帧接收方也必然收到了(不然不会发送为帧号为n的帧号)                while (between(exceptAck,frame.getAck(),nextSeq)){                    //释放发送窗口                    currentWindowSize = currentWindowSize - 1;                    stopTimer(exceptAck);                    exceptAck = inc(exceptAck);                }                break;            case CSKSUM_ERROR:                break;            case TIMEOUT:                // 当超时，从期望收到的ACK开始回退                nextSeq = exceptAck;                for (int i = 1; i &lt;= currentWindowSize; i++){                    sendData(nextSeq, exceptAck, packets[nextSeq]);                    nextSeq = inc(nextSeq);                }                break;            default:        }        if (currentWindowSize &lt; MAX_SEQ){            enableNetworkLayer();        }else {            disableNetworkLayer();        }    }}/** * 发送一帧 * @param nextSeq 当前发送帧的帧号 * @param exceptSeq 期望收到帧的帧号 * @param packet 分组 */private void sendData(int nextSeq, int exceptSeq, Packet packet){    Frame frame = new Frame();    frame.setSeq(nextSeq);    /*假设期望收到帧的帧号为n，那么表示n-1帧(前一帧)肯定是收到了，所有ack=n-1,    又因为帧号是在[0,7]之间循环，n的前一帧 = (n + MAX_SEQ) % (MAX_SEQ + 1)     */    int ack = (exceptSeq + MAX_SEQ) % (MAX_SEQ + 1);    frame.setAck(ack);    frame.setPacket(packet);    packets[nextSeq] = packet;    toPhysicalLayer(frame);    startTimer(nextSeq);}/** * 可以释放发送窗口空间的情况 * 归根结底需要满足 exceptAck &lt;= currentAck &lt; nextSeq，只不过因为帧号是循坏的，所以需要考虑几种情况 * 帧号循环: 0123456701234567 * @param exceptAck 期望收到的ACK * @param currentAck 当前收到的ACK * @param nextSeq 当前准备发送帧的帧号 * @return */private boolean between(int exceptAck, int currentAck, int nextSeq){    boolean condition1 = exceptAck &lt;= currentAck &amp;&amp; currentAck &lt; nextSeq;    boolean condition2 = nextSeq &lt; exceptAck &amp;&amp; exceptAck &lt;= currentAck;    boolean condition3 = currentAck &lt; nextSeq &amp;&amp; nextSeq &lt; exceptAck;    return condition1 || condition2 || condition3;}</code></pre><h2 id="选择性重传协议"><a href="#选择性重传协议" class="headerlink" title="选择性重传协议"></a>选择性重传协议</h2><p>如果信道可靠性较高，错误发生的情况较少，那么可以使用回退n帧的协议。但是如果错误发生的比较频繁，大量重传，会导致带宽的浪费。</p><p>选择性重传协议的本质在于，保存已收到的帧(即使不是期望收到的帧号)，也就是接收窗口大于1。当收到期望的帧时，就是之前收到的帧一起发送给网络层。</p><pre><code>public class SelectRepeatProtocol implements Protocol {public static final int MAX_SEQ = 7;public static final int WINDOW_SIZE = 4;/** * 用来保存已发送的数据 */private Packet[] sendPackets = new Packet[WINDOW_SIZE];/** * 用来保存已接收的数据 */private Packet[] receivePackets = new Packet[WINDOW_SIZE];/** * 用来标记接收窗口被占用的情况，为true，表示第index位已经被占用 */private boolean[] arrivals = new boolean[WINDOW_SIZE];/** * 是否已经发送了NAK */private boolean noNak = true;@Overridepublic void protocol() {    // 正在发送帧的帧号    int nextSeq = 0;    // 接收方期望收到帧的帧号    int exceptSeq = 0;    // 发送方期望收到ACK    int exceptAck = 0;    // 当前发送窗口大小，表示发送方已经发送了多少帧    int sendWindowSize = 0;    // 接收窗口的上限边界    int upper = WINDOW_SIZE;    while (true){        EventType event = waitForEvent();        switch (event){            case NETWORK_LAYER_READY:                // 从网络层获取数据                Packet packet = fromNetworkLayer();                // 保存将要发送的数据保                sendPackets[nextSeq % WINDOW_SIZE] = packet;                sendFrame(DATA,nextSeq,exceptSeq,sendPackets);                // 帧号自增                nextSeq = inc(nextSeq);                // 发送窗口size自增                sendWindowSize = sendWindowSize + 1;                break;            case FRAME_ARRIVAL:                Frame frame = fromPhysicalLayer();                // 收到的是数据帧                if (frame.getKind() == DATA){                    /**                     * 1. 收到的不是期望的帧                     * 2. 还没有发送过NAK                     * 同时满足这两个条件，则发送NAK，让发送方重发接收方期望收到的帧                     */                    if (frame.getSeq() != exceptSeq &amp;&amp; noNak){                        sendFrame(NAK,0,exceptSeq,sendPackets);                    }else {                        // 启动ack定时器，一段时间内，没有反向数据发送，则为ACK单独发送一帧                        startAckTimer();                    }                    // 收到的帧在接收窗口中并且是第一次收到                    if (between(exceptSeq,frame.getSeq(),upper) &amp;&amp; !arrivals[frame.getSeq() % WINDOW_SIZE]){                        // 标记这一帧已经收到                        arrivals[frame.getSeq() % WINDOW_SIZE] = true;                        // 保存这一帧                        receivePackets[frame.getSeq() % WINDOW_SIZE] = frame.getPacket();                        //如果接收方期望的帧已经收到，则将接收窗口之前收到的帧一起发送给网络层                        while (arrivals[exceptSeq % WINDOW_SIZE]){                            toNetworkLayer(receivePackets[exceptSeq % WINDOW_SIZE]);                            noNak = true;                            //重置标记位                            arrivals[exceptSeq % WINDOW_SIZE] = false;                            exceptSeq = inc(exceptSeq);                            // 接收窗口的上限往前移一位                            upper = inc(upper);                            startAckTimer();                        }                    }                }                // 如果收到NAK，并且丢失帧位于发送窗口中，重发丢失的那一帧                if (frame.getKind() == NAK &amp;&amp; between(exceptAck, (frame.getAck() + 1) % (MAX_SEQ + 1),nextSeq)){                    sendFrame(DATA,(frame.getAck() + 1) % (MAX_SEQ + 1),exceptSeq,sendPackets);                }                // 释放发送窗口                while (between(exceptAck, frame.getAck(),nextSeq)){                    stopTimer(exceptAck % WINDOW_SIZE);                    exceptAck = inc(exceptAck);                    sendWindowSize = sendWindowSize - 1;                }                break;            case CSKSUM_ERROR:                // 收到损坏的帧，若没有发送过NAK，则发送NAK                if (noNak){                    sendFrame(NAK,0,exceptSeq,sendPackets);                }            case TIMEOUT:                break;            case ACK_TIMEOUT:                // 没有等到反向的流量进行捎带确认，则单独发送ACK                sendFrame(ACK,0,exceptSeq,sendPackets);                break;            default:        }    }}/** * 发送一帧 * @param kind 帧类型，数据帧，NAK * @param seq 帧号 * @param exceptSeq 期望收到的帧号 * @param packets 网络分组数据 */private void sendFrame(FrameKind kind,int seq,int exceptSeq,Packet[] packets){    Frame frame = new Frame();    if (kind == DATA){        frame.setPacket(packets[seq % WINDOW_SIZE]);    }    frame.setSeq(seq);    frame.setAck((exceptSeq + MAX_SEQ) % (MAX_SEQ + 1));    if (kind == NAK){        noNak = false;    }    if (kind == DATA){        startTimer(seq % WINDOW_SIZE);    }    stopAckTimer();}/** * 检测帧号是否在窗口之中，需要满足 * 窗口下边界 &lt; 检测帧号  &lt; 窗口上边界 * 由于帧号是循坏的，因此需要分别考虑几种情况 * @param except 窗口下边界 * @param current 检测帧号 * @param next 窗口上边界 * @return */private boolean between(int except, int current, int next){    boolean condition1 = except &lt;= current &amp;&amp; current &lt; next;    boolean condition2 = next &lt; except &amp;&amp; except &lt;= current;    boolean condition3 = current &lt; next &amp;&amp; next &lt; except;    return condition1 || condition2 || condition3;}}</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>滑动窗口协议是双向协议，可以提供信道的利用率</li><li>发送窗口和接收窗口的上下界不一定相同</li><li>在信道错误率较高的情况下，不适合使用回退n帧协议          </li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>数据链路层协议设计与实现(1)</title>
      <link href="/2019/06/02/shu-ju-lian-lu-ceng-xie-yi-she-ji-yu-shi-xian-1/"/>
      <url>/2019/06/02/shu-ju-lian-lu-ceng-xie-yi-she-ji-yu-shi-xian-1/</url>
      
        <content type="html"><![CDATA[<h2 id="数据链路层功能"><a href="#数据链路层功能" class="headerlink" title="数据链路层功能"></a>数据链路层功能</h2><p>数据链路层在TCP/IP协议模型里，位于第二层，它从网络层获取一个分组(packet)，并将其打包成一帧(frame)，然后发送给物理层。</p><p>当然数据链路层要做的不仅仅就只有这些，它要实现的功能还有许多，例如</p><ol><li>向网路层提供一个定义良好的服务接口</li><li>处理传输过程中的错误</li><li>调节数据流，确保接收方不会被发送方的数据给淹没</li></ol><p>下面逐步由简单的场景到复杂场景构建对应的协议</p><h2 id="接口定义"><a href="#接口定义" class="headerlink" title="接口定义"></a>接口定义</h2><p>后续实现的协议均实现了以下接口</p><pre><code>public interface Protocol {    int MAX_SEQ = 7;    /**     * 等待一个事件发生     * @return     */    default EventType waitForEvent(){        int i = ThreadLocalRandom.current().nextInt(EventType.values().length);        return EventType.values()[i];    }    /**     * 从网络层收到数据     * @return     */    default Packet fromNetworkLayer(){        return new Packet();    }    /**     * 向网络层发送数据     * @param packet 分组     */    default void toNetworkLayer(Packet packet){    }    /**     * 从物理层收到一帧     * @return     */    default Frame fromPhysicalLayer(){        return new Frame();    }    /**     * 发送一帧到物理层     * @param frame     */    default void toPhysicalLayer(Frame frame){    }    /**     * 启动定时器     * @param seq 帧号     */    default void startTimer(int seq){    }    /**     * 停止定时器     * @param seq 帧号     */    default void stopTimer(int seq){    }    /**     * 网络层允许接收数据     */    default void enableNetworkLayer(){    }    /**     * 网络层不允许接收数据     */    default void disableNetworkLayer(){    }    /**     * 帧号自增     * @param seq 帧号     * @return     */    default int inc(int seq){        if (seq &lt; MAX_SEQ){            return seq + 1;        }else{            return 0;        }    }    /**     * 协议具体实现     */    void protocol();}</code></pre><h2 id="无限制的单工协议"><a href="#无限制的单工协议" class="headerlink" title="无限制的单工协议"></a>无限制的单工协议</h2><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><ol><li>数据只能单向传输</li><li>传输方和接收方的网路层总是处于就绪状态，处理时间可以被忽略</li><li>接收方的缓存空间无限大</li><li>信道传输的数据永远不会丢失或者损坏</li></ol><h3 id="协议实现"><a href="#协议实现" class="headerlink" title="协议实现"></a>协议实现</h3><p>对于发送方来说，由于网路层处理数据的时间可以被忽略，同时数据不会损坏或者丢失，同时接收方的缓存空间无限大，无需考虑流控制，因此发送方只需不断的从网络层获取数据，然后发送给物理层即可</p><pre><code>protected void sender(){    while (true){        //1. 从网络层(上层)获取数据        Packet packet = fromNetworkLayer();        //2. 生成一帧        Frame frame = new Frame();        frame.setPacket(packet);        //3. 向物理层(下层)发送数据        toPhysicalLayer(frame);    }}</code></pre><p>对于接收方来说，由于缓存空间无限大，也无需考虑数据损坏丢失的情况，因此接收方只需要等待发送方发送的数据到来，然后发送给网络层即可  </p><pre><code>protected void receiver(){    while (true){        //1. 从物理层获取一帧        Frame frame = fromPhysicalLayer();        //2. 获取需要向网络层传输的数据        Packet packet = frame.getPacket();        //3. 想网络层发送数据        toNetworkLayer(packet);    }} </code></pre><h2 id="停等协议"><a href="#停等协议" class="headerlink" title="停等协议"></a>停等协议</h2><h3 id="应用场景-1"><a href="#应用场景-1" class="headerlink" title="应用场景"></a>应用场景</h3><p>在实际应用场景中，接收方的缓存空间不可能无限大，用来存储所有进来的帧，并且按序发送给上层，因此我们需要考虑流控制问题</p><ol><li>数据只能单向传输</li><li>接收方缓存空间有限，网络层处理数据需要时间</li><li>信道传输的数据永远不会丢失或者损坏</li></ol><h3 id="协议实现-1"><a href="#协议实现-1" class="headerlink" title="协议实现"></a>协议实现</h3><p>停等协议主要解决的是如何避免发送方用超过接收方处理能力的大量数据来淹没接收方。解决的方式也比较简单，发送方根据接收方的反馈信息来发送数据。每当接收方收到一帧数据，并处理完该数据之后，会向发送方发送一个哑帧，用于告诉发送方可以发送下一帧了。</p><p>因此，对于发送方来说，在发送一帧之后，必须等到接收方发过来的确认，才可以发送下一帧</p><pre><code>while (true){    //1. 从网络层(上层)获取数据    Packet packet = fromNetworkLayer();    //2. 生成一帧    Frame frame = new Frame();    frame.setPacket(packet);    //3. 向物理层(下层)发送数据    toPhysicalLayer(frame);    //4. 等待receiver发送帧已收到的事件    waitForEvent();}</code></pre><p>对于接收方来说，在处理完一帧之后，需要向发送方发送一个确认，表示其可以继续发送下一帧</p><pre><code>protected void receiver(){    // 告知sender帧已经收到的信号    Frame frameHasReceived = new Frame();    while (true){        //1. 等待sender发送数据        waitForEvent();        //2. 从物理层获取一帧        Frame frame = fromPhysicalLayer();        //3. 获取需要向网络层传输的数据        Packet packet = frame.getPacket();        //4. 想网络层发送数据        toNetworkLayer(packet);        //5. 告诉sender帧已经收到，可以发送下一帧        toPhysicalLayer(frameHasReceived);    }}</code></pre><h2 id="自动重复请求协议"><a href="#自动重复请求协议" class="headerlink" title="自动重复请求协议"></a>自动重复请求协议</h2><p>在实际生活中，信道传输的数据必然会出现丢失或者损坏的情况。数据链路层的职责就是将数据有序准确地发送给网络层。</p><p>那么如何解决这个问题呢？接收方在收到一帧之后，需要向发送方发送一个ACK，表明这一帧已经收到。同时     发送方需要设置一个定时器，如果在一定时间内没有收到ACK，则重复发送该帧。</p><p>由于接收方可能会收到一些重复的帧，因此接收方需要一种方式来区分某一帧是第一次收到的帧，还是重传的帧。解决这个问题的方式，就是在每一帧上加一个序列号。接收方通过检查帧号来区分新帧和重复帧。</p><p>序列号只需要一位就够了(0,1)。在任何时刻，接收方保存一个期望收到的序列号(exceptSeq)。如果收到的帧包含错误的序列号，则被认为是一个重复的帧而拒绝处理；如果包含正确的帧，则发送给网络层，同时期望收到的序列号模2增1(0 变成 1，1 变成 0)</p><pre><code>（seq + 1） mod 2</code></pre><h3 id="协议实现-2"><a href="#协议实现-2" class="headerlink" title="协议实现"></a>协议实现</h3><p>对于发送方来说，它需要考虑三种情形</p><ol><li>ACK完好无损地到达</li><li>ACK被损坏</li><li>定时器过期</li></ol><p>只有收到一个正确的ACK，发送方才会发送下一帧，否则则重复发送之前那一帧</p><pre><code>protected void sender(){    // 初始化，从网络层获取数据    Packet packet = fromNetworkLayer();    //初始化序列号    int nextSendSeq = 0;    Frame frame = new Frame();    while (true){        int seq = nextSendSeq;        frame.setPacket(packet);        frame.setSeq(seq);        //启动定时器        startTimer(seq);        //向物理层发送数据        toPhysicalLayer(frame);        //等待事件(只有FRAME_ARRIVAL事件)到来        EventType event = waitForEvent();        //从receiver收到一帧        if (event == FRAME_ARRIVAL){            frame = fromPhysicalLayer();            /* 如果ACK与之前发送的序列号相同，则表示receiver已正确收到该帧            如果序列号不一致，则会重复发送之前的一帧             */            if (frame.getAck() == seq){                //停止定时器                stopTimer(seq);                // 继续从网络层获取数据                packet = fromNetworkLayer();                // 序列号自增                nextSendSeq = inc(seq);            }        }    }}</code></pre><p>对于接收方来说，每收到一帧需要检查该帧的帧号是否与期望收到的帧号相同，若相同则处理，若不同则忽略</p><pre><code>protected void receiver(){    Frame frame = new Frame();    // receiver期待收到的帧号    int exceptSeq = 0;    while (true){        //等待收到一帧的事件        EventType event = waitForEvent();        if (event == FRAME_ARRIVAL){            //从物理层获取数据            frame = fromPhysicalLayer();            // 如果收到的帧号是期望收到            if (frame.getSeq() == exceptSeq){                //将收到的数据发送到网路层                toNetworkLayer(frame.getPacket());                //期望收到的序列号自增                exceptSeq = inc(exceptSeq);            }            //向sender发送ACK(无论是否收到正确的帧都需要发送ACK，sender只有收到ACK才知道该发哪一帧)            frame.setKind(FrameKind.ACK);            frame.setAck(1 - exceptSeq);            toPhysicalLayer(frame);        }    }}        </code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>数据链路层协议需要有错误控制以及流量控制的功能</li><li>通过接收方通过发送ACK来告知发送方数据已经收到，可以发送下一帧</li><li>接收方可以通过序列号来区分新帧和重复帧   </li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>OSI模型与TCP/IP模型</title>
      <link href="/2019/05/12/osi-mo-xing-yu-tcp-ip-mo-xing/"/>
      <url>/2019/05/12/osi-mo-xing-yu-tcp-ip-mo-xing/</url>
      
        <content type="html"><![CDATA[<h2 id="OSI模型与TCP-IP模型"><a href="#OSI模型与TCP-IP模型" class="headerlink" title="OSI模型与TCP/IP模型"></a>OSI模型与TCP/IP模型</h2><table><tr><th>OSI模型</th><th>TCP/IP模型</th><th>功能</th><th>协议</th><th>物理设备</th></tr><tr><td>应用层</td><td rowspan="3">应用层</td><td>文件传输，电子邮件，虚拟终端</td><td>TFTP，HTTP，SNMP，FTP，SMTP，DNS，Telnet</td><td></td></tr><tr><br><td>表示层</td><td>数据格式化，数据加密</td><td>无协议</td><td></td></tr><tr><td>会话层</td><td>解除或建立与别的节点的联系</td><td>无协议</td><td></td></tr><tr><td>传输层</td><td>传输层</td><td>提供端到端的连接</td><td>TCP，UDP</td><td>四层交换机</td></tr><tr><td>网络层</td><td>网络层</td><td>为数据包选择路由</td><td>IP，ICMP，RIP，OSPF，BGP，IGMP，ARP，RARP</td><td>三层交换机，路由器</td></tr><tr><td>数据链路层</td><td>数据链路层</td><td>传输有地址的帧以及错误检测功能</td><td>SLIP，CSLIP，PPP</td><td>网桥，以太网交换机</td></tr><tr><td>物理层</td><td>物理层</td><td>以二进制数据形式在物理媒体上传输数据</td><td>ISO2110，IEEE802，IEEE802.2</td><td>中继器，集线器</td><br></tr></table><h2 id="协议概览"><a href="#协议概览" class="headerlink" title="协议概览"></a>协议概览</h2><table><thead><tr><th style="text-align:center">协议名称</th><th>功能</th><th style="text-align:center">所在层</th></tr></thead><tbody><tr><td style="text-align:center">TFTP</td><td>Trivial File Transfer Protocol,简单文件传输协议，用来在客户端与服务机之间进行简单的文件传输，端口号69</td><td style="text-align:center">应用层</td></tr><tr><td style="text-align:center">HTTP</td><td>HyperText Transfer Protocol,超文本传输协议</td><td style="text-align:center">应用层</td></tr><tr><td style="text-align:center">SNMP</td><td>Simple Network Management Protocol,简单网络管理协议，主要用于管理和监控网络设备</td><td style="text-align:center">应用层</td></tr><tr><td style="text-align:center">FTP</td><td>File Transfer Protocol，文件传输协议，用于将文件从一个主机复制到另一个主机</td><td style="text-align:center">应用层</td></tr><tr><td style="text-align:center">SMTP</td><td>Simple Mail Transfer Protoco，简单邮件传输协议</td><td style="text-align:center">应用层</td></tr><tr><td style="text-align:center">DNS</td><td>Domain Name System，域名系统，用来将域名解析为IP地址</td><td style="text-align:center">应用层</td></tr><tr><td style="text-align:center">TCP</td><td>Transmission Control Protocol，传输控制协议，是一种面向连接，可靠的，基于字节流的传输层协议</td><td style="text-align:center">传输层</td></tr><tr><td style="text-align:center">UDP</td><td>User Datagram Protocol,用户数据报协议，是一种无连接，不可靠的传输协议</td><td style="text-align:center">传输层</td></tr><tr><td style="text-align:center">IP</td><td>Internet Protocol，互联网协议，用来在目的主机和源主机之间传输数据</td><td style="text-align:center">网络层</td></tr><tr><td style="text-align:center">ICMP</td><td>Internet Control Message Protocol，互联网控制消息协议，用于在IP协议中发送控制消息</td><td style="text-align:center">网络层</td></tr><tr><td style="text-align:center">RIP</td><td>Routing Information Protocol，路由信息协议，通过不断的交换信息让路由器动态的适应网络连接的变化</td><td style="text-align:center">网络层</td></tr><tr><td style="text-align:center">OSPF</td><td>Open Shortest Path First,开放式最短路径优先,是基于链路状态的路由协议</td><td style="text-align:center">网络层</td></tr><tr><td style="text-align:center">BGP</td><td>Border Gateway Protocol，边界网关协议，是互联网上一个核心的去中心化自治路由协议</td><td style="text-align:center">网络层</td></tr><tr><td style="text-align:center">IGMP</td><td>Internet Group Management Protocol，网路群组管理协议，是用于管理网路协议多播组成员的一种通信协议</td><td style="text-align:center">网络层</td></tr><tr><td style="text-align:center">ARP</td><td>Address Resolution Protocol，地址解析协议，是一个通过解析网络层地址来找寻数据链路层地址的网络传输协议，即将IP地址转换为MAC地址</td><td style="text-align:center">网络层</td></tr><tr><td style="text-align:center">RARP</td><td>逆地址解析协议，将MAC地址转换为IP地址</td><td style="text-align:center">网络层</td></tr><tr><td style="text-align:center">SLIP</td><td>Serial Line Internet Protocol,串列线路互联网协议，已被PPP协议取代</td><td style="text-align:center">数据链路层</td></tr><tr><td style="text-align:center">CSLIP</td><td>压缩的SLIP,可以提高SLIP的传输效率</td><td style="text-align:center">数据链路层</td></tr><tr><td style="text-align:center">PPP</td><td>Point-to-Point Protocol,点对点协议,在两节点间创建直接的连接</td><td style="text-align:center">数据链路层</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 计算机基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>git rebase,reset以及revert命令分析</title>
      <link href="/2019/05/03/git-rebase-reset-yi-ji-revert-ming-ling-fen-xi/"/>
      <url>/2019/05/03/git-rebase-reset-yi-ji-revert-ming-ling-fen-xi/</url>
      
        <content type="html"><![CDATA[<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><p>在讲述命令的使用姿势之前，我们首先需要了解git仓库的组成。git仓库主要由三部分组成，分别是工作空间(workspace), 暂存区(stage), 本地仓库。</p><ul><li>工作空间(workspace): 通过git进行版本管理的目录和文件</li><li>暂存区(stage): 所有更新都会先放到暂存区，直到我们把更新提交到仓库中</li><li>本地仓库: 存放在本地的版本库，<strong>HEAD指向当前本地仓库的最后一次提交</strong></li></ul><p>下图展示了文件如何在以上三个部分转换</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190512153125.png" alt=""></p><h1 id="git-rebase"><a href="#git-rebase" class="headerlink" title="git rebase"></a>git rebase</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><blockquote><p>rebase命令将某一个分支上的所有修改都转移至另一个分支上</p></blockquote><h2 id="操作示例"><a href="#操作示例" class="headerlink" title="操作示例"></a>操作示例</h2><p>从下图中我们可以看到两个分支master与branch1，他们有相同的祖先节点C1，表示这两个分支都是基于C1这次提交进行修改的<br><img src="https://ws4.sinaimg.cn/large/006tNc79ly1g2nubiqm38j30ra0ge0tg.jpg" alt=""> </p><p>如果我们使用rebase命令合并两个分支，命令如下，示意图如图</p><pre><code>git checkout branch1git rebase master</code></pre><p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1g2ohtgx1kjj30vi0bkt9h.jpg" alt=""></p><p>经过变基之后，在branch1的C3,C4提交将被删除，同时，在C2后面将生成C3’,C4’这两个提交，它们和C3，C4的提交内容一模一样，此时在合并branch1，即可以实行快进合并(fast-forword)<img src="https://ws1.sinaimg.cn/large/006tNc79ly1g2ohzhuogpj30x40bkgm9.jpg" alt=""></p><h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><p>适合场景</p><blockquote><p>本地未提交至远程的分支上，例如从master上开出一个分支进行开发，开发过程中，其他人将一些提交合并到master分支，此时使用rebase，在进行merge，可以使master的变更历史沿着一条直线前进</p></blockquote><p>不适合场景</p><blockquote><p>已提交至远程仓库的分支上，若你push一个分支到远程仓库，此时其他人已经pull下这条分支进行开发，而你又执行rebase操作，则会使变更历史变得混乱。</p></blockquote><h1 id="git-reset"><a href="#git-reset" class="headerlink" title="git reset"></a>git reset</h1><h2 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h2><blockquote><p>reset命令会移动HEAD到某个commit上</p></blockquote><p>git reset可以用来移除当前分支上的一些提交</p><h2 id="操作示例-1"><a href="#操作示例-1" class="headerlink" title="操作示例"></a>操作示例</h2><p>git reset有三种模式，soft，mixed，hard</p><ul><li>soft：工作空间和暂停区的内容都不会改变</li><li>mixed：默认模式，暂存区的内容将被指定的commit覆盖，而工作空间不受影响</li><li>hard：暂存区和工作空间都被指定的commit覆盖</li></ul><p>下面通过实际操作来看这三种模式的区别，首先创建一个git仓库，并新增一个文件file.txt，对文件进行了两次提交，最终log如下图所示</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190512155537.png" alt=""></p><p>此时file的内容为</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190512155711.png" alt=""></p><p>下面使用soft模式移除v2提交</p><pre><code>git reset --soft dd0d9dbf23b79991536be42cd158538b98ecce37</code></pre><p>此时log，git仓库状态以及file文件内容如下图所示<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190512160451.png" alt=""></p><p>可以看到file文件的内容没有被修改，说明工作空间内容不受影响。</p><p>执行git diff可以看到结果为空，说明工作空间和暂存区的内容一致，暂存区也不受影响</p><p>下面使用mixed模式移除提交<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190512161515.png" alt=""></p><p>下面使用hard模式移除提交<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190512162048.png" alt=""></p><h2 id="使用场景-1"><a href="#使用场景-1" class="headerlink" title="使用场景"></a>使用场景</h2><p>soft模式</p><blockquote><p>当你仅仅想修改commit msg，并想保留commit的内容时。</p></blockquote><p>mixed模式</p><blockquote><p>当你想在原来提交的基础上重新修改commit的内容时 </p></blockquote><p>hard模式<strong>(慎用)</strong></p><blockquote><p>当你想完全丢弃一些提交时</p></blockquote><h1 id="git-revert"><a href="#git-revert" class="headerlink" title="git revert"></a>git revert</h1><h2 id="定义-2"><a href="#定义-2" class="headerlink" title="定义"></a>定义</h2><blockquote><p>git revert命令会撤销某次提交，但是该提交之前和之后的提交都不会被撤销。git会新生成一个提交来记录此次撤销</p></blockquote><h2 id="操作实例"><a href="#操作实例" class="headerlink" title="操作实例"></a>操作实例</h2><p>下图是操作前，log的状态<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190512185754.png" alt=""></p><p>可以看到总有了三次提交记录，此时我们通过revert操作，撤销v3这次提交</p><pre><code>git revert c7c608e38a33c282aa3f08f857d4183b2f3c5575</code></pre><p>此时在支持git log，可以看到新增了一次提交，此次提交的影响是回滚了v3提交的操作<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/20190512190059.png" alt=""></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>git rebase和merge可以用来合并分支，只不过rebase可以master的提交历史始终沿着一条直线前进，使用rebase或者merge可以视情况而定，<strong>注意的是不要在已经push到远程仓库的分支上执行rebase操作</strong></li><li>注意checkout与reset的区别，checkout某一个文件，会使文件从暂存区中移到工作空间中，checkout HEAD则是进行分支的切换。reset会删除提交历史，而checkout不会</li><li>git revert是通过新生成一个提交来回滚之前提交造成的影响，<strong>它不会改变已有历史记录</strong></li><li><strong>从安全性的角度来看 revert &gt; checkout &gt; reset</strong></li></ol><p>#参考文献</p><ul><li><a href="https://git-scm.com/book/zh/v2/Git-%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA" target="_blank" rel="noopener">Git 分支 - 变基</a></li><li><a href="https://www.git-tower.com/learn/git/ebook/cn/command-line/advanced-topics/rebase" target="_blank" rel="noopener">Rebase 代替合并</a></li><li><a href="http://gitbook.liuhui998.com/4_2.html" target="_blank" rel="noopener">rebase</a></li><li><a href="https://www.cnblogs.com/jiangzhaowei/p/7879916.html" target="_blank" rel="noopener">git 仓库结构</a></li><li><a href="https://www.jianshu.com/p/9299e32faa62" target="_blank" rel="noopener">git revert用法</a></li><li><a href="https://github.com/geeeeeeeeek/git-recipes/wiki/5.2-%E4%BB%A3%E7%A0%81%E5%9B%9E%E6%BB%9A%EF%BC%9AReset%E3%80%81Checkout%E3%80%81Revert-%E7%9A%84%E9%80%89%E6%8B%A9" target="_blank" rel="noopener">代码回滚：Reset、Checkout、Revert 的选择</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring Boot启动流程扩展</title>
      <link href="/2019/05/02/spring-boot-qi-dong-liu-cheng-kuo-zhan/"/>
      <url>/2019/05/02/spring-boot-qi-dong-liu-cheng-kuo-zhan/</url>
      
        <content type="html"><![CDATA[<h2 id="Spring-Boot启动可扩展流程"><a href="#Spring-Boot启动可扩展流程" class="headerlink" title="Spring Boot启动可扩展流程"></a>Spring Boot启动可扩展流程</h2><p>通过上一篇<a href="https://bloodhunter.github.io/2019/04/27/spring-boot-qi-dong-liu-cheng-chu-tan/" target="_blank" rel="noopener">Spring Boot启动流程详解</a>，我们可知Spring Boot在以下几点可以进行扩展</p><ol><li>初始化器(Initializer)</li><li>监听器(Listener)</li><li>Runners</li></ol><p>下面依次来看下如何添加扩展</p><h2 id="Initializer"><a href="#Initializer" class="headerlink" title="Initializer"></a>Initializer</h2><p>Spring Boot在启动时会从META-INF/spring.factories文件中，加载<strong>ApplicationContextInitializer</strong>，下面是其定义</p><pre><code>    public interface ApplicationContextInitializer&lt;C extends ConfigurableApplicationContext&gt; {        void initialize(ConfigurableApplicationContext configurableApplicationContext);    }</code></pre><p>下面，我们定义一个类来实现该接口        </p><pre><code>@Slf4jpublic class CustomApplicationInitializer implements ApplicationContextInitializer {    @Override    public void initialize(ConfigurableApplicationContext configurableApplicationContext) {        log.info(&quot;自定义Initializer启动&quot;);    }}</code></pre><p>加载自定义的initializer的方式有两种，一是在main方法中add initializer<img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79ly1g2n8eqhkiqj31ra0hcaf6.jpg" alt="">另一种则更符合Spring Boot style，在META-INF/spring.factories中增加自定义initializer的配置<img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79ly1g2n8fihib4j30mk070wex.jpg" alt=""></p><pre><code>org.springframework.context.ApplicationContextInitializer=com.wbl.spingbootdemo.initializer.CustomApplicationInitializer</code></pre><p>启动Spring Boot则可以看到如下输出<img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79ly1g2n8hj5d8ej32120coq77.jpg" alt="">    </p><h2 id="Listener"><a href="#Listener" class="headerlink" title="Listener"></a>Listener</h2><p>Spring Boot启动的时候会从META-INF/spring.factories文件中加载<strong>ApplicationListener</strong>,<br>下面是其定义</p><pre><code>@FunctionalInterfacepublic interface ApplicationListener&lt;E extends ApplicationEvent&gt; extends EventListener {    void onApplicationEvent(ApplicationEvent applicationEvent;}</code></pre><p>ApplicationListener实现了EventListener接口，这是JDK中定义的一个类，用来实现观察者模式。只不过ApplicationListener只监听ApplicationEvent事件<img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79ly1g2n8udsethj31ah0u0tfs.jpg" alt="">    </p><p>下面实现一个自定的ApplicationListener，监听的几个事件都是继承SpringApplicationEvent的</p><pre><code>@Slf4jpublic class CustomApplicationListener implements ApplicationListener {    @Override    public void onApplicationEvent(ApplicationEvent applicationEvent) {        if (applicationEvent instanceof ApplicationStartingEvent){            log.info(&quot;receive application starting event&quot;);        }        if (applicationEvent instanceof ApplicationStartedEvent){            log.info(&quot;receive application started event&quot;);        }        if (applicationEvent instanceof ApplicationEnvironmentPreparedEvent) {            log.info(&quot;receive application environment prepared event&quot;);        }        if (applicationEvent instanceof ApplicationPreparedEvent){            log.info(&quot;receive application application prepared event&quot;);        }        if (applicationEvent instanceof ApplicationContextInitializedEvent){            log.info(&quot;receive application context initialized event&quot;);        }        if (applicationEvent instanceof ApplicationReadyEvent){            log.info(&quot;receive application ready event&quot;);        }    }}</code></pre><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79ly1g2n9w8x84aj31r80ewjzv.jpg" alt=""></p><p>启动Spring Boot可以看到如下输出<img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79ly1g2naef3ayyj31xw0tund9.jpg" alt="">    </p><p>总共监听到了以下事件</p><ol><li>ApplicationEnvironmentPreparedEvent</li><li>ApplicationContextInitializedEvent</li><li>ApplicationPreparedEvent</li><li>ApplicationStartedEvent</li><li>ApplicationReadyEvent</li></ol><p>而没有监听到的事件是ApplicationStartingEvent，这是因为在发送此事件时，日志对象还没有初始化成功，所有无法打印日志，如果使用System.out.println则可以看到输出</p><h2 id="Runner"><a href="#Runner" class="headerlink" title="Runner"></a>Runner</h2><p>Runner的实现分为两种</p><ol><li>ApplicationRunner</li><li>CommandLineRunner</li></ol><p>这两个实现本质上没有什么不同，除了接收参数不同</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79ly1g2nakvg24cj312w0iogob.jpg" alt=""><br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79ly1g2nalig576j30xg0ik76z.jpg" alt=""></p><h3 id="ApplicationRunner"><a href="#ApplicationRunner" class="headerlink" title="ApplicationRunner"></a>ApplicationRunner</h3><p>下面实现了一个自定义的ApplicationRunner</p><pre><code>@Service@Slf4j@Order(1)public class CustomApplicationRunner implements ApplicationRunner {    @Override    public void run(ApplicationArguments args) throws Exception {        log.info(&quot;启动自定义ApplicationRunner&quot;);    }}</code></pre><p>@Order用来决定Runner执行的顺序，数字越小，表示优先级越高，越先执行    </p><h3 id="CommandLineRunner"><a href="#CommandLineRunner" class="headerlink" title="CommandLineRunner"></a>CommandLineRunner</h3><p>下面实现一个自定义的CommandLineRunner</p><pre><code>@Service@Slf4j@Order(2)public class CustomCommandLineRunner implements CommandLineRunner {    @Override    public void run(String... args) throws Exception {        log.info(&quot;启动自定义CommandLineRunner&quot;);    }}    </code></pre><p>启动两个Runner可以看到如下输出<img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79ly1g2naylamacj31ii076adj.jpg" alt="">    </p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>Initializer需要实现ApplicationContextInitializer接口</li><li>Listener需要实现ApplicationListener</li><li>Initializer和Listener可以在META-INF/spring.factories进行配置，以便Spring Boot加载</li><li>Runner有ApplicationRunner和CommandLineRunner两种实现，两者除了接收参数不同外(一个接收ApplicationArguments，一个接收String[])，没有其他的区别</li><li>@Order注解用来决定Runner的执行顺序</li></ol><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://blog.csdn.net/dm_vincent/article/details/77151122" target="_blank" rel="noopener">Spring Boot 启动过程定制化</a></li><li><a href="https://www.jianshu.com/p/85460c1d835a" target="_blank" rel="noopener">Spring Boot：定制自己的starter</a></li><li><a href="https://www.cnblogs.com/gyjx2016/p/7479330.html" target="_blank" rel="noopener">springBoot之定制Banner</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Spring Boot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Boot </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring Boot启动流程初探</title>
      <link href="/2019/04/27/spring-boot-qi-dong-liu-cheng-chu-tan/"/>
      <url>/2019/04/27/spring-boot-qi-dong-liu-cheng-chu-tan/</url>
      
        <content type="html"><![CDATA[<p>刚接触Spring Boot的时候，相信大家都有接触过以下代码，这是Spring Boot的启动类，今天就来简单看下Spring Boot的启动流程</p><pre><code>@SpringBootApplicationpublic class Application {    public static void main(String[] args) {        SpringApplication.run(Application.class, args);    }}</code></pre><p>首先来看下SpringApplication.run()这个方法的真面目，</p><pre><code>public static ConfigurableApplicationContext run(Class&lt;?&gt;[] primarySources,        String[] args) {    return new SpringApplication(primarySources).run(args);}</code></pre><p>看源码可以发现这个方法主要做了两件事情</p><ol><li>初始化SpringApplication实例</li><li>调用run方法生成context</li></ol><p>下面分别来看下这两个流程，以下代码均属于2.1.4版本</p><h2 id="SpringApplication实例初始化"><a href="#SpringApplication实例初始化" class="headerlink" title="SpringApplication实例初始化"></a>SpringApplication实例初始化</h2><p>首先来看下SpringApplication初始化的流程</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1g2hl4nylaoj31k60hyq99.jpg" alt=""><br>可以看到整个流程分为了4步</p><ul><li><p>第一步，推断应用程序类型，Spring Boot的应有类型有REACTIVE，SERVLET，NONE<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1g2hla826qsj31gy0muq8p.jpg" alt=""><br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1g2hlc9rwjxj31hd0u041q.jpg" alt=""></p></li><li><p>第二步，设置initializers，Spring Boot将会从META-INF/spring.factories中加载相应的ApplicationContextInitializer</p></li></ul><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1g2hlh5ese2j31jw0b2gof.jpg" alt=""></p><ul><li>第三步，设置listener，Spring Boot将会从META-INF/spring.factories中加载相应的ApplicationListener</li></ul><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1g2hliyjnwxj31e40jkwje.jpg" alt=""></p><ul><li>第四步，加载main方法的定义类<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1g2hll7v2ayj31ha0p878p.jpg" alt=""></li></ul><h2 id="SpringApplication-run"><a href="#SpringApplication-run" class="headerlink" title="SpringApplication.run()"></a>SpringApplication.run()</h2><p>下面再来看下run方法的具体实现</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1g2hmls8dcbj30tw13gtho.jpg" alt=""></p><ol><li>从META-INF/spring.factories中加载SpringApplicationRunListener<img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1g2hmomy3vpj316s054wgb.jpg" alt=""></li><li>创建参数，即从run方法中传入args</li><li>设置程序运行所需的环境变量，SpringApplicationRunListener发送environmentPrepared的消息<img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1g2hmrwro2ej31ii0pmaj3.jpg" alt=""></li><li>创建ApplicationContext</li><li>初始化ApplicationContext，并设置环境变量，SpringApplicationRunListener发送contextLoaded消息</li><li>refresh ApplicationContext</li><li>SpringApplicationRunListener发送started信息</li><li>完成最终的程序的启动</li><li>SpringApplicationRunListener发送starting消息</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>Spring Boot的启动流程主要分为两步，一是初始化SpringApplication，二是调用run()来加载上下文环境</li><li>Spring Boot的应有类型有三种，REACTIVE(响应式web服务)，SERVLET(基于servlet的web服务)，NONE(非web服务)</li><li><p>SpringApplication.run()完成默认的执行流程，如果用户需要扩展执行流程，可以先初始化SpringApplication，在通过其setXXX的方法来增加扩展，最后在调用run来完成初始化</p><pre><code>  SpringApplication app = new SpringApplication(Application.class)  app.setXXX  app.run(args)</code></pre></li></ul><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://juejin.im/post/5b8f05a5f265da43296c6102" target="_blank" rel="noopener">SpringBoot 应用程序启动过程探秘</a></li><li><a href="https://juejin.im/post/5b3a24386fb9a024ed75ab36" target="_blank" rel="noopener">实战Spring Boot 2.0 Reactive编程系列</a></li><li><a href="https://blog.csdn.net/dm_vincent/article/details/76735888" target="_blank" rel="noopener">Spring Boot启动过程源码分析</a>    </li></ul>]]></content>
      
      
      <categories>
          
          <category> Spring Boot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Boot </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Prometheus查询之Vector match</title>
      <link href="/2019/04/27/prometheus-cha-xun-zhi-vector-match/"/>
      <url>/2019/04/27/prometheus-cha-xun-zhi-vector-match/</url>
      
        <content type="html"><![CDATA[<h2 id="Vector-Match"><a href="#Vector-Match" class="headerlink" title="Vector Match"></a>Vector Match</h2><p>vector match的含义如下</p><blockquote><p>根据一定的规则，对两个vector的label进行匹配，如果匹配成功，则对两个vector进行运算</p></blockquote><p>vector match有两种类型，一个是one to one，一个是one to many或者many to one</p><h2 id="one-to-one"><a href="#one-to-one" class="headerlink" title="one to one"></a>one to one</h2><pre><code>&lt;vector expr&gt; &lt;bin-op&gt; ignoring(&lt;label list&gt;) &lt;vector expr&gt;&lt;vector expr&gt; &lt;bin-op&gt; on(&lt;label list&gt;) &lt;vector expr&gt;</code></pre><blockquote><p>bin-op 表示运算操作符，”+,-,/,*”等</p><p>ignoring 表示忽略某些label来关联两个vector</p><p>on 表示根据某些label来关联两个vector</p></blockquote><p>例如vector1{label1,label2,label3}, vector2{label2,label3}, 则</p><pre><code>ignoring(label1) 表示通过label2和label3对vector进行匹配on(label2) 表示通过label2对vector进行匹配</code></pre><p>下面以一个实际的例子来说明one to one 的vector match</p><p>原始数据如下</p><pre><code>#vector1method_code:http_errors:rate5m{method=&quot;get&quot;, code=&quot;500&quot;}  24method_code:http_errors:rate5m{method=&quot;get&quot;, code=&quot;404&quot;}  30method_code:http_errors:rate5m{method=&quot;put&quot;, code=&quot;501&quot;}  3method_code:http_errors:rate5m{method=&quot;post&quot;, code=&quot;500&quot;} 6method_code:http_errors:rate5m{method=&quot;post&quot;, code=&quot;404&quot;} 21#vector2method:http_requests:rate5m{method=&quot;get&quot;}  600method:http_requests:rate5m{method=&quot;del&quot;}  34method:http_requests:rate5m{method=&quot;post&quot;} 120</code></pre><p>查询语句如下</p><pre><code>method_code:http_errors:rate5m{code=&quot;500&quot;} / ignoring(code) method:http_requests:rate5m</code></pre><p>首先vector1的label有method，code，vector2的label有method，根据ignoring(code)可知，两个vector是根据method进行关联，可以得到下表所示的match结果</p><table><thead><tr><th>vector1</th><th>vector2</th></tr></thead><tbody><tr><td>method_code:http_errors:rate5m{method=”get”, code=”500”} 24</td><td>method:http_requests:rate5m{method=”get”}  600</td></tr><tr><td>method_code:http_errors:rate5m{method=”post”, code=”500”} 6</td><td>method:http_requests:rate5m{method=”post”} 120</td></tr></tbody></table><p>因此，查询结果如下所示：</p><pre><code>{method=&quot;get&quot;}  0.04            //  24 / 600{method=&quot;post&quot;} 0.05            //   6 / 120</code></pre><p>上述查询语句等价于</p><pre><code>method_code:http_errors:rate5m{code=&quot;500&quot;} / on(method) method:http_requests:rate5m</code></pre><h2 id="one-to-many-many-to-one"><a href="#one-to-many-many-to-one" class="headerlink" title="one to many/many to one"></a>one to many/many to one</h2><pre><code>&lt;vector expr&gt; &lt;bin-op&gt; ignoring(&lt;label list&gt;) group_left(&lt;label list&gt;) &lt;vector expr&gt;&lt;vector expr&gt; &lt;bin-op&gt; ignoring(&lt;label list&gt;) group_right(&lt;label list&gt;) &lt;vector expr&gt;&lt;vector expr&gt; &lt;bin-op&gt; on(&lt;label list&gt;) group_left(&lt;label list&gt;) &lt;vector expr&gt;&lt;vector expr&gt; &lt;bin-op&gt; on(&lt;label list&gt;) group_right(&lt;label list&gt;) &lt;vector expr&gt;    </code></pre><blockquote><p>group_left   表示many to one</p><p>group_right  表示one to many</p></blockquote><p>下面还是以实际数据来说明，原始数据如下：</p><pre><code>#vector1method_code:http_errors:rate5m{method=&quot;get&quot;, code=&quot;500&quot;}  24method_code:http_errors:rate5m{method=&quot;get&quot;, code=&quot;404&quot;}  30method_code:http_errors:rate5m{method=&quot;put&quot;, code=&quot;501&quot;}  3method_code:http_errors:rate5m{method=&quot;post&quot;, code=&quot;500&quot;} 6method_code:http_errors:rate5m{method=&quot;post&quot;, code=&quot;404&quot;} 21#vector2method:http_requests:rate5m{method=&quot;get&quot;}  600method:http_requests:rate5m{method=&quot;del&quot;}  34method:http_requests:rate5m{method=&quot;post&quot;} 120</code></pre><p>查询语句如下：</p><pre><code>method_code:http_errors:rate5m / ignoring(code) group_left method:http_requests:rate5m</code></pre><p>上述查询语句表示通过method对两个vector进行匹配，vector1存在两个method=get的metric，两个method=post的metric，vector2各存在一个method=get已经method的metric，所以match结果如下</p><table><thead><tr><th>vector1</th><th>vector2</th></tr></thead><tbody><tr><td>method_code:http_errors:rate5m{method=”get”, code=”500”}  24</td><td>method:http_requests:rate5m{method=”get”}  600</td></tr><tr><td>method_code:http_errors:rate5m{method=”get”, code=”404”}  30</td><td>method:http_requests:rate5m{method=”get”}  600</td></tr><tr><td>method_code:http_errors:rate5m{method=”post”, code=”500”} 6</td><td>method:http_requests:rate5m{method=”post”} 120</td></tr><tr><td>method_code:http_errors:rate5m{method=”post”, code=”404”} 21</td><td>method:http_requests:rate5m{method=”post”} 120</td></tr></tbody></table><p>查询结果如下</p><pre><code>{method=&quot;get&quot;, code=&quot;500&quot;}  0.04            //  24 / 600{method=&quot;get&quot;, code=&quot;404&quot;}  0.05            //  30 / 600{method=&quot;post&quot;, code=&quot;500&quot;} 0.05            //   6 / 120{method=&quot;post&quot;, code=&quot;404&quot;} 0.175           //  21 / 120</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li><p>对于one to one表达的是，vector1和vector2根据on或者ignoring中的label组成的值是唯一的，也就是说vector1和vector2根据label list，不存在两个相同的label value</p></li><li><p>对于group_left(label list)来说，vector1的label list组成的value可以有多个，而vector2的label list组成的value只能有一个，而group_right(label list)则相反，vector1的值只能有一个，而vector2的值可以有多个</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 监控 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring-Boot Quick start</title>
      <link href="/2019/04/21/spring-boot-quick-start/"/>
      <url>/2019/04/21/spring-boot-quick-start/</url>
      
        <content type="html"><![CDATA[<h2 id="Create-Project"><a href="#Create-Project" class="headerlink" title="Create Project"></a>Create Project</h2><p>构建一个Spring Boot的项目非常方面，可以使用官方提供的Spring Initializr，打开<a href="https://start.spring.io/" target="_blank" rel="noopener">https://start.spring.io/</a>，输入项目基本信息即可构建一个项目</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1g2a8x5z7kkj31pw0u0jxb.jpg" alt=""></p><p>另外你还可以设置需要引入的依赖，点击set all，即可以选择需要引用的依赖</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1g2a8yyuwhlj31qp0u00xt.jpg" alt=""></p><p>最后点击生成，即可以得到一个压缩包，解压缩之后便可以得到一个Spring Boot项目</p><p>如果你是用的IDEA，则IDEA内置了Spring Initializer，按照提示可以方便构建项目</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1g2a91psir9j311n0u00yl.jpg" alt=""></p><h2 id="Maven-Install"><a href="#Maven-Install" class="headerlink" title="Maven Install"></a>Maven Install</h2><p>下面来看下如何使用maven来构建Spring boot项目。</p><p>利用maven来构建Spring boot 项目有两种方式</p><ol><li>继承spring-boot-starter-parent，使用Spring Initializer构建的项目都是采用这种方式</li><li>import Spring-boot的pom文件</li></ol><p>下面看下以上两种方式pom文件的配置</p><h3 id="inherits-spring-boot-starter-parent"><a href="#inherits-spring-boot-starter-parent" class="headerlink" title="inherits spring-boot-starter-parent"></a>inherits spring-boot-starter-parent</h3><pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;    xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;groupId&gt;com.example&lt;/groupId&gt;    &lt;artifactId&gt;myproject&lt;/artifactId&gt;    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;    &lt;!-- Inherit defaults from Spring Boot --&gt;    &lt;parent&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;        &lt;version&gt;2.1.4.RELEASE&lt;/version&gt;    &lt;/parent&gt;&lt;/project&gt;</code></pre><h3 id="import-Spring-boot-pom"><a href="#import-Spring-boot-pom" class="headerlink" title="import Spring-boot pom"></a>import Spring-boot pom</h3><pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;    xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;groupId&gt;com.example&lt;/groupId&gt;    &lt;artifactId&gt;myproject&lt;/artifactId&gt;    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;    &lt;dependencyManagement&gt;        &lt;dependencies&gt;            &lt;dependency&gt;                &lt;!-- Import dependency management from Spring Boot --&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;                &lt;version&gt;2.1.4.RELEASE&lt;/version&gt;                &lt;type&gt;pom&lt;/type&gt;                &lt;scope&gt;import&lt;/scope&gt;            &lt;/dependency&gt;        &lt;/dependencies&gt;    &lt;/dependencyManagement&gt;&lt;/project&gt;</code></pre><h2 id="Install-Application"><a href="#Install-Application" class="headerlink" title="Install Application"></a>Install Application</h2><p>下面以一个web服务为例，描述如何启动一个Spring Boot项目</p><p>首先生成一个Application类，Spring Boot的入口类</p><pre><code>@SpringBootApplicationpublic class Application{    public static void main(String[] args) {        SpringApplication.run(Application.class,args);    }}    </code></pre><p>@SpringBootApplication等价于@Configuration，@EnableAutoConfiguration,@ComponentScan三者合一    </p><p>第二步就是生成一个Controller</p><pre><code>@RestControllerpublic class DemoController {    @RequestMapping(&quot;/&quot;)    public String helloWorld() {        return &quot;Hello World&quot;;    }}</code></pre><p>@RestController注解用来告知Spring这是一个Restful的web Controller</p><p>@RequestMapping注解提供路由信息</p><p>下面就是启动项目了，首先需要在pom文件加入如下build插件，此时插件将生成一个可执行的jar</p><pre><code>&lt;build&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;</code></pre><p>之后运行maven命令，即可以得到jar</p><pre><code>mvn clean install</code></pre><p>得到可执行jar后，有两种启动方式  </p><ol><li>直接运行jar</li><li>以Unix service的方式运行</li></ol><h3 id="start-with-jar"><a href="#start-with-jar" class="headerlink" title="start with jar"></a>start with jar</h3><p>直接运行jar比较简单，直接输入一下命令即可以</p><pre><code>java -jar target/springbootDemo.jar</code></pre><h3 id="start-with-Unix-Service"><a href="#start-with-Unix-Service" class="headerlink" title="start with Unix Service"></a>start with Unix Service</h3><p>首先需要创建一个系统链接</p><pre><code>sudo ln -s /www/demo/springbootDemo.jar /etc/init.d/myapp</code></pre><p>此时，即可以启动项目</p><pre><code>service springbootDemo start</code></pre><p>运行成功之后，可以发现/var/run/springbootDemo/springbootDemo.pid这个文件，如果你想配置项目的相关配置，可以在jar的目录下，配置.conf的配置文件，例如</p><pre><code>springbootDemo.confLOG_FOLDER=/www/demo/log   //日志路径JAVA_OPTS=&quot;-Dfile.encoding=UTF-8 -Dspring.profiles.active=dev&quot;            </code></pre><h2 id="Spring-Active-Profile"><a href="#Spring-Active-Profile" class="headerlink" title="Spring Active Profile"></a>Spring Active Profile</h2><p>在实际的开发中，需要区分不同的部署环境，不同环境的配置是不一样的，例如dev，pre，pro环境，那么如何管理这些配置文件呢？</p><p>Spring Boot默认会去寻找application.properties或者application.yml文件来作为配置文件，我们可以通过spring.profiles.active参数来指定加载对应的配置文件，例如</p><pre><code>java -jar -Dspring.profiles.active=dev springbootDemo.jar</code></pre><p>则Spring Boot会去加载文件名为application-dev的配置文件</p><p>###@ActiveProfiles</p><p>在单元测试中，我们又可能需要加载配置文件，此时可以通过@ActiveProfiles注解来指定加载的配置文件</p><pre><code>@ActiveProfiles(&quot;local&quot;)    </code></pre><p>注意@ActiveProfiles只能在/src/test/java中使用</p><p>###@Profiles<br>@Profile声明的类，必须提供满足value属性中指定的条件，才会被注册到Spring容器中，例如</p><pre><code>@Profile(&quot;dev&quot;)@RestController@RequestMapping(&quot;/test&quot;)public class TestController {    @GetMapping(&quot;/greet&quot;)    public String greet() {        return &quot;Hey there!&quot;;    }}</code></pre><p>如果指定spring.profiles.active=pro，则    TestController则不会被加载到Spring容器中</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://docs.spring.io/spring-boot/docs/current/reference/html/deployment-install.html" target="_blank" rel="noopener">Installing Spring Boot Applications</a></li><li><a href="https://docs.spring.io/spring-boot/docs/current/reference/html/getting-started-installing-spring-boot.html#getting-started-maven-installation" target="_blank" rel="noopener">Installing Spring Boot</a></li><li><a href="https://spldeolin.com/posts/profile-activeprofiles/" target="_blank" rel="noopener">Spring Boot中@ActiveProfiles和@Profile的区别</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Spring Boot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Boot </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring-boot定时任务</title>
      <link href="/2019/04/20/spring-boot-ding-shi-ren-wu/"/>
      <url>/2019/04/20/spring-boot-ding-shi-ren-wu/</url>
      
        <content type="html"><![CDATA[<h2 id="create-project"><a href="#create-project" class="headerlink" title="create project"></a>create project</h2><p>使用IDEA创建一个scheduler-demo项目，这里可以使用spring initializr插件初始化spring boot</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1g291m3ryxrj311n0u00yl.jpg" alt=""></p><h2 id="EnableScheduling"><a href="#EnableScheduling" class="headerlink" title="@EnableScheduling"></a>@EnableScheduling</h2><p>注解EnableScheduling表示允许Spring Boot开启定时任务管理</p><pre><code>@SpringBootApplication@EnableSchedulingpublic class SchedulerDemoApplication {    public static void main(String[] args) {        SpringApplication.run(SchedulerDemoApplication.class, args);    }}</code></pre><h2 id="Scheduled"><a href="#Scheduled" class="headerlink" title="@Scheduled"></a>@Scheduled</h2><p>@Scheduled用来生成一个定时任务</p><p>@Scheduled的配置如下</p><table><thead><tr><th style="text-align:center">param</th><th style="text-align:center">explain</th></tr></thead><tbody><tr><td style="text-align:center">fixedDelay</td><td style="text-align:center">两个定时任务之间的间隔，即前一个任务执行完后，延迟delay毫秒再执行下一个任务</td></tr><tr><td style="text-align:center">fixedDelayString</td><td style="text-align:center">与fixedDelay相同，只不过用string类型表示时间</td></tr><tr><td style="text-align:center">fixedRate</td><td style="text-align:center">固定周期执行任务，例如每隔10s执行一次任务</td></tr><tr><td style="text-align:center">fixedRateString</td><td style="text-align:center">与fixedRate相同，用string表示时间</td></tr><tr><td style="text-align:center">cron</td><td style="text-align:center">用cron表达式来管理定时任务</td></tr><tr><td style="text-align:center">initialDelay</td><td style="text-align:center">执行第一个定时任务的延迟时间，只对fixedDelay或fixedRate任务生效</td></tr><tr><td style="text-align:center">initialDelayString</td><td style="text-align:center">与initialDelay相同</td></tr><tr><td style="text-align:center">zone</td><td style="text-align:center">时区，默认使用server的时区</td></tr></tbody></table><h3 id="fixedDelay与fixedRate的区别"><a href="#fixedDelay与fixedRate的区别" class="headerlink" title="fixedDelay与fixedRate的区别"></a>fixedDelay与fixedRate的区别</h3><p>对于fixedDelay任务，后个任务一定需要在前一个任务执行完并且再过delay毫秒后才会执行。对于下面的例子来说，delay为5s，而任务执行需要5s，所有每隔10s任务才会执行一次</p><pre><code>@Scheduled(fixedDelay = 5000)public void fixedDelayTask() throws Exception{    SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm&quot;);    System.out.println(dateFormat.format(new Date()) + &quot;:&quot; + &quot; task of fixed delay&quot;);    Thread.sleep(5000);}</code></pre><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1g292hzkr0wj31700nqtcz.jpg" alt=""></p><p>对于fixedRate任务，他们的执行是严格按照时间周期，即使上一个任务还未执行完毕，只要时间一到就会里面执行</p><pre><code>@Scheduled(fixedRate = 5000,initialDelay = 5000)public void fixedRateTask() throws Exception{    SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);    System.out.println(dateFormat.format(new Date()) + &quot;:&quot; + &quot; task of fixed rate&quot;);    Thread.sleep(5000);}</code></pre><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1g292nj7rxqj30u20rutca.jpg" alt=""></p><h3 id="cron表达式"><a href="#cron表达式" class="headerlink" title="cron表达式"></a>cron表达式</h3><pre><code>@Scheduled(cron = &quot;[Seconds] [Minutes] [Hours] [Day of month] [Month] [Day of week]&quot;)</code></pre><ul><li>second 取值在[0-59]，或者特殊字符 , - * /</li><li>minute 取值在[0-59], 或者特殊字符, - * /</li><li>hour 取值在[0-23],或者特殊字符, - * /</li><li>day of month 每个月第几天，取值在[0-31],或者特殊字段, - * / ? </li><li>month 取值[1-12]或者月份的英文描述，特殊字符为, - * /</li><li>day of week 取值为[1-7]，1表示星期天，2表示星期一，以此类推，也可用英文描述的星期，例如SUN，特殊字符为, - * / #</li></ul><table><thead><tr><th style="text-align:center">特殊字符</th><th style="text-align:center">含义</th></tr></thead><tbody><tr><td style="text-align:center">*</td><td style="text-align:center">表示任意值，若second为*，表示每秒都会触发该事件</td></tr><tr><td style="text-align:center">,</td><td style="text-align:center">表示列出枚举值，若minute为5,20 则表示第5分钟和第20分钟会触发事件</td></tr><tr><td style="text-align:center">/</td><td style="text-align:center">表示起始时间开始触发，然后每隔固定周期都会触发，例如minute为5/20，则在5分，25分，45分都会触发事件</td></tr><tr><td style="text-align:center">-</td><td style="text-align:center">表示取值范围，若minute为5-20，则表示从5分到20分，每分钟都会触发事件</td></tr><tr><td style="text-align:center">?</td><td style="text-align:center">只能用在每月第几天和星期两个域。表示不指定值，当2个子表达式其中之一被指定了值以后，为了避免冲突，需要将另一个子表达式的值设为”?”</td></tr><tr><td style="text-align:center">L</td><td style="text-align:center">表示最后，只能出现在week或者day of month中，若week为1L,表示在最后一个星期天</td></tr><tr><td style="text-align:center">W</td><td style="text-align:center">表示有效工作日(周一到周五),只能出现在day of month中</td></tr><tr><td style="text-align:center">#</td><td style="text-align:center">用于确定每个月第几个星期几，只能出现在day of month中，例如1#3 表示每个月第三个星期日</td></tr></tbody></table><h4 id="cron示例"><a href="#cron示例" class="headerlink" title="cron示例"></a>cron示例</h4><p>每天10点</p><pre><code>0 0 10 * * *</code></pre><p>每隔5分钟</p><pre><code>* */5 * * * *</code></pre><p>每天8点，8点半，9点，9点半，10点</p><pre><code>* */30 8-10 * * *</code></pre><h2 id="自定义线程池来管理定时任务"><a href="#自定义线程池来管理定时任务" class="headerlink" title="自定义线程池来管理定时任务"></a>自定义线程池来管理定时任务</h2><p>自定义线程池配置，例如线程池size，线程池名称</p><pre><code>@Configurationpublic class ScheduleConfig implements SchedulingConfigurer {    @Override    public void configureTasks(ScheduledTaskRegistrar scheduledTaskRegistrar) {        ThreadPoolTaskScheduler taskScheduler = new ThreadPoolTaskScheduler();        taskScheduler.setPoolSize(10);        taskScheduler.setThreadNamePrefix(&quot;schedule-task-pool&quot;);        taskScheduler.initialize();        scheduledTaskRegistrar.setTaskScheduler(taskScheduler);    }}</code></pre><p>定义一个cron任务</p><pre><code>@Scheduled(cron = &quot;*/5 * * * * *&quot;)public void cronTask(){    String name = Thread.currentThread().getName();    SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);    System.out.println(String.format(&quot;%s: current thread %s&quot;, dateFormat.format(new Date()), name));}</code></pre><p>运行程序，可以得到如下的运行结果，可以看到此时定时任务是运行在自定义的线程池里        </p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1g29486h5y6j311a08amyp.jpg" alt=""></p><h2 id="动态管理定时任务"><a href="#动态管理定时任务" class="headerlink" title="动态管理定时任务"></a>动态管理定时任务</h2><p>使用ThreadPoolTaskScheduler来生成定时任务，在通过维护定时任务的ScheduleFuture的map来实现动态管理定时任务</p><h3 id="DynamicScheduleTaskManager"><a href="#DynamicScheduleTaskManager" class="headerlink" title="DynamicScheduleTaskManager"></a>DynamicScheduleTaskManager</h3><pre><code>@Componentpublic class DynamicScheduleTaskManager {    private ThreadPoolTaskScheduler taskScheduler = new ThreadPoolTaskScheduler();    private Map&lt;Integer, ScheduledFuture&gt; futureMap = new HashMap&lt;&gt;();    @PostConstruct    public void init(){        taskScheduler.initialize();    }    /**     * 增加定时任务，若任务已存在，则删除旧任务，更新新任务     * @param taskConfig     */    public void addOrUpdateTask(TaskConfig taskConfig){        int taskConfigId = taskConfig.getId();        if (futureMap.containsKey(taskConfigId)){            deleteTask(taskConfig);        }        ScheduledFuture&lt;?&gt; scheduledFuture = taskScheduler.schedule(() -&gt; {            SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);            String timeFormat = dateFormat.format(new Date());            System.out.println(String.format(&quot;time:%s,process task,id:%d&quot;,timeFormat,taskConfigId));        }, new CronTrigger(taskConfig.getCron()));        futureMap.put(taskConfigId, scheduledFuture);    }    /**     * 删除任务     * @param taskConfig     */    public void deleteTask(TaskConfig taskConfig){        int taskConfigId = taskConfig.getId();        if (futureMap.containsKey(taskConfigId)){            ScheduledFuture scheduledFuture = futureMap.get(taskConfigId);            scheduledFuture.cancel(true);            System.out.println(&quot;delete task,id:&quot; + taskConfigId);        }    }}        TaskConfig@Getter@Setterpublic class TaskConfig {    /**     * id of task     */    private int id;    /**     * cron expression     */    private String cron;}</code></pre><h3 id="ScheduleController"><a href="#ScheduleController" class="headerlink" title="ScheduleController"></a>ScheduleController</h3><pre><code>@RestController@RequestMapping(produces = &quot;application/json; charset=utf-8&quot;)public class ScheduleController {    @Autowired    private DynamicScheduleTaskManager scheduleTaskManager;    @PostMapping(&quot;/add/task&quot;)    public String addTask(@RequestBody TaskConfig taskConfig){        scheduleTaskManager.addOrUpdateTask(taskConfig);        return &quot;success&quot;;    }    @PostMapping(&quot;/delete/task&quot;)    public void deleteTask(@RequestBody TaskConfig taskConfig){        scheduleTaskManager.deleteTask(taskConfig);    }}    </code></pre><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>####1. 新增taskConfig</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1g295imsq3uj31c80fwjt8.jpg" alt=""></p><p>####2. 更新taskConfig</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1g295kc5vt5j31c80e2myy.jpg" alt=""></p><p>####3. 删除taskConfig<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1g295kx02yej31ck0es765.jpg" alt=""></p><p>####4.输出</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1g295nz4evhj31b80feq68.jpg" alt=""></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://cloud.tencent.com/info/9d5782f8b475dfa8c41968f11aaea733.html" target="_blank" rel="noopener">SpringBoot定时任务及Cron表达式详解</a></li><li><a href="https://dzone.com/articles/running-on-time-with-springs-scheduled-tasks" target="_blank" rel="noopener">Running on Time With Spring’s Scheduled Tasks</a></li><li><a href="https://www.callicoder.com/spring-boot-task-scheduling-with-scheduled-annotation/" target="_blank" rel="noopener">How to Schedule Tasks with Spring Boot</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Spring Boot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Boot </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Raft协议之日志复制</title>
      <link href="/2019/03/31/raft-xie-yi-zhi-ri-zhi-fu-zhi/"/>
      <url>/2019/03/31/raft-xie-yi-zhi-ri-zhi-fu-zhi/</url>
      
        <content type="html"><![CDATA[<p>上篇<a href="https://bloodhunter.github.io/2019/03/30/raft-xie-yi-zhi-leader-xuan-ju/" target="_blank" rel="noopener">Raft协议之Leader选举</a>介绍了Leader选举的过程。Leader会处理来自客户端的请求，并将客户端更新操作以消息(Append Entries消息)的形式发送到集群中所有Follower节点。本文将介绍Raft协议日志复制的流程。</p><h2 id="日志复制"><a href="#日志复制" class="headerlink" title="日志复制"></a>日志复制</h2><p>假设集群中有A，B，C三个节点，其中节点A为Leader，此时有一个客户端发送了一个更新操作到集群，</p><ol><li>当收到客户端的请求，节点A会将更新操作记录到本地Log中</li><li>节点A向其他节点发送Append Entries消息，消息中记录了Leader节点最近收到的请求日志</li><li>B,C收到来自Leader的Append Entries消息时，会将该操作记录到本地Log中，并返回响应消息</li><li>当A收到超过半数的响应消息时，会认为集群中有半数以上的节点已经记录了该更新操作。Leader节点将该日志设置为已提交(committed)</li><li>Leader向客户端返回响应，并通知Follower节点该日志已被提交</li><li>Follower收到消息时，才会认为该日志已被提交</li></ol><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tKfTcgy1g1m0wfu6bzj31em0eatbw.jpg" alt=""><br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tKfTcgy1g1m149rhf4j31ok0e4dil.jpg" alt=""></p><h2 id="日志一致性"><a href="#日志一致性" class="headerlink" title="日志一致性"></a>日志一致性</h2><p>当一个新的Leader被选举出来，它的日志可能会其他Follower不一致，这时候需要一个机制来保证日志的一致性。</p><p>集群中每个节点都会维护一个本地log用于记录操作，另外，每个节点还会维护两个索引值，分别是commitIndex和lastApplied</p><blockquote><p>commitIndex表示当前节点<strong>已知的，最大的，已提交</strong>的日志索引</p><p>lastApplied索引表示当前节点最后一条被应用到状态机的日志索引，当commitIndex大于lastApplied时，会将lastApplied加1，并将lastApplied对应的日志应用到状态机</p></blockquote><p>Leader节点还需要知道每个Follower节点的日志复制到哪个位置，从而决定下次发送Append Entries消息中包含哪些日志记录。为此Leader会会维护两个数组，nextIndex[]和matchIndex[]</p><blockquote><p>nextIndex[]记录了需要发给每个Follower的下一条日志的索引值</p><p>matchIndex[]记录了已经复制给每个Follower的最大的日志索引值</p></blockquote><p>下面通过一个示例来说明nextIndex[]和matchIndex[]在日志复制过程的作用，假设有三个节点A,B,C，其中节点A为term=1的Leader，C由于宕机导致一段时间没有与Leader同步日志，此时C的log并不包含全部已提交日志，此时Leader记录的nextIndex[]和matchIndex[]的值如下</p><table><thead><tr><th>节点</th><th>nextIndex</th><th>matchIndex</th></tr></thead><tbody><tr><td>A</td><td>4</td><td>3</td></tr><tr><td>B</td><td>4</td><td>3</td></tr><tr><td>C</td><td>2</td><td>1</td></tr></tbody></table><p>因为Leader中记录了C的nextIndex=2，所以会向C发送index=2的Append Entries消息。C收到消息之后，会将日志记录到本地log中，并向Leader发送响应。Leader收到响应后，会递增C对应的nextIndex和matchIndex</p><table><thead><tr><th>节点</th><th>nextIndex</th><th>matchIndex</th></tr></thead><tbody><tr><td>A</td><td>4</td><td>3</td></tr><tr><td>B</td><td>4</td><td>3</td></tr><tr><td>C</td><td>3</td><td>2</td></tr></tbody></table><p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1g1m1z1w3kqj30so0f4q3p.jpg" alt=""></p><p>如果在上述例子中，节点C故障恢复后，节点A宕机后重启，导致节点B成为term=2的新Leader，此时B不知道旧Leader节点的nextIndex和matchIndex，所以新的Leader会重置nextIndex[]和matchIndex[],其中nextIndex[]全部重置为新Leader节点自身最后一条已提交日志的index值，而matchIndex[]全部重置为0</p><table><thead><tr><th>节点</th><th>nextIndex</th><th>matchIndex</th></tr></thead><tbody><tr><td>A</td><td>4</td><td>0</td></tr><tr><td>B</td><td>4</td><td>0</td></tr><tr><td>C</td><td>4</td><td>0</td></tr></tbody></table><p>新的Leader会发送新的Append Entries消息(term=2,index=4),对于C节点，它没有index=2，index=3两条日志，因此追加失败。</p><p>Leader收到C追加日志失败的响应，会将nextIndex减1，即发送(term=2,index=3)的Append Entries消息给C。循环反复，不断减小nextIndex的值，直到节点C返回追加成功的响应。</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1g1m2man8dgj31mq0fignb.jpg" alt=""></p><h2 id="选举限制"><a href="#选举限制" class="headerlink" title="选举限制"></a>选举限制</h2><ol><li>Candidate在拉票时需要携带自己本地已经持久化的最新的日志信息，等待投票的节点如果发现自己本地的日志信息比竞选的Candidate更新，则拒绝给他投票</li><li>只允许Leader提交（commit）当前Term的日志。</li></ol><p>第一条限制保证了已经Commited日志不会丢失，第二条限制是为了防止即使超过半数的节点已提交了日志，依然有可能被新选Leader覆盖的情况</p><p>例如<br><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1g1m2ryimtfj312z0u0142.jpg" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> Raft </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Raft </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Raft协议之Leader选举</title>
      <link href="/2019/03/30/raft-xie-yi-zhi-leader-xuan-ju/"/>
      <url>/2019/03/30/raft-xie-yi-zhi-leader-xuan-ju/</url>
      
        <content type="html"><![CDATA[<h2 id="Raft节点状态"><a href="#Raft节点状态" class="headerlink" title="Raft节点状态"></a>Raft节点状态</h2><p>Raft协议的工作模式是一个Leader和多个Follower节点的模式。在Raft协议中，每个节点都维护了一个状态机，该状态机有3种状态，Leader，Follower，Candidate，在任意时间，集群中的任意节点都处于这三个状态之一。</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tKfTcgy1g1kyvbmbw1j30ua0fw3zt.jpg" alt=""></p><h3 id="Leader"><a href="#Leader" class="headerlink" title="Leader"></a>Leader</h3><blockquote><p>Leader节点的主要工作有两个，一个是处理所有client的请求，另一个是定期向Follower节点发送心跳信息。</p><p>当收到客户端写入请求时，Leader节点会在本地追加一个日志，然后将其封装成消息发送到集群中的其他Follow节点。Follower节点收到对应消息对其进行响应。Leader如果收到超过半数节点的响应信息，则认为该条日志已被committed，可以对client返回响应</p><p>定期向Follower发送心跳信息是为了防止集群其他Follower节点的选举计时器超时而导致触发新一轮选举</p></blockquote><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tKfTcgy1g1kx1bm3g3j30ra0jugmo.jpg" alt=""></p><h3 id="Follower"><a href="#Follower" class="headerlink" title="Follower"></a>Follower</h3><blockquote><p>Follower节点不会处理任何请求，他们只是简单的响应来自Leader或者Candidate的请求。Follower会将client节点的请求重定向给集群的Leader节点</p></blockquote><h3 id="Candidate"><a href="#Candidate" class="headerlink" title="Candidate"></a>Candidate</h3><blockquote><p>Candidate节点由Follower节点转换而来，当Follower节点长时间没有收到来自Leader节点发送的心跳信息，则该节点的选举计时器就会过期，同时将自身状态变为Candidate，发起新一轮选举</p></blockquote><h2 id="Leader选举"><a href="#Leader选举" class="headerlink" title="Leader选举"></a>Leader选举</h2><p>在Raft协议中有两个时间控制Leader选举发生</p><ol><li>选举超时时间(election timeout)</li><li>心跳超时时间(heartbeat timeout)</li></ol><blockquote><p>选举超时时间：Follower在election timeout时间内没有收到Leader的心跳信息，则切换为Candidate开始新一轮的选举。election timeout一般设置为150ms~300ms的随机数，<strong>也即每个节点的选举超时时间一般都不同</strong></p><p>心跳超时时间：Leader向Follower节点发送心跳消息的<strong>间隔</strong>时间</p></blockquote><h3 id="初始选举"><a href="#初始选举" class="headerlink" title="初始选举"></a>初始选举</h3><ol><li>集群初始化时，所有节点为Follower</li><li>在经过一段时间后(election timeout)收不到Leader的心跳信息，则认为Leader出现故障，切换为Candidate发起选举</li><li>Raft协议中每次发起选举，任期(Term)都会进行递增，每个节点都会记录当前任期(currentTerm)</li><li>当一个Candidate收到超过半数节点的选票，则成为Leader</li></ol><p>假设集群有A，B,C三个节点，若A节点的选举超时时间最先超时，则</p><ol><li>A切换为Candidate，同时重置选举计时器(election timer)</li><li>A先把票投给自己，并向集群其他节点B,C发送选举请求(Request vote)，此时A的term=1</li><li>B,C收到选举请求时，因为两个节点的term=0，且都是Follower状态，所以它们会把选票投给A节点</li><li>B,C节点投票之后，会重置选举计时器，这是防止一个任期中出现多个Candidate，导致选举失败</li><li>A节点得到超过半数的选票，在term=1的任期中，A成为集群的Leader</li><li>A节点成为Leader后，会定期向B,C节点发送心跳信息，防止B,C节点的选举计时器超时而触发新一轮选举，所以心跳超时时间要远小于选举超时时间</li></ol><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tKfTcgy1g1l00eqkbaj314x0u00xd.jpg" alt=""></p><h3 id="出现多个Candidate节点"><a href="#出现多个Candidate节点" class="headerlink" title="出现多个Candidate节点"></a>出现多个Candidate节点</h3><p>当出现多个Candidate同时发起选举，而每个Candidate都获取不到半数的选票，这种情况Raft情况会如何处理呢？</p><p>假设集群有4个节点，其中节点A和节点B的选举计时器同时到期，切换为Candidate并向集群其他节点发起选举请求</p><ol><li>假设A的选举请求先到C，而B的请求先到D，则节点A和节点B得票数都为2，没有超过半数</li><li>在这种情况下，这次选举以失败结束，随着时间流逝，当任意节点的选举计时器到期后，会再一次发起选举。</li><li>由于election timeout是一个时间区间内取的随机数，所以上述情况多次出现的概率不大</li></ol><h3 id="宕机选举"><a href="#宕机选举" class="headerlink" title="宕机选举"></a>宕机选举</h3><p>假设集群中有4个节点，其中A为Leader，B，C，D为Follower，在系统运行一段时间后(当前term为5)，A因为故障而宕机。</p><ol><li>由于Leader不在往Follower发送心跳消息，Follower的election timer将会过期，假设为D节点最先超时，切换为Candidate发起新一轮选举</li><li>当B和C收到节点D的选举请求后，会将其选票投给D，由于节点A已经宕机，无法投票，但D节点仍获得超过半数的投票，成为新任期(term=6)的Leader，并开始向其他节点发送心跳信息</li><li>当A节点恢复后，会收到来自D节点的心跳信息，改信息中携带的任期号(term=6)大于节点A当前记录的任期号(term=5),A节点切换为Follower</li></ol><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tKfTcgy1g1lxrmbw9ij31pa0iw42h.jpg" alt=""></p><p>在Raft协议中，当某个节点收到的消息中所携带的任期号大于当前节点记录的任期号，那么节点会自动切换为Follower，并且更新自身记录的任期号</p><h2 id="Leader选举时间要求"><a href="#Leader选举时间要求" class="headerlink" title="Leader选举时间要求"></a>Leader选举时间要求</h2><p>通过上述几个例子，可以看到Leader选举对于时间的要求比较严格，一般要求整个集群的时间满足如下不等式</p><pre><code>广播时间 &lt;&lt; 选举超时时间 &lt;&lt; 平均故障间隔时间</code></pre><p>广播时间指从一个节点发送心跳信息到其他节点收到信息并发出响应的平均时间</p><p>平均故障时间是指一个节点，两次故障之间的平均时间。</p><p>为了保证集群可用，广播时间必须比选举超时时间小一个数量级，这样Leader才能发送心跳信息来重置其他Follower的选举计时器，从而防止他们切换为Candidate，触发新一轮选举。选举超时时间是一个<strong>随机数</strong>    ，这样可以减少出现多个Candidate而瓜分选票的情况。</p><p>一般情况广播时间可以做到0.5ms~50ms，选举超时时间一般设置为200ms~1s之间。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>Raft协议中节点有三种状态Leader，Follower，Candidate</li><li>控制选举触发的时间有两个，一是选举超时时间(election timeout)，一个心跳超时时间(heartbeat timeout)</li><li>选举计时器(election timer)每次重置都会从某个时间区间随机取一个随机数，作为新的选举超时时间，这样是为了避免出现多个Candidate而导致选举无效的情况出现</li></ol>]]></content>
      
      
      <categories>
          
          <category> Raft </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Raft </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring Boot多数据源</title>
      <link href="/2019/03/23/spring-boot-duo-shu-ju-yuan/"/>
      <url>/2019/03/23/spring-boot-duo-shu-ju-yuan/</url>
      
        <content type="html"><![CDATA[<h2 id="maven-配置"><a href="#maven-配置" class="headerlink" title="maven 配置"></a>maven 配置</h2><pre><code>&lt;parent&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;    &lt;version&gt;2.1.3.RELEASE&lt;/version&gt;    &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt;&lt;dependencies&gt;     &lt;dependency&gt;        &lt;groupId&gt;mysql&lt;/groupId&gt;        &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;        &lt;scope&gt;runtime&lt;/scope&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;        &lt;optional&gt;true&lt;/optional&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;        &lt;artifactId&gt;lombok&lt;/artifactId&gt;        &lt;optional&gt;true&lt;/optional&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;        &lt;scope&gt;test&lt;/scope&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;    &lt;/dependency&gt; &lt;/dependencies&gt;</code></pre><h2 id="application-properties-配置"><a href="#application-properties-配置" class="headerlink" title="application.properties 配置"></a>application.properties 配置</h2><p>配置两个数据源</p><pre><code>## 数据源1user.datasource.jdbc-url=jdbc:mysql://localhost:3306/testuser.datasource.username=rootuser.datasource.password=root## 数据源2product.datasource.jdbc-url=jdbc:mysql://172.16.28.3:6606/testproduct.datasource.username=rootproduct.datasource.password=meitu.com</code></pre><h2 id="数据实例"><a href="#数据实例" class="headerlink" title="数据实例"></a>数据实例</h2><p>构建两个实例与两个数据源中的表格对应</p><h3 id="user"><a href="#user" class="headerlink" title="user"></a>user</h3><pre><code>@Entity@Getter@Setterpublic class User {    @Id    @GeneratedValue(strategy = GenerationType.IDENTITY)    private int id;    private String name;}    CREATE TABLE `user` (  `id` int(11) NOT NULL AUTO_INCREMENT,  `name` varchar(20) DEFAULT NULL,  PRIMARY KEY (`id`))</code></pre><h3 id="product"><a href="#product" class="headerlink" title="product"></a>product</h3><pre><code>@Entity@Getter@Setterpublic class Product {    @Id    @GeneratedValue(strategy = GenerationType.IDENTITY)    private int id;    private String name;}CREATE TABLE `product` (  `id` int(11) NOT NULL AUTO_INCREMENT,  `name` varchar(20) DEFAULT NULL,  PRIMARY KEY (`id`))</code></pre><h2 id="包结构"><a href="#包结构" class="headerlink" title="包结构"></a>包结构</h2><p>为了读取不同数据源的配置，根据包结构来对配置进行区分</p><pre><code>src/main/java    - com.wbl.springDemo        - produce            - data                        - repo                        - config        - user            - data            - repo            - config</code></pre><h3 id="ProductDao"><a href="#ProductDao" class="headerlink" title="ProductDao"></a>ProductDao</h3><pre><code>@Repositorypublic interface ProductDao extends JpaRepository&lt;Product, Integer&gt; {}                </code></pre><h3 id="UserDao"><a href="#UserDao" class="headerlink" title="UserDao"></a>UserDao</h3><pre><code>@Repositorypublic interface UserDao extends JpaRepository&lt;User, Integer&gt; {}    </code></pre><h2 id="数据源配置"><a href="#数据源配置" class="headerlink" title="数据源配置"></a>数据源配置</h2><h3 id="user配置"><a href="#user配置" class="headerlink" title="user配置"></a>user配置</h3><pre><code>@Configuration@EnableTransactionManagement@EnableJpaRepositories(        entityManagerFactoryRef = &quot;userEntityManagerFactory&quot;,        transactionManagerRef = &quot;userTransactionManager&quot;,        basePackages = {                &quot;com.wbl.spingbootdemo.muldatasource.user.repo&quot;        })public class UserConfig {    @Primary    @Bean(&quot;userDatasource&quot;)    @ConfigurationProperties(&quot;user.datasource&quot;)    public HikariDataSource userDatasource(){        return DataSourceBuilder.create().type(HikariDataSource.class).build();    }    @Primary    @Bean(&quot;userEntityManagerFactory&quot;)    public LocalContainerEntityManagerFactoryBean entityManagerFactory(            EntityManagerFactoryBuilder builder,            @Qualifier(&quot;userDatasource&quot;)DataSource dataSource){        return builder.dataSource(dataSource)                .packages(&quot;com.wbl.spingbootdemo.muldatasource.user.data&quot;)                .persistenceUnit(&quot;db1&quot;)                .build();    }    @Primary    @Bean(&quot;userTransactionManager&quot;)    public PlatformTransactionManager userTransactionManager(@Qualifier(&quot;userEntityManagerFactory&quot;) EntityManagerFactory entityManagerFactory){        return new JpaTransactionManager(entityManagerFactory);    }}</code></pre><h3 id="product-配置"><a href="#product-配置" class="headerlink" title="product 配置"></a>product 配置</h3><pre><code>@EnableTransactionManagement@EnableJpaRepositories(        entityManagerFactoryRef = &quot;productEntityManagerFactory&quot;,        transactionManagerRef = &quot;productTransactionManager&quot;,        basePackages = {                &quot;com.wbl.spingbootdemo.muldatasource.product.repo&quot;        })public class ProductConfig {    @Bean(&quot;productDatasource&quot;)    @ConfigurationProperties(prefix = &quot;product.datasource&quot;)    public DataSource productDatasource(){        return DataSourceBuilder.create().build();    }    @Bean(&quot;productEntityManagerFactory&quot;)    public LocalContainerEntityManagerFactoryBean productEntityManagerFactory(            EntityManagerFactoryBuilder builder,            @Qualifier(&quot;productDatasource&quot;)DataSource productDatasource){        return builder.dataSource(productDatasource)                .packages(&quot;com.wbl.spingbootdemo.muldatasource.product.data&quot;)                .persistenceUnit(&quot;db2&quot;)                .build();    }    @Bean(name = &quot;productTransactionManager&quot;)    public PlatformTransactionManager productTransactionManager(            @Qualifier(&quot;productEntityManagerFactory&quot;) EntityManagerFactory productEntityManagerFactory    ) {        return new JpaTransactionManager(productEntityManagerFactory);    }}</code></pre><p>其中@Primary的作用是，在对同一接口有几种不同实现时，告诉spring默认注入哪个实例</p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><pre><code>@RunWith(SpringRunner.class)@SpringBootTestpublic class MultipleDataSourcesProductTests {    @Autowired    ProductDao productDao;    @Test    @Transactional(&quot;productTransactionManager&quot;)    public void testSaveProduct(){        Product product = new Product();        product.setName(&quot;product1&quot;);        product = productDao.save(product);        Assert.assertNotNull(productDao.findById(product.getId()));    }}        @RunWith(SpringRunner.class)@SpringBootTestpublic class MultipleDataSourcesUserTests {    @Autowired    private UserDao userDao;    @Test//    @Transactional(&quot;userTransactionManager&quot;)    public void testSaveUser(){        User user = new User();        user.setName(&quot;name&quot;);        userDao.save(user);    }}</code></pre><p>其中加入@Transactional注解，数据不会真正保存在数据库中</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>spring boot 多数据源配置步骤总结</p><ol><li>配置application.properties，填入数据源的详细信息</li><li>生成entity</li><li>生成entity对应的Repository</li><li>配置entityManager以及TransactionManager(事务管理)</li></ol>]]></content>
      
      
      <categories>
          
          <category> Spring Boot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Boot </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>InfluxDB的RP与CQ</title>
      <link href="/2019/03/16/influxdb-de-rp-yu-cq/"/>
      <url>/2019/03/16/influxdb-de-rp-yu-cq/</url>
      
        <content type="html"><![CDATA[<h2 id="Retention-Policy"><a href="#Retention-Policy" class="headerlink" title="Retention Policy"></a>Retention Policy</h2><p>RP表示数据保留策略，策略包含数据保留时长，备份个数等信息。InfluxDB为每个database默认创建了一个默认的RP，名称为autogen，默认数据保留时间为永久。</p><h3 id="查看RP"><a href="#查看RP" class="headerlink" title="查看RP"></a>查看RP</h3><pre><code>show retention policies</code></pre><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tKfTcgy1g14lvppooxj311808sjtd.jpg" alt="">    </p><h3 id="新建RP"><a href="#新建RP" class="headerlink" title="新建RP"></a>新建RP</h3><pre><code>CREATE RETENTION POLICY &lt;retention_policy_name&gt; ON &lt;database_name&gt; DURATION &lt;duration&gt; REPLICATION &lt;n&gt; [SHARD DURATION &lt;duration&gt;] [DEFAULT]</code></pre><table><thead><tr><th>name</th><th>example</th></tr></thead><tbody><tr><td>duration</td><td>表示数据保留时间，最长为INF，最短为1h</td></tr><tr><td>replication</td><td>备份数，在集群模式中可用</td></tr><tr><td>shard duration</td><td>一个分片包含的时间，InfluxDB会根据duration设置默认的shard duration</td></tr><tr><td>default</td><td>表示该RP为默认的RP</td></tr></tbody></table><p>新建一个RP，保留时间为1d</p><pre><code>CREATE RETENTION POLICY &quot;one_day_only&quot; ON &quot;NOAA_water_database&quot; DURATION 1d REPLICATION 1    </code></pre><h3 id="修改RP"><a href="#修改RP" class="headerlink" title="修改RP"></a>修改RP</h3><pre><code>ALTER RETENTION POLICY &lt;retention_policy_name&gt; ON &lt;database_name&gt; DURATION &lt;duration&gt; REPLICATION &lt;n&gt; SHARD DURATION &lt;duration&gt; DEFAULT</code></pre><h3 id="删除RP"><a href="#删除RP" class="headerlink" title="删除RP"></a>删除RP</h3><pre><code>DROP RETENTION POLICY &lt;retention_policy_name&gt; ON &lt;database_name&gt;</code></pre><h3 id="RP使用"><a href="#RP使用" class="headerlink" title="RP使用"></a>RP使用</h3><p>在查询或者插入数据时，需要指定RP，若不指定，则认为选择了默认的RP</p><pre><code>select sum(value) from &quot;rp_1h&quot;.test_me where time &gt; now() - 6h;</code></pre><p>假设默认RP为autogen，则</p><pre><code>select sum(value) from test_me where time &gt; now() - 6h;=== 两条语句等价select sum(value) from &quot;autogen&quot;.test_me where time &gt; now() - 6h;</code></pre><h2 id="Continue-Query"><a href="#Continue-Query" class="headerlink" title="Continue Query"></a>Continue Query</h2><p>InfluxDB提供了自动聚合数据，并将聚合数据存储至measurement的方法，即continue query</p><h3 id="基础用法"><a href="#基础用法" class="headerlink" title="基础用法"></a>基础用法</h3><pre><code>CREATE CONTINUOUS QUERY &lt;cq_name&gt; ON &lt;database_name&gt;BEGIN  &lt;cq_query&gt;END            </code></pre><p>其中cq_query表示聚合语句，</p><pre><code>SELECT &lt;function[s]&gt; INTO &lt;destination_measurement&gt; FROM &lt;measurement&gt; [WHERE &lt;stuff&gt;] GROUP BY time(&lt;interval&gt;)[,&lt;tag_key[s]&gt;]</code></pre><p>cq_query的where条件中不需要设置时间区间，inflxuDB会自动生成时间区间</p><p>influxDB根据cq_query中的Group By time(interval)的interval，每隔interval执行一次cq_query，而查询的时间区间也为interval。例如当前时间为17：00，interval为1h，则cq_query会查询16:00至16：59分的数据。</p><p>生成一条CQ如下，则每隔1h执行一次query</p><pre><code>CREATE CONTINUOUS QUERY &quot;cq_basic&quot; ON &quot;transportation&quot;BEGIN  SELECT mean(&quot;passengers&quot;) INTO &quot;average_passengers&quot; FROM &quot;bus_data&quot; GROUP BY time(1h)END</code></pre><p>在8：00，时间区间为[7:00,8:00)</p><p>在9：00，时间区间为[8:00,9:00)</p><p>根据CQ的特性，可以进行数据降准，例如将维度为1m的数据聚合为5m,measurement_1m存储维度为1m的数据，cq每隔5m对数据进行聚合，并将聚合的数据存储到rp_5m.measurement_5m中，此时维度变成了5m</p><pre><code>CREATE CONTINUOUS QUERY &quot;cq_basic_5m&quot; ON &quot;test_database&quot;BEGIN  SELECT mean(*) INTO &quot;rp_5m&quot;.&quot;measurement_5m&quot;   FROM &quot;rp_1m&quot;.&quot;measurement_1m&quot;  GROUP BY time(5m),*END    </code></pre><h4 id="时间偏移"><a href="#时间偏移" class="headerlink" title="时间偏移"></a>时间偏移</h4><pre><code>CREATE CONTINUOUS QUERY &quot;cq_basic_offset&quot; ON &quot;transportation&quot;BEGIN  SELECT mean(&quot;passengers&quot;) INTO &quot;average_passengers&quot; FROM &quot;bus_data&quot; GROUP BY time(1h,15m)END</code></pre><p>group by time(1h) 与 group by time(1h,15m)的区别</p><p>group by time(1h)的执行时间点和时间区间</p><table><thead><tr><th>time</th><th>range</th></tr></thead><tbody><tr><td>8:00</td><td>[7:00,8:00)</td></tr><tr><td>9:00</td><td>[8:00,9:00)</td></tr></tbody></table><p>group by time(1h, 15m)的执行时间点和时间区间</p><table><thead><tr><th>time</th><th>range</th></tr></thead><tbody><tr><td>8:15</td><td>[7:15,8:15)</td></tr><tr><td>9:15</td><td>[8:15,9:15)</td></tr></tbody></table><h3 id="高级用法"><a href="#高级用法" class="headerlink" title="高级用法"></a>高级用法</h3><pre><code>CREATE CONTINUOUS QUERY &lt;cq_name&gt; ON &lt;database_name&gt;RESAMPLE EVERY &lt;interval&gt; FOR &lt;interval&gt;BEGIN  &lt;cq_query&gt;END    </code></pre><p>其中EVERY表示执行间隔，即每隔多久执行一次，FOR表示时间区间，即每次执行查询多久的数据，区间为[now - for_interval, now)</p><h4 id="EVERY-30m-GROUP-BY-time-1h"><a href="#EVERY-30m-GROUP-BY-time-1h" class="headerlink" title="EVERY=30m,GROUP BY time(1h)"></a>EVERY=30m,GROUP BY time(1h)</h4><pre><code>CREATE CONTINUOUS QUERY &quot;cq_advanced_every&quot; ON &quot;transportation&quot;RESAMPLE EVERY 30mBEGIN  SELECT mean(&quot;passengers&quot;) INTO &quot;average_passengers&quot; FROM &quot;bus_data&quot; GROUP BY time(1h)END</code></pre><table><thead><tr><th>time</th><th>range</th><th>返回time</th></tr></thead><tbody><tr><td>8:00</td><td>[7:00,8:00)</td><td>7:00</td></tr><tr><td>8:30</td><td>[7:00,8:00)</td><td>7:00</td></tr><tr><td>9:00</td><td>[8:00,9:00)</td><td>8:00</td></tr></tbody></table><p>可以看到区间[7:00,8:00)的数据被查询了两次，后一次的数据会覆盖前一次的查询</p><h4 id="FOR-1h-GROUP-BY-time-30m"><a href="#FOR-1h-GROUP-BY-time-30m" class="headerlink" title="FOR=1h,GROUP BY time(30m)"></a>FOR=1h,GROUP BY time(30m)</h4><pre><code>CREATE CONTINUOUS QUERY &quot;cq_advanced_for&quot; ON &quot;transportation&quot;RESAMPLE FOR 1hBEGIN  SELECT mean(&quot;passengers&quot;) INTO &quot;average_passengers&quot; FROM &quot;bus_data&quot; GROUP BY time(30m)END</code></pre><table><thead><tr><th>time</th><th>range</th><th>返回time</th></tr></thead><tbody><tr><td>8:00</td><td>[7:00,8:00)</td><td>7:00<br>7:30</td></tr><tr><td>8:30</td><td>[7:30,8:30)</td><td>7:30<br>8:00</td></tr><tr><td>9:00</td><td>[8:00,9:00)</td><td>8:00<br>8:30</td></tr></tbody></table><p>每次查询都会返回两条数据，每个时间点的数据都被计算了两次，这样在一定程度可以避免数据延迟而导致CQ数据丢失的情况。</p><h4 id="EVERY-1h，FOR-90m，GROUP-BY-time-30m"><a href="#EVERY-1h，FOR-90m，GROUP-BY-time-30m" class="headerlink" title="EVERY=1h，FOR=90m，GROUP BY time(30m)"></a>EVERY=1h，FOR=90m，GROUP BY time(30m)</h4><pre><code>CREATE CONTINUOUS QUERY &quot;cq_advanced_every_for&quot; ON &quot;transportation&quot;RESAMPLE EVERY 1h FOR 90mBEGIN  SELECT mean(&quot;passengers&quot;) INTO &quot;average_passengers&quot; FROM &quot;bus_data&quot; GROUP BY time(30m)END</code></pre><table><thead><tr><th>time</th><th>range</th><th>返回time</th></tr></thead><tbody><tr><td>8:00</td><td>[6:30,8:00)</td><td>6:30<br>7:00<br>7:30</td></tr><tr><td>9:00</td><td>[7:30,9:00)</td><td>7:30<br>8:00<br>8:30    </td></tr></tbody></table><p>FOR interval必须大于GROUP by time(interval)以及EVERY interval，否则InfluxDB会返回如下错误，因为这样会造成数据丢失</p><pre><code>error parsing query: FOR duration must be &gt;= GROUP BY time duration: must be a minimum of &lt;minimum-allowable-interval&gt; got &lt;user-specified-interval&gt;</code></pre><h3 id="CQ管理"><a href="#CQ管理" class="headerlink" title="CQ管理"></a>CQ管理</h3><h4 id="查看CQ"><a href="#查看CQ" class="headerlink" title="查看CQ"></a>查看CQ</h4><pre><code>SHOW CONTINUOUS QUERIES</code></pre><h4 id="删除CQ"><a href="#删除CQ" class="headerlink" title="删除CQ"></a>删除CQ</h4><pre><code>DROP CONTINUOUS QUERY &lt;cq_name&gt; ON &lt;database_name&gt;</code></pre><h4 id="修改CQ"><a href="#修改CQ" class="headerlink" title="修改CQ"></a>修改CQ</h4><p>CQ不能被修改，如果需要需改，只能先删除CQ，在重新创建CQ</p><h2 id="使用CQ与RP的目的"><a href="#使用CQ与RP的目的" class="headerlink" title="使用CQ与RP的目的"></a>使用CQ与RP的目的</h2><ol><li>利用CQ可以达到数据降准的目的，即将细粒度的数据转换为粗粒度的数据，例如1m维度的数据可以聚合为5m数据</li><li>不同粒度的数据可以设置不同的RP，节省存储空间。例如1m维度的数据可以保存7d，而5m维度的数据则可以保存30d，细粒度的数据主要用于及时排查问题，粗粒度的数据在于查看变化趋势。            </li></ol>]]></content>
      
      
      <categories>
          
          <category> 监控 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> InfluxDB </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>InfluxDB group by time()说明</title>
      <link href="/2019/03/08/influxdb-group-by-time-shuo-ming/"/>
      <url>/2019/03/08/influxdb-group-by-time-shuo-ming/</url>
      
        <content type="html"><![CDATA[<h2 id="使用姿势"><a href="#使用姿势" class="headerlink" title="使用姿势"></a>使用姿势</h2><pre><code>SELECT &lt;function&gt;(&lt;field_key&gt;) FROM_clause WHERE &lt;time_range&gt; GROUP BY time(&lt;time_interval&gt;),[tag_key] [fill(&lt;fill_option&gt;)]</code></pre><p>group time(interval)会对查询结果按照interval进行聚合，例如，time(5m),interval=5m, 则会将数据每隔5m进行聚合</p><h2 id="示例说明"><a href="#示例说明" class="headerlink" title="示例说明"></a>示例说明</h2><p>样例数据</p><pre><code>&gt; SELECT &quot;water_level&quot;,&quot;location&quot; FROM &quot;h2o_feet&quot; WHERE time &gt;= &#39;2015-08-18T00:00:00Z&#39; AND time &lt;= &#39;2015-08-18T00:30:00Z&#39;name: h2o_feet--------------time                   water_level   location2015-08-18T00:00:00Z   8.12          coyote_creek2015-08-18T00:00:00Z   2.064         santa_monica2015-08-18T00:06:00Z   8.005         coyote_creek2015-08-18T00:06:00Z   2.116         santa_monica2015-08-18T00:12:00Z   7.887         coyote_creek2015-08-18T00:12:00Z   2.028         santa_monica2015-08-18T00:18:00Z   7.762         coyote_creek2015-08-18T00:18:00Z   2.126         santa_monica2015-08-18T00:24:00Z   7.635         coyote_creek2015-08-18T00:24:00Z   2.041         santa_monica2015-08-18T00:30:00Z   7.5           coyote_creek2015-08-18T00:30:00Z   2.051         santa_monica</code></pre><p>此时按照interval=12m 对数据进行聚合，查询语句以及查询结果如下：</p><pre><code>&gt; SELECT COUNT(&quot;water_level&quot;) FROM &quot;h2o_feet&quot; WHERE &quot;location&quot;=&#39;coyote_creek&#39; AND time &gt;= &#39;2015-08-18T00:00:00Z&#39; AND time &lt;= &#39;2015-08-18T00:30:00Z&#39; GROUP BY time(12m)name: h2o_feet--------------time                   count2015-08-18T00:00:00Z   22015-08-18T00:12:00Z   22015-08-18T00:24:00Z   2</code></pre><p>InfluxDB在计算group by时，会用到两个时间区间，一个是根据interval形成的预设区间，一个是根据where语句中的time_range形成的区间，在上述例子中time_range为[2015-08-18T00:00:00Z,2015-08-18T00:30:00Z),详细说明如下所示</p><table><thead><tr><th>预设区间</th><th>where time_range</th><th>数据</th><th>返回时间戳</th></tr></thead><tbody><tr><td>time&gt;=2015-08-18T00:00:00Z and time&lt;2015-08-18T00:12:00Z</td><td>time&gt;=2015-08-18T00:00:00Z and time&lt;2015-08-18T00:12:00Z</td><td>8.12，8.005</td><td>2015-08-18T00:00:00Z</td></tr><tr><td>time&gt;=2015-08-18T00:12:00Z and time&lt;2015-08-18T00:24:00Z</td><td>time&gt;=2015-08-18T00:12:00Z and time&lt;2015-08-18T00:24:00Z</td><td>7.887，7.762</td><td>2015-08-18T00:12:00Z</td></tr><tr><td>time&gt;=2015-08-18T00:24:00Z and time&lt;2015-08-18T00:36:00Z</td><td>time&gt;=2015-08-18T00:24:00Z and time&lt;2015-08-18T00:30:00Z</td><td>7.635,7.5</td><td>2015-08-18T00:24:00Z</td></tr></tbody></table><h2 id="异常情况说明"><a href="#异常情况说明" class="headerlink" title="异常情况说明"></a>异常情况说明</h2><p>有的时候使用group by time()，会发现查询结果的时间与where条件中的time_range冲突，这是因为InfluxDB在返回时间时是以预设区间的时间为主。详细说明如下</p><p>样本数据</p><pre><code>&gt; SELECT &quot;water_level&quot; FROM &quot;h2o_feet&quot; WHERE &quot;location&quot;=&#39;coyote_creek&#39; AND time &gt;= &#39;2015-08-18T00:00:00Z&#39; AND time &lt;= &#39;2015-08-18T00:18:00Z&#39;name: h2o_feet--------------time                   water_level2015-08-18T00:00:00Z   8.122015-08-18T00:06:00Z   8.0052015-08-18T00:12:00Z   7.8872015-08-18T00:18:00Z   7.762</code></pre><p>查询语句以及查询结果：</p><pre><code>&gt; SELECT COUNT(&quot;water_level&quot;) FROM &quot;h2o_feet&quot; WHERE &quot;location&quot;=&#39;coyote_creek&#39; AND time &gt;= &#39;2015-08-18T00:06:00Z&#39; AND time &lt; &#39;2015-08-18T00:18:00Z&#39; GROUP BY time(12m)name: h2o_feettime                   count----                   -----2015-08-18T00:00:00Z   1        &lt;----- 时间戳超出where条件中的起始时间2015-08-18T00:12:00Z   1</code></pre><table><thead><tr><th>预设区间</th><th>where time_range</th><th>数据</th><th>返回时间戳</th></tr></thead><tbody><tr><td>time&gt;=2015-08-18T00:00:00Z and time&lt;2015-08-18T00:12:00Z</td><td>time&gt;=2015-08-18T00:06:00Z and time&lt;2015-08-18T00:12:00Z</td><td>8.005</td><td>2015-08-18T00:00:00Z</td></tr><tr><td>time&gt;=2015-08-18T00:12:00Z and time&lt;2015-08-18T00:24:00Z</td><td>time&gt;=2015-08-18T00:12:00Z and time&lt;2015-08-18T00:18:00Z</td><td>7.887</td><td>2015-08-18T00:12:00Z</td></tr></tbody></table><p>数据需要同时在预设区间和time_range在能满足查询条件，8.12这条数据在预设区间中，但是不在time_range中，所以不满足条件，只有8.005这条数据满足</p><p>如果要避免这种异常情况，需要group by time()的高级用法</p><h2 id="高级用法"><a href="#高级用法" class="headerlink" title="高级用法"></a>高级用法</h2><p>使用姿势</p><pre><code>SELECT &lt;function&gt;(&lt;field_key&gt;) FROM_clause WHERE &lt;time_range&gt; GROUP BY time(&lt;time_interval&gt;,&lt;offset_interval&gt;),[tag_key] [fill(&lt;fill_option&gt;)]</code></pre><p>与基本用法的唯一区别在于多了一个offset_interval的参数，这个参数表示在设置预设区间时需要偏移的时间，可以为正数或负数</p><p>若time_range为[2019-03-08T16:00:00Z, 2019-03-08T16:30:00Z)</p><p>###group by time(10m)</p><table><thead><tr><th>预设区间</th><th>where time_range</th><th>返回时间戳</th></tr></thead><tbody><tr><td>time&gt;=2019-03-08T16:00:00Z and time&lt;2019-03-08T16:10:00Z</td><td>time&gt;=2019-03-08T16:00:00Z and time&lt;2019-03-08T16:10:00Z</td><td>2019-03-08T16:00:00Z</td></tr><tr><td>time&gt;=2019-03-08T16:10:00Z and time&lt;2019-03-08T16:20:00Z</td><td>与预设区间相同</td><td>2019-03-08T16:10:00Z</td></tr><tr><td>time&gt;=2019-03-08T16:20:00Z and time&lt;2019-03-08T16:30:00Z</td><td>与预设区间相同</td><td>2019-03-08T16:20:00Z</td></tr></tbody></table><p>###group by time(10m,-5m)<br>|预设区间|where time_range|返回时间戳<br>|—|—|—|<br>|time&gt;=2019-03-08T15:55:00Z and time&lt;2019-03-08T16:05:00Z|time&gt;=2019-03-08T16:00:00Z and time&lt;2019-03-08T16:10:00Z|2019-03-08T15:55:00Z<br>|time&gt;=2019-03-08T16:05:00Z and time&lt;2019-03-08T16:15:00Z|time&gt;=2019-03-08T16:10:00Z and time&lt;2019-03-08T16:20:00Z|2019-03-08T16:05:00Z<br>|time&gt;=2019-03-08T16:15:00Z and time&lt;2019-03-08T16:25:00Z|time&gt;=2019-03-08T16:20:00Z and time&lt;2019-03-08T16:30:00Z|2019-03-08T16:15:00Z<br>|time&gt;=2019-03-08T16:25:00Z and time&lt;2019-03-08T16:35:00Z||2019-03-08T16:25:00Z</p><h2 id="group-by-time-1d"><a href="#group-by-time-1d" class="headerlink" title="group by time(1d)"></a>group by time(1d)</h2><p>InfluxDB默认是使用UTC时区，所以在进行计算group by time(1d)，对于CST时区，数据会偏移8个小时，所以在聚合1d数据时，需要使用time(1d, -8h)</p>]]></content>
      
      
      <categories>
          
          <category> 监控 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> InfluxDB </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>InfluxDB配置详解</title>
      <link href="/2019/02/24/influxdb-pei-zhi-xiang-jie/"/>
      <url>/2019/02/24/influxdb-pei-zhi-xiang-jie/</url>
      
        <content type="html"><![CDATA[<h2 id="配置文件位置"><a href="#配置文件位置" class="headerlink" title="配置文件位置"></a>配置文件位置</h2><pre><code>Linux：/etc/influxdb/influxdb.confmaxOS：/usr/local/etc/influxdb.conf</code></pre><p>使用配置文件</p><pre><code>influxd -config /etc/influxdb/influxdb.conf</code></pre><p>可以使用环境变量INFLUXDB_CONFIG_PATH来指定配置文件位置</p><pre><code>echo $INFLUXDB_CONFIG_PATH/etc/influxdb/influxdb.confinfluxd</code></pre><h2 id="环境变量配置"><a href="#环境变量配置" class="headerlink" title="环境变量配置"></a>环境变量配置</h2><p>InfluxDB的配置可以放在环境变量中，InfluxDB相关的环境变量都已INFLUXDB_作为前缀</p><pre><code>INFLUXDB_*</code></pre><h2 id="配置优先级"><a href="#配置优先级" class="headerlink" title="配置优先级"></a>配置优先级</h2><p>inflxudb所有的配置项可以在配置文件influxdb.conf中配置，也可以通过环境变量来配置。环境变量的配置优先级高于配置文件的配置。如果有配置环境变量，环境变量的配置将覆盖配置文件的配置</p><pre><code>环境变量 &gt;     配置文件 &gt; InfluxDB内置配置</code></pre><h2 id="全局配置"><a href="#全局配置" class="headerlink" title="全局配置"></a>全局配置</h2><table><thead><tr><th>配置名称</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td>reporting-disabled</td><td>false</td><td>是否向每隔24小时向influxdb汇报信息，包括influxdb版本，database，measurement和series的数量等信息</td></tr><tr><td>bind-address</td><td>127.0.0.1:8088</td><td>RPC服务的地址</td></tr></tbody></table><h2 id="元数据配置-meta"><a href="#元数据配置-meta" class="headerlink" title="元数据配置[meta]"></a>元数据配置[meta]</h2><p>用来控制influxdb的元数据信息，包括database，rp策略，CQ等信息</p><table><thead><tr><th>配置名称</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td>dir</td><td>/usr/local/var/influxdb/meta</td><td>存储元数据信息的路径</td></tr><tr><td>retention-autocreate</td><td>true</td><td>当数据库创建时是否自动创建默认的retention policy</td></tr><tr><td>logging-enabled</td><td>true</td><td>是否允许打印元数据相关的日志</td></tr></tbody></table><h2 id="数据配置-data"><a href="#数据配置-data" class="headerlink" title="数据配置[data]"></a>数据配置[data]</h2><table><thead><tr><th>配置名称</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td>dir</td><td>/usr/local/var/influxdb/data</td><td>TSM文件存储的路径</td></tr><tr><td>wal-dir</td><td>/usr/local/var/influxdb/wal</td><td>WAL文件存储的路径</td></tr><tr><td>trace-logging-enabled</td><td>false</td><td>输出TSM Engine的日志</td></tr><tr><td>query-log-enabled</td><td>true</td><td>在执行查询语句之前，将查询语句输出到日志中</td></tr><tr><td>cache-max-memory-size</td><td>1g</td><td>shard缓存的最大值，如果超过最大值，shard将不再写入数据。若不带单位，则默认为字节</td></tr><tr><td>cache-snapshot-memory-size</td><td>25m</td><td>缓存快照的大小，超过数值，engine会将数据写入到TSM文件中</td></tr><tr><td>cache-snapshot-write-cold-duration</td><td>10m</td><td>当shard没有写入或删除数据，engine将cache的数据写入到TSM文件中的间隔</td></tr><tr><td>compact-full-write-cold-duration</td><td>4h</td><td>当shard没有写入或删除数据时，engine压缩shard中所有TSM文件的间隔</td></tr><tr><td>max-series-per-database</td><td>1000000</td><td>每个database允许的最大series的最大值，当database的series的数据量超过数值，将拒绝写入，并返回{“error”:”max series per database exceeded: <series>“}。设置为0表示对series的数量没有限制</series></td></tr><tr><td>max-values-per-tag</td><td>100000</td><td>每个tag value所允许的最大数量。当tag的数量超过配置，influxdb会返回partial write 错误。对应已有的tag value写入不会失败，但是对于新建的tag value，写入会失败</td></tr></tbody></table><h2 id="查询配置-coordinator"><a href="#查询配置-coordinator" class="headerlink" title="查询配置[coordinator]"></a>查询配置[coordinator]</h2><table><thead><tr><th>配置名称</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td>write-timeout</td><td>10s</td><td>写入超时时间</td></tr><tr><td>max-concurrent-queries</td><td>0</td><td>inflxudb实例允许的最大查询数</td></tr><tr><td>query-timeout</td><td>0s</td><td>查询超时时间，设置为0表示查询没有超时时间</td></tr><tr><td>log-queries-after</td><td>0s</td><td>慢查询时间，当查询时间超过配置，influxdb将把这个查询记录到日志中</td></tr><tr><td>max-select-point</td><td>0</td><td>select语句所能处理的最大point数，设置为0，表示没有限制</td></tr><tr><td>max-select-series</td><td>0</td><td>select语句所能处理的最大series数据，设置为0，表示没有限制</td></tr><tr><td>max-select_buckets</td><td>0</td><td>group by time()的最大数量</td></tr></tbody></table><h2 id="retention-policy配置-retention"><a href="#retention-policy配置-retention" class="headerlink" title="retention policy配置[retention]"></a>retention policy配置[retention]</h2><table><thead><tr><th>配置名称</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td>enabled</td><td>true</td><td>是否启用retention policy</td></tr><tr><td>check-interval</td><td>30ms0s</td><td>check retention policy的间隔</td></tr></tbody></table><h2 id="监控配置-monitor"><a href="#监控配置-monitor" class="headerlink" title="监控配置[monitor]"></a>监控配置[monitor]</h2><table><thead><tr><th>配置名称</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td>store-enabled</td><td>true</td><td>是否记录监控信息</td></tr><tr><td>store-database</td><td>_interval</td><td>监控数据存储的数据库</td></tr><tr><td>store-interval</td><td>10s</td><td>记录监控信息的间隔</td></tr></tbody></table><h2 id="http配置-http"><a href="#http配置-http" class="headerlink" title="http配置[http]"></a>http配置[http]</h2><table><thead><tr><th>配置名称</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td>enabled</td><td>true</td><td>是否启用http</td></tr><tr><td>bind-address</td><td>8086</td><td>Http端口</td></tr><tr><td>auth-enabled</td><td>false</td><td>是否开启验证</td></tr><tr><td>max-body-size</td><td>25000000</td><td>request body的最大值，如果超过配置，将返回413</td></tr></tbody></table><h2 id="CQ配置-continuous-queries"><a href="#CQ配置-continuous-queries" class="headerlink" title="CQ配置[continuous_queries]"></a>CQ配置[continuous_queries]</h2><table><thead><tr><th>配置名称</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td>enabled</td><td>true</td><td>是否启用CQ</td></tr><tr><td>query-stats-enabled</td><td>false</td><td>是否将CQ的监控信息记录到默认的监控数据库</td></tr><tr><td>run-interval</td><td>1s</td><td>influxdb检查是否需要执行CQ的间隔</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 监控 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> InfluxDB </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>InfluxDB简介</title>
      <link href="/2019/02/16/influxdb-jian-jie/"/>
      <url>/2019/02/16/influxdb-jian-jie/</url>
      
        <content type="html"><![CDATA[<h2 id="InfluxDB简介"><a href="#InfluxDB简介" class="headerlink" title="InfluxDB简介"></a>InfluxDB简介</h2><p>InfluxDB是一个时序型数据库，用于高性能的查询与存储时序型数据。目前，InfluxDB被广泛的用于监控系统中。InfluxDB与Grafana结合，可以为用户带来清晰明了的监控面板。</p><h2 id="InfluxDB安装"><a href="#InfluxDB安装" class="headerlink" title="InfluxDB安装"></a>InfluxDB安装</h2><h3 id="macOS"><a href="#macOS" class="headerlink" title="macOS"></a>macOS</h3><pre><code>brew updatebrew install influxdbinfluxd -config /usr/local/etc/influxdb.conf   //启动influxdb</code></pre><h3 id="Ubuntu"><a href="#Ubuntu" class="headerlink" title="Ubuntu"></a>Ubuntu</h3><pre><code>sudo apt-get update &amp;&amp; sudo apt-get install influxdbsudo service influxdb start</code></pre><h2 id="InfluxDB相关概念"><a href="#InfluxDB相关概念" class="headerlink" title="InfluxDB相关概念"></a>InfluxDB相关概念</h2><h3 id="database"><a href="#database" class="headerlink" title="database"></a>database</h3><p>数据库，包含用户，数据保留策略以及时序型数据。类似关系型数据库中数据库</p><h3 id="measurement"><a href="#measurement" class="headerlink" title="measurement"></a>measurement</h3><p>具有相同tag以及filed的数据集合</p><h3 id="tag"><a href="#tag" class="headerlink" title="tag"></a>tag</h3><p>influxdb使用键值对key-value的形式来保存数据，tag是具有索引的数据</p><h3 id="filed"><a href="#filed" class="headerlink" title="filed"></a>filed</h3><p>influxdb中用来存储具体数值，也是key-value的形式，与tag相比，filed没有索引，因此用filed来过滤查询数据性能会很低</p><h3 id="point"><a href="#point" class="headerlink" title="point"></a>point</h3><p>tag + filed + timestamp = point，类似于关系型数据库中的一行数据(row)</p><h3 id="continuous-query-CQ"><a href="#continuous-query-CQ" class="headerlink" title="continuous query(CQ)"></a>continuous query(CQ)</h3><p>InfluxDB自动并且周期性执行的SQL语句，主要用来自动聚合数据，提供查询性能</p><h3 id="retention-policy-RP"><a href="#retention-policy-RP" class="headerlink" title="retention policy(RP)"></a>retention policy(RP)</h3><p>保留数据策略，每一个RP都会设置一个数据保留期限(duration)，对于超过期限的数据，InfluxDB会自动删除。例如RP设置的期限为7天，则7天之前的数据都会被删除</p><h3 id="series"><a href="#series" class="headerlink" title="series"></a>series</h3><p>在同一个measurement，具有相同的retention policy以及相同tag的数据集合</p><h3 id="shard"><a href="#shard" class="headerlink" title="shard"></a>shard</h3><p>分片包含了实际加密和压缩的数据，一个分片对应了磁盘上的一个TSM文件</p><h2 id="InfluxDB与关系型数据库的对比"><a href="#InfluxDB与关系型数据库的对比" class="headerlink" title="InfluxDB与关系型数据库的对比"></a>InfluxDB与关系型数据库的对比</h2><h3 id="相关概念对比"><a href="#相关概念对比" class="headerlink" title="相关概念对比"></a>相关概念对比</h3><table><thead><tr><th>InfluxDB</th><th>关系型数据库</th></tr></thead><tbody><tr><td>database</td><td>database</td></tr><tr><td>measurement</td><td>table</td></tr><tr><td>tag</td><td>primary-key</td></tr><tr><td>filed</td><td>column</td></tr><tr><td>point</td><td>row</td></tr></tbody></table><p>下面一张表，可以对应到InfluxDB的measurement中<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tKfTcgy1g08cg9a683j30su076q44.jpg" alt=""></p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tKfTcgy1g08chjy7isj30xk08st9w.jpg" alt=""></p><h2 id="InfluxDB-Quick-start"><a href="#InfluxDB-Quick-start" class="headerlink" title="InfluxDB Quick start"></a>InfluxDB Quick start</h2><pre><code>//1. 启动influxd</code></pre><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tKfTcgy1g08co9olscj327c0icaff.jpg" alt=""></p><pre><code>//2. 进入命令行influx -precision rfc3339</code></pre><p>-precision 用来指定时间戳的显示格式<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tKfTcgy1g08cpc9a2fj30x006yjsu.jpg" alt=""></p><pre><code>//3. 查看databaseshow databases;</code></pre><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tKfTcgy1g08crkttvjj310e09sjs2.jpg" alt=""></p><pre><code>//4. 使用databaseuse media_quality//5. 查看measurementshow measurements</code></pre><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tKfTcgy1g08cthchcvj30l609qmy4.jpg" alt=""></p><pre><code>//6. 查询数据select * from [measurement] where time &gt; now() - 5m limit 10</code></pre><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://docs.influxdata.com/influxdb/v1.7/about_the_project/" target="_blank" rel="noopener">InfluDB官网</a>                </li></ul>]]></content>
      
      
      <categories>
          
          <category> 监控 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> InfluxDB </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>logback配置</title>
      <link href="/2019/02/01/logback-pei-zhi/"/>
      <url>/2019/02/01/logback-pei-zhi/</url>
      
        <content type="html"><![CDATA[<h2 id="logback配置文件加载顺序"><a href="#logback配置文件加载顺序" class="headerlink" title="logback配置文件加载顺序"></a>logback配置文件加载顺序</h2><ol><li>在 classpath 中寻找 logback-test.xml文件</li><li>如果找不到 logback-test.xml，则在 classpath 中寻找 logback.groovy 文件</li><li>如果找不到 logback.groovy，则在 classpath 中寻找 logback.xml文件</li><li>如果上述的文件都找不到，则 logback 会使用 JDK 的 SPI 机制查找 META-INF/services/ch.qos.logback.classic.spi.Configurator 中的 logback 配置实现类，这个实现类必须实现 Configuration 接口，使用它的实现来进行配置</li><li>如果上述操作都不成功，logback 就会使用它自带的 BasicConfigurator 来配置，并将日志输出到 console<h2 id="logback配置结构"><a href="#logback配置结构" class="headerlink" title="logback配置结构"></a>logback配置结构</h2> configuration<pre><code> - appender - logger - root </code></pre></li></ol><p>下面详细说明各个标签的详细配置</p><h2 id="configuration"><a href="#configuration" class="headerlink" title="configuration"></a>configuration</h2><pre><code>&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt;      &lt;property name=&quot;glmapper-name&quot; value=&quot;glmapper-demo&quot; /&gt;     &lt;contextName&gt;${glmapper-name}&lt;/contextName&gt;     &lt;appender&gt;        //xxxx    &lt;/appender&gt;       &lt;logger&gt;        //xxxx    &lt;/logger&gt;    &lt;root&gt;                    //xxxx    &lt;/root&gt;  &lt;/configuration&gt;   </code></pre><table><thead><tr><th>属性名称</th><th>属性说明</th></tr></thead><tbody><tr><td>scan</td><td>为true时，配置文件变化后会自动重新加载，默认设置为true</td></tr><tr><td>scanPeriod</td><td>扫描配置文件的时间间隔，如果没有给出时间单位，默认为ms。当scan为true，此属性生效，默认值为1m</td></tr><tr><td>debug</td><td>为true时，打印logback内部的日志，默认为false</td></tr></tbody></table><h2 id="contextName"><a href="#contextName" class="headerlink" title="contextName"></a>contextName</h2><pre><code>&lt;contextName&gt;${glmapper-name}&lt;/contextName&gt; </code></pre><p>默认的contextName为default，可以通过设置contextName来区分不同应用程序的日志</p><h2 id="property"><a href="#property" class="headerlink" title="property"></a>property</h2><pre><code>&lt;property name=&quot;glmapper-name&quot; value=&quot;glmapper-demo&quot; /&gt;</code></pre><p>property标签用来定义变量，具有如下两个属性</p><table><thead><tr><th>属性名称</th><th>属性说明</th></tr></thead><tbody><tr><td>name</td><td>变量名称</td></tr><tr><td>value</td><td>变量值</td></tr></tbody></table><p>定义变量之后，可以通过表示式来使用变量</p><pre><code>${name}</code></pre><h2 id="logger"><a href="#logger" class="headerlink" title="logger"></a>logger</h2><p>用来设置某一个包或者具体的某一个类的日志打印级别以及指定appender。</p><pre><code>&lt;logger name=&quot;com.meitu.alarm&quot; level=&quot;debug&quot; additivity=&quot;false&quot;&gt;</code></pre><table><thead><tr><th>属性名称</th><th>属性说明</th></tr></thead><tbody><tr><td>name</td><td>logger名称，必填，与LoggerFactory.getLogger(“name”)中的name对应</td></tr><tr><td>level</td><td>level的取值可以为TRACE, DEBUG, INFO, WARN, ERROR, ALL, OFF</td></tr><tr><td>additivity</td><td>是否向父类继续上报日志，如果设置为true，则日志会向上传递，父类也会打印该日志</td></tr></tbody></table><p><logger>标签只有一个子标签<appender-ref>，用来绑定对应的appender</appender-ref></logger></p><h2 id="appender"><a href="#appender" class="headerlink" title="appender"></a>appender</h2><p>appender用来标识日志输出的格式以及日志输出地点，可以是控制台，文件</p><pre><code>&lt;appender name=&quot;console&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;&lt;/appender&gt;</code></pre><table><thead><tr><th>属性名称</th><th>属性说明</th></tr></thead><tbody><tr><td>name</td><td>appender的名称</td></tr><tr><td>class</td><td>appender的实现类名称</td></tr></tbody></table><appender> 标签下可以包含至多一个 <layout>，0个或多个 <encoder>，0个或多个 <filter><br><br>以下是几种常见的appender<br>### Console<br>将日志输出到控制台中<br><br>    <appender name="console" class="ch.qos.logback.core.ConsoleAppender"><br>        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"><br>            <pattern>%d{YY-MM-dd HH:mm:ss.SSS} %-5level %logger{36} - %msg%n</pattern><br>        </encoder><br>    </appender><h3 id="RollingFileAppender-by-time"><a href="#RollingFileAppender-by-time" class="headerlink" title="RollingFileAppender(by time)"></a>RollingFileAppender(by time)</h3><p>将日志输出到文件中，并根据time分割日志</p><pre><code>&lt;appender name=&quot;debug&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;        &lt;file&gt;${LOG_PATH}/debug.log&lt;/file&gt;        &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;            &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss} %logger %msg%n&lt;/pattern&gt;        &lt;/encoder&gt;        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;            &lt;fileNamePattern&gt;${LOG_PATH}/debug.%d{yyyyMMdd-HH}.log&lt;/fileNamePattern&gt;            &lt;maxHistory&gt;30&lt;/maxHistory&gt;        &lt;/rollingPolicy&gt;        &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt;            &lt;level&gt;DEBUG&lt;/level&gt;            &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt;            &lt;onMismatch&gt;DENY&lt;/onMismatch&gt;        &lt;/filter&gt;    &lt;/appender&gt;</code></pre><h3 id="JSON-Appender"><a href="#JSON-Appender" class="headerlink" title="JSON Appender"></a>JSON Appender</h3><p>按照JSON格式输出日志</p><pre><code>&lt;appender name=&quot;console&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;    &lt;encoder class=&quot;net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder&quot;&gt;        &lt;providers&gt;            &lt;pattern&gt;                &lt;pattern&gt;                    {                    &quot;timestamp&quot;: &quot;%date{\&quot;yyyy-MM-dd HH:mm:ss\&quot;}&quot;,                    &quot;log_level&quot;: &quot;%level&quot;,                    &quot;class_name&quot;: &quot;%class&quot;,                    &quot;message&quot;: &quot;%message&quot;,                    &quot;stack_trace&quot;: &quot;%exception{5}&quot;                    }                &lt;/pattern&gt;            &lt;/pattern&gt;        &lt;/providers&gt;        &lt;!--&lt;charset&gt;UTF-8&lt;/charset&gt;--&gt;    &lt;/encoder&gt;&lt;/appender&gt;</code></pre><h2 id="多环境日志输出"><a href="#多环境日志输出" class="headerlink" title="多环境日志输出"></a>多环境日志输出</h2><p>根据不同的环境(test,dev,pre,release)来定义输出日志</p><pre><code>&lt;springProfile name=&quot;test,dev&quot;&gt; //多个环境用逗号分隔    &lt;logger name=&quot;com.meitu.alarm&quot; level=&quot;debug&quot; additivity=&quot;false&quot;&gt;        &lt;appender-ref ref=&quot;debug&quot;/&gt;        &lt;appender-ref ref=&quot;info&quot;/&gt;        &lt;appender-ref ref=&quot;warn&quot;/&gt;        &lt;appender-ref ref=&quot;error&quot;/&gt;    &lt;/logger&gt;&lt;/springProfile&gt;&lt;springProfile name=&quot;release&quot;&gt;    &lt;logger name=&quot;com.meitu.alarm&quot; level=&quot;info&quot; additivity=&quot;false&quot;&gt;        &lt;appender-ref ref=&quot;console&quot;/&gt;    &lt;/logger&gt;&lt;/springProfile&gt;</code></pre><h2 id="关闭某个包或者某个类的日志"><a href="#关闭某个包或者某个类的日志" class="headerlink" title="关闭某个包或者某个类的日志"></a>关闭某个包或者某个类的日志</h2><pre><code>&lt;logger name=&quot;packageName&quot; level=&quot;OFF&quot; /&gt;</code></pre><h2 id="自定义字段"><a href="#自定义字段" class="headerlink" title="自定义字段"></a>自定义字段</h2><p>若日志最终存储到ES中，可以在JSON中添加自定义的字段，方便问题的排查</p><h3 id="StructuredArguments提供的结构化字段"><a href="#StructuredArguments提供的结构化字段" class="headerlink" title="StructuredArguments提供的结构化字段"></a>StructuredArguments提供的结构化字段</h3><pre><code>import static net.logstash.logback.argument.StructuredArguments.*//output: log message valuelogger.info(&quot;log message {}&quot;, value(&quot;name&quot;, &quot;value&quot;));//output: log message name=valuelogger.info(&quot;log message {}&quot;, keyValue(&quot;name&quot;, &quot;value&quot;));//json output: {&quot;message&quot;:&quot;log message&quot;,&quot;name&quot;:&quot;value&quot;}logger.info(&quot;log message&quot;, keyValue(&quot;name&quot;, &quot;value&quot;));</code></pre><p>如果想在输出的JSON中，加上自定义字段，需要配置arguments参数</p><pre><code>&lt;encoder class=&quot;net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder&quot;&gt;        &lt;providers&gt;            &lt;pattern&gt;                &lt;pattern&gt;                    {                    &quot;timestamp&quot;: &quot;%date{\&quot;yyyy-MM-dd HH:mm:ss\&quot;}&quot;,                    &quot;log_level&quot;: &quot;%level&quot;,                    &quot;class_name&quot;: &quot;%class&quot;,                    &quot;thread&quot;: &quot;%thread&quot;,                    &quot;message&quot;: &quot;%message&quot;,                    &quot;stack_trace&quot;: &quot;%exception{5}&quot;                    }                &lt;/pattern&gt;            &lt;/pattern&gt;            &lt;arguments/&gt;        &lt;/providers&gt;    &lt;/encoder&gt;</code></pre><h3 id="Markers提供的标记"><a href="#Markers提供的标记" class="headerlink" title="Markers提供的标记"></a>Markers提供的标记</h3><pre><code>import static net.logstash.logback.marker.Markers.* /* * Add &quot;name&quot;:&quot;value&quot; to the JSON output. */logger.info(append(&quot;name&quot;, &quot;value&quot;), &quot;log message&quot;);/* * Add &quot;name1&quot;:&quot;value1&quot;,&quot;name2&quot;:&quot;value2&quot; to the JSON output by using multiple markers. */logger.info(append(&quot;name1&quot;, &quot;value1&quot;).and(append(&quot;name2&quot;, &quot;value2&quot;)), &quot;log message&quot;);</code></pre><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://www.jianshu.com/p/a26da0c55255" target="_blank" rel="noopener">logstash中logback的json编码器插件</a></li></ul></filter></encoder></layout></appender>]]></content>
      
      
      <categories>
          
          <category> Spring Boot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Logback </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Prometheus2.0实战</title>
      <link href="/2019/01/26/prometheus2-0-shi-zhan/"/>
      <url>/2019/01/26/prometheus2-0-shi-zhan/</url>
      
        <content type="html"><![CDATA[<h2 id="Prometheus-1-x-VS-Prometheus-2-x"><a href="#Prometheus-1-x-VS-Prometheus-2-x" class="headerlink" title="Prometheus 1.x VS Prometheus 2.x"></a>Prometheus 1.x VS Prometheus 2.x</h2><p>1.0版本与2.0版本最大的改变之一就是存储引擎，1.x版本使用的是LevelDB，2.x使用的是TSDB，性能上有较大的提升，以下是官方对比数据</p><ul><li>与 Prometheus 1.8 相比，CPU使用率降低了 20％ - 40％</li><li>与 Prometheus 1.8 相比，磁盘空间使用率降低了 33％ - 50％</li><li>没有太多查询，平均负载的磁盘 I/O&lt;1％</li></ul><h2 id="Prometheus-存储"><a href="#Prometheus-存储" class="headerlink" title="Prometheus 存储"></a>Prometheus 存储</h2><h3 id="本地存储"><a href="#本地存储" class="headerlink" title="本地存储"></a>本地存储</h3><p>Prometheus将两个小时的数据存储在一个目录底下，目录包含chunk(存储时间序列样本)，meta(存储元数据)，index(存储metric名称以及label)</p><p>数据会先缓存在内存中而不会立刻持久化到磁盘中，因此Prometheus采用write-ahead-log机制，当prometheus server发生异常，重启之后会根据日志重新加载数据。</p><p>通过API删除数据，数据先保存到tombstone文件，而不是立即从磁盘删除</p><pre><code>./data/01BKGTZQ1SYQJTR4PB43C8PD98./data/01BKGTZQ1SYQJTR4PB43C8PD98/meta.json./data/01BKGTZQ1SYQJTR4PB43C8PD98/index./data/01BKGTZQ1SYQJTR4PB43C8PD98/chunks./data/01BKGTZQ1SYQJTR4PB43C8PD98/chunks/000001./data/01BKGTZQ1SYQJTR4PB43C8PD98/tombstones</code></pre><h3 id="远程存储"><a href="#远程存储" class="headerlink" title="远程存储"></a>远程存储</h3><p>prometheus可以与远程系统进行如下交互：</p><ol><li>prometheus可以通过remote_write写入数据</li><li>prometheus可以通过remote_read读取数据</li></ol><p><img src="https://prometheus.io/docs/prometheus/latest/images/remote_integrations.png" alt=""></p><p>目前prometheus是通过HTTP协议传输数据，未来可能会使用gRPC。</p><p>采用远程存储时，prometheus进行查询时，会从远端拉取所需的数据，然后进行相应的处理，因此可靠性不能保证。目前PromQL是不支持分布式查询。</p><p>目前支持prometheus远程存储的数据源如下：</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1fzgkyab3ybj30bc0brmye.jpg" alt=""></p><h2 id="Prometheus-Federation"><a href="#Prometheus-Federation" class="headerlink" title="Prometheus Federation"></a>Prometheus Federation</h2><h3 id="Hierarchical-federation"><a href="#Hierarchical-federation" class="headerlink" title="Hierarchical federation"></a>Hierarchical federation</h3><p>这种方式相同job的不同instance分布在不同的prometheus上，高一层级的prometheus server从低层级的prometheus server查询数据。</p><p>这种方式适合于某个job收集metrics过多，单台prometheus无法负荷时，可以利用这种方式对job的instance进行水平扩展，将不同的instance拆分到不同的prometheus中，在由全局的prometheus来收集聚合数据<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1fzgjb6rttlj30kp08at92.jpg" alt=""></p><h3 id="Cross-service-federation"><a href="#Cross-service-federation" class="headerlink" title="Cross-service federation"></a>Cross-service federation</h3><p>这种方式是以service维度来拆分prometheus，在由全局的prometheus来收集聚合数据<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1fzgjg57ocrj30gx07q3yo.jpg" alt=""></p><h3 id="Federation的优缺点"><a href="#Federation的优缺点" class="headerlink" title="Federation的优缺点"></a>Federation的优缺点</h3><p>优点：数据集中式管理，告警，不需要为每个prometheus实例管理数据</p><p>缺点：数据集中化，网络可能会延迟。Federation没有解决数据单点问题</p><h2 id="Recording-rules"><a href="#Recording-rules" class="headerlink" title="Recording rules"></a>Recording rules</h2><p>recording rule类似于Influxdb的CQ，可以在后台处理配置的表达式，并将表达式的结果存储起来。recording rule主要目的是为了提前计算一些复杂运算结果，提供查询效率。CQ的主要目的在于聚合数据，从而通过不同的RP策略来保存数据</p><pre><code>groups:  - name: example    rules:    - record: job:http_inprogress_requests:sum      expr: sum(http_inprogress_requests) by (job)</code></pre><p>其中record表示指标的名称，expr则是指标的表达式</p><h2 id="prometheus高可用部署"><a href="#prometheus高可用部署" class="headerlink" title="prometheus高可用部署"></a>prometheus高可用部署</h2><h3 id="基于HA"><a href="#基于HA" class="headerlink" title="基于HA"></a>基于HA</h3><p>部署多台prometheus server(一主一从)，并采集相同export的指标。</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1fziofcdgszj30el06c74a.jpg" alt=""></p><p>基于HA模式只能确保prometheus服务可用性问题，但是不解决prometheus server之间数据一致性问题已经持久化问题(数据丢失无法恢复)。</p><h3 id="基于HA-远程存储"><a href="#基于HA-远程存储" class="headerlink" title="基于HA + 远程存储"></a>基于HA + 远程存储</h3><p>在HA的基础上通过添加remote storage，将监控数据存储到第三方存储服务上。既解决了服务可用性问题，同时也确保了数据的持久化</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1fzirxf5gtnj30e207ndfx.jpg" alt=""></p><h3 id="基于HA-远程存储-联邦集成"><a href="#基于HA-远程存储-联邦集成" class="headerlink" title="基于HA + 远程存储 + 联邦集成"></a>基于HA + 远程存储 + 联邦集成</h3><p>当单台prometheus需要处理大量的采集任务时，可以使用prometheusde联邦的方式，将采集任务分割到不同的prometheus实例中。</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1fzisip7noyj30pw09l0t5.jpg" alt=""></p><h3 id="三种方式对比"><a href="#三种方式对比" class="headerlink" title="三种方式对比"></a>三种方式对比</h3><table><thead><tr><th>部署方式</th><th>使用场景</th></tr></thead><tbody><tr><td>基于HA</td><td>监控规模不大，prometheus server不会经常发生迁移，并且数据保存周期较短</td></tr><tr><td>基于HA + 远程存储</td><td>监控规模不大，但要求监控数据持久化</td></tr><tr><td>基于HA + 远程存储 + 联邦集成</td><td>单数据中心，并且采集指标量很大，此时prometheus的性能瓶颈主要在于大量的采集任务</td></tr></tbody></table><h3 id="Thanos"><a href="#Thanos" class="headerlink" title="Thanos"></a>Thanos</h3><p><a href="https://github.com/improbable-eng/thanos" target="_blank" rel="noopener">thanos</a>是开源的大规模Prometheus集群解决方案，它的设计目标如下</p><ol><li>全局的查询视图</li><li>不受限的数据存储</li><li>高可用性</li></ol><p>thanos的架构如图</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1fzk1j4mmlnj317f0u07kq.jpg" alt=""></p><h3 id="M3"><a href="#M3" class="headerlink" title="M3"></a>M3</h3><p><a href="https://github.com/m3db/m3" target="_blank" rel="noopener">M3</a>是Uber开源的基于M3DB的指标平台，它提供了如下的功能</p><ol><li>全局数据查询和存储</li><li>提供数据聚合以及保留(retention)功能</li><li>可作为prometheus的存储后台，提供prometheus的高可用部署</li></ol><p><img src="http://eng.uber.com/wp-content/uploads/2018/08/image4-1.png" alt=""></p><p><img src="http://eng.uber.com/wp-content/uploads/2018/08/image1-1.png" alt=""></p><h2 id="Prometheus实践"><a href="#Prometheus实践" class="headerlink" title="Prometheus实践"></a>Prometheus实践</h2><h3 id="recording-rule"><a href="#recording-rule" class="headerlink" title="recording rule"></a>recording rule</h3><p>生成recording rule</p><pre><code>groups: - name: test   rules:   - record: job:prometheus_http_response_size_bytes_sum:sum     expr: sum(prometheus_http_response_size_bytes_sum) by (job)</code></pre><p>在graph中查看recording rule生成的指标</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1fzjyh83xnsj32200f0jt9.jpg" alt=""></p><p>可以看到生成的新指标与表达式得到的指标值一致</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1fzjyjcgsasj31vk0eumyu.jpg" alt="">       </p><h3 id="remote-write-remote-read"><a href="#remote-write-remote-read" class="headerlink" title="remote_write/remote_read"></a>remote_write/remote_read</h3><h4 id="influxdb"><a href="#influxdb" class="headerlink" title="influxdb"></a>influxdb</h4><p>influxdb内部已经实现了读写prometheus数据的协议，只需要在prometheus.yml中配置remote_write和remote_read的url地址即可</p><pre><code>remote_write: - url: &quot;http://127.0.0.1:8086/api/v1/prom/write?db=prometheus_test&quot;remote_read: - url: &quot;http://127.0.0.1:8086/api/v1/prom/read?db=prometheus_test&quot;</code></pre><p>配置prometheus之后，需要在infludb中创建配置中对应的数据库</p><pre><code>create database prometheus_test</code></pre><p>启动prometheus之后，可以在influxdb中看到生成的measurement，每个metric对应一个measurement，而metric中的label对应inflxudb的tag</p><pre><code># Prometheus metricexample_metric{queue=&quot;0:http://example:8086/api/v1/prom/write?db=prometheus&quot;,le=&quot;0.005&quot;} 308# Same metric parsed into InfluxDBmeasurement  example_metrictags  queue = &quot;0:http://example:8086/api/v1/prom/write?db=prometheus&quot;  le = &quot;0.005&quot;  job = &quot;prometheus&quot;  instance = &quot;localhost:9090&quot;  __name__ = &quot;example_metric&quot;fields  value = 308</code></pre><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1fzjzk2viz9j30sw0le423.jpg" alt=""></p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1fzjzkukt4wj317y0bmtac.jpg" alt=""></p><h3 id="federation"><a href="#federation" class="headerlink" title="federation"></a>federation</h3><p>启动三台prometheus server，其中一台作为master，从另外两台拉取数据</p><table><thead><tr><th>name</th><th>role</th><th>port</th></tr></thead><tbody><tr><td>prometheus</td><td>master</td><td>9090</td></tr><tr><td>node1</td><td>collector</td><td>9091</td></tr><tr><td>node2</td><td>collector</td><td>9092</td></tr></tbody></table><p>master配置</p><pre><code>global:  scrape_interval: 15s   evaluation_interval: 15s scrape_configs: - job_name: &#39;prometheus&#39;   honor_labels: true   metrics_path: &#39;/federate&#39;   params:    &#39;match[]&#39;:      - &#39;{job=&quot;node1&quot;}&#39;      - &#39;{job=&quot;node2&quot;}&#39;</code></pre><p>node1配置</p><pre><code>global:  scrape_interval:     15s  evaluation_interval: 15s  external_labels:      server: &#39;node1&#39;scrape_configs:  - job_name: &#39;node1&#39;    static_configs:      - targets: [&#39;localhost:9091&#39;]</code></pre><p>node2配置    </p><pre><code>global:  scrape_interval:     15s  evaluation_interval: 15s  external_labels:      server: &#39;node2&#39;scrape_configs:  - job_name: &#39;node2&#39;    static_configs:      - targets: [&#39;localhost:9092&#39;]</code></pre><p>启动3台prometheus</p><pre><code>#master./prometheus --config.file=prometheus.yml#node1./prometheus --config.file=prometheus-node1-9091.yml --storage.tsdb.path=data-node1 --web.listen-address=0.0.0.0:9091#node2./prometheus --config.file=prometheus-node2-9092.yml --storage.tsdb.path=data-node2 --web.listen-address=0.0.0.0:9092</code></pre><p>可以看到在master可以查询到另外两台node的数据</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1fzk187nu4wj326u0l443s.jpg" alt="">                 </p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://www.ctolib.com/docs/sfile/prometheus-book/alert/prometheus-recoding-rules.html" target="_blank" rel="noopener">使用Recoding Rules优化性能</a></li><li><a href="https://www.imuo.com/a/dbe9b42ff8b0c9569db6d250c4ca1261fc228876ef86ada92d45dc3523c20e20" target="_blank" rel="noopener">Prometheus 联邦及高可用详解</a></li><li><a href="https://hk.saowen.com/a/c1c70c681b1df019e2e8bc9291e1e43b489bbaaca5923b5b4fd9bb4f734c7d73" target="_blank" rel="noopener">Prometheus高可用方案策略</a></li><li><a href="http://dockone.io/article/6019" target="_blank" rel="noopener">Thanos：开源的大规模Prometheus集群解决方案</a></li><li><a href="https://docs.mesosphere.com/services/prometheus/0.1.1-2.3.2/configuration/remote-storage/" target="_blank" rel="noopener">Prometheus Remote Storage to InfluxDB</a></li><li><a href="https://docs.influxdata.com/influxdb/v1.7/supported_protocols/prometheus/" target="_blank" rel="noopener">Prometheus remote read and write API support</a></li><li><a href="https://kairen.github.io/2018/06/29/devops/prometheus-federation/" target="_blank" rel="noopener">了解 Prometheus Federation 功能</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 监控 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Prometheus简介</title>
      <link href="/2019/01/16/prometheus-jian-jie/"/>
      <url>/2019/01/16/prometheus-jian-jie/</url>
      
        <content type="html"><![CDATA[<h2 id="Prometheus简介"><a href="#Prometheus简介" class="headerlink" title="Prometheus简介"></a>Prometheus简介</h2><p>Prometheus 是一套开源的系统监控报警框架。作为新一代的监控框架，Prometheus具有如下几个特点</p><ol><li>多维度的数据模型</li><li>灵活和强大的查询语句(PromQL)</li><li>易于管理，prometheus是一个独立的二进制文件，不依赖分布式存储</li><li>采用pull模式利用HTTP采集数据</li><li>有多种的可视化图形界面(目前推荐使用Grafana展示数据)</li></ol><p>prometheus的架构如下图所示</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1fzbvfyy503j31ae0r60yu.jpg" alt=""></p><p>prometheus的主要工作流程如下</p><ol><li>prometheus serve定期从job pull metric，或者接收来自Pushgateway的metrics</li><li>prometheus将获取的metric存储在本地，并根据配置的alert rule向Alertmanage发送告警信息</li><li>Alertmanage根据配置，对接收的告警信息进行处理，发出相应的告警</li><li>可视化采集的数据</li></ol><h2 id="Prometheus相关概念"><a href="#Prometheus相关概念" class="headerlink" title="Prometheus相关概念"></a>Prometheus相关概念</h2><h3 id="instance"><a href="#instance" class="headerlink" title="instance"></a>instance</h3><p>一个单独采集的目标(target)，一般对应一个进程</p><h3 id="job"><a href="#job" class="headerlink" title="job"></a>job</h3><p>一组相同类型的instance</p><pre><code>web-api部署在多台实例上，prometheus会从每个实例上去采集数据job: web-api    instance x.x.x.x:port1    instance x.x.x.x:port2</code></pre><h3 id="sample"><a href="#sample" class="headerlink" title="sample"></a>sample</h3><p>实际的时间序列，每一个时间序列包含一个float64的值以及一个毫秒级的时间戳</p><h3 id="metric"><a href="#metric" class="headerlink" title="metric"></a>metric</h3><p>prometheus有4中metric，可以将metric理解为数据模型，metric的格式如下</p><pre><code>&lt;metric name&gt;{&lt;label name&gt;=&lt;label value&gt;,...}</code></pre><h3 id="label"><a href="#label" class="headerlink" title="label"></a>label</h3><p>标签，用来表示采集数据的维度,例如有个指标为http_request_total表示所有http请求的总数，则http_request_total{method=”POST”}则表示请求方式为POST的请求总数，其中method就是label</p><h2 id="Prometheus安装配置"><a href="#Prometheus安装配置" class="headerlink" title="Prometheus安装配置"></a>Prometheus安装配置</h2><p>下载<a href="https://prometheus.io/download" target="_blank" rel="noopener">prometheus</a>，解压安装包</p><pre><code>tar -zxvf prometheus-2.6.0.darwin-amd64.tar.gzcd prometheus-2.6.0.darwin-amd64</code></pre><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><p>prometheus安装包下有一个二进制文件，叫prometheus，之前运行该文件，即可启动prometheus server</p><pre><code>./prometheus --help</code></pre><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>prometheus的配置文件为prometheus.yml，内容如下</p><pre><code>global:  scrape_interval:     15s # prometheus server 从instance拉取metric的间隔  evaluation_interval: 15s # prometheus server检测alert rule的间隔  scrape_timeout: 10s # proemtheus server抓取数据的超时时间# Alertmanager 配置alerting:  alertmanagers:  - static_configs:    - targets:      # - alertmanager:9093# 告警规则rule_files:  # - &quot;first_rules.yml&quot;  # - &quot;second_rules.yml&quot;# 抓取对象配置scrape_configs:  # 全局唯一的名称，用来标识一个job  - job_name: &#39;prometheus&#39;    # 该job对应的所有instance    static_configs:    - targets: [&#39;localhost:9090&#39;]</code></pre><h2 id="Metric"><a href="#Metric" class="headerlink" title="Metric"></a>Metric</h2><h3 id="Counter"><a href="#Counter" class="headerlink" title="Counter"></a>Counter</h3><p>对数据进行累加，数据只会递增，例如http请求数，错误个数</p><h3 id="Guage"><a href="#Guage" class="headerlink" title="Guage"></a>Guage</h3><p>可以对数据进行加减，例如温度，线程数量</p><h3 id="Histogram"><a href="#Histogram" class="headerlink" title="Histogram"></a>Histogram</h3><p>可以理解为柱状图，依据事先设置的阈值，对采集数据进行分类统计，适合统计的指标如response time，request size等</p><p>Histogram具有3个指标值</p><pre><code>&lt;metric_name&gt;_bucket 对应分桶的条数&lt;metric_name&gt;_sum 采集数据求和的值&lt;metric_name&gt;_count 采集条数</code></pre><p>下面以实例来说明上述三个指标，例如对response time进行统计，总共采集了3条数据，分别是</p><pre><code>100ms,200ms,120ms</code></pre><p>则以下三个指标分别表示</p><pre><code>response_time_bucket{le=120}=2, response time小于等于120ms的数据有两条response_time_sum=(100+200+120)=420 对所有的response time进行求和response_time_count=3 总共采集了3条数据</code></pre><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>与Histogram类似，最大的区别在于Summary可以精确的统计百分位的值，例如90%的响应时间低于200ms</p><p>summary也有三个指标</p><pre><code>&lt;metric_name&gt;{quantile=&quot;&lt;q&gt;&quot;}  0=&lt;q&lt;=1 百分位位于q的值&lt;metric_name&gt;_sum 采集数据求和的值&lt;metric_name&gt;_count 采集条数</code></pre><h3 id="Histogram-VS-Summary"><a href="#Histogram-VS-Summary" class="headerlink" title="Histogram VS Summary"></a>Histogram VS Summary</h3><ul><li>都包含&lt;basename>_sum，&lt;basename>_count</li><li>Histogram 需要通过 \<basename>_bucket 计算 quantile, 而 Summary 直接存储了 quantile 的值。</basename></li></ul><h2 id="Prometheus实例演示"><a href="#Prometheus实例演示" class="headerlink" title="Prometheus实例演示"></a>Prometheus实例演示</h2><h3 id="启动prometheus"><a href="#启动prometheus" class="headerlink" title="启动prometheus"></a>启动prometheus</h3><pre><code>./prometheus --config.file=&quot;prometheus.yml&quot;</code></pre><p>启动成功之后可以在localhost:9090上查看对应的metric<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1fzbx49z7fqj327w0ra78w.jpg" alt=""></p><h3 id="查看对应的指标"><a href="#查看对应的指标" class="headerlink" title="查看对应的指标"></a>查看对应的指标</h3><p>在输入框中输入指标名称，即可看到对应指标的值</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1fzbx6jtpt3j327i0mu428.jpg" alt=""></p><h3 id="可视化指标"><a href="#可视化指标" class="headerlink" title="可视化指标"></a>可视化指标</h3><p>选择graph标签页，即可将对应的数据可视化，例如查看http请求code为200的QPS</p><pre><code>rate(promhttp_metric_handler_requests_total{code=&quot;200&quot;}[1m])</code></pre><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1fzbxac8hggj31ww0u0jva.jpg" alt=""></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://prometheus.io/docs/introduction/overview/" target="_blank" rel="noopener">https://prometheus.io/docs/introduction/overview/</a></li><li><a href="https://prometheus.io/docs/practices/histograms/" target="_blank" rel="noopener">https://prometheus.io/docs/practices/histograms/</a></li><li><a href="https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/index.html" target="_blank" rel="noopener">https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/index.html</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 监控 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Prometheus </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kafka源码分析——Consumer</title>
      <link href="/2019/01/13/kafka-yuan-ma-fen-xi-consumer/"/>
      <url>/2019/01/13/kafka-yuan-ma-fen-xi-consumer/</url>
      
        <content type="html"><![CDATA[<h2 id="Consumer使用实例"><a href="#Consumer使用实例" class="headerlink" title="Consumer使用实例"></a>Consumer使用实例</h2><h3 id="kafka-console-consumer"><a href="#kafka-console-consumer" class="headerlink" title="kafka-console-consumer"></a>kafka-console-consumer</h3><pre><code>sh kafka-console-consumer.sh ----bootstrap-server localhost:9092 --topic test --from-beginning</code></pre><h3 id="consumer-client"><a href="#consumer-client" class="headerlink" title="consumer client"></a>consumer client</h3><pre><code>Properties props = new Properties();props.put(&quot;bootstrap.servers&quot;,&quot;localhost:9092&quot;);    props.put(&quot;group.id&quot;,&quot;test_group_id&quot;);props.put(&quot;enable.auto.commit&quot;,&quot;true&quot;);props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;);props.put(&quot;key.deserializer&quot;,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);KafkaConsumer&lt;String,String&gt; consumer = new KafkaConsumer&lt;&gt;(props);while(true){    ConsumerRecords&lt;String,String&gt; records = consumer.poll(1000)    for(ConsumerRecord&lt;String, String&gt; record : records){        System.out.printf(&quot;offset=%d,key=%s,value=%s&quot;,record.offset(),record.key(),record.value());    }}</code></pre><p>可以看到consumer的入口在poll方法，下面来看下poll方法的实现</p><h2 id="Consumer-poll模型"><a href="#Consumer-poll模型" class="headerlink" title="Consumer poll模型"></a>Consumer poll模型</h2><pre><code>//timeout是Consumer消费的超时时间，如果设置为0，表示buffer中只要有数据就立刻拉取public ConsumerRecords&lt;K, V&gt; poll(long timeout) {    acquire();    try {        if (timeout &lt; 0)            throw new IllegalArgumentException(&quot;Timeout must not be negative&quot;);        if (this.subscriptions.hasNoSubscriptionOrUserAssignment())            throw new IllegalStateException(&quot;Consumer is not subscribed to any topics or assigned any partitions&quot;);        // poll for new data until the timeout expires        long start = time.milliseconds();        long remaining = timeout;        do {                //从订阅的partition中消费数据，pollonce是其核心实现            Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; records = pollOnce(remaining);            if (!records.isEmpty()) {                // 在返回获取数据之前，需要发起下次的fetch请求，主要是为了避免用户在处理获取数据，而导致fetch请求被阻塞                if (fetcher.sendFetches() &gt; 0 || client.pendingRequestCount() &gt; 0)                    client.pollNoWakeup();                if (this.interceptors == null)                    return new ConsumerRecords&lt;&gt;(records);                else                    return this.interceptors.onConsume(new ConsumerRecords&lt;&gt;(records));            }            long elapsed = time.milliseconds() - start;            remaining = timeout - elapsed;        } while (remaining &gt; 0);        return ConsumerRecords.empty();    } finally {        release();    }}</code></pre><p>Consumer的poll方法主要在做以下几件事：</p><ol><li>检测timeout是否合法以及Consumer是否订阅了相应的topic-partition</li><li>调用pollOnce方法获取数据</li><li>在返回结果前，提前发起下次的fetch请求，避免用户在处理返回数据时，而导致线程被阻塞</li><li>如果在timeout的时间中没有获取到数据，则返回空数据</li></ol><h3 id="pollOnce方法"><a href="#pollOnce方法" class="headerlink" title="pollOnce方法"></a>pollOnce方法</h3><pre><code>private Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; pollOnce(long timeout) {    coordinator.poll(time.milliseconds());    // 确认是否所有的分区的offset是否有效，更新没有生效的partition的offset    if (!subscriptions.hasAllFetchPositions())        updateFetchPositions(this.subscriptions.missingFetchPositions());    // 如果获取到数据，则立马返回    Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; records = fetcher.fetchedRecords();    if (!records.isEmpty())        return records;    // 对于新的fetch请求，立即发起请求    fetcher.sendFetches();    long now = time.milliseconds();    long pollTimeout = Math.min(coordinator.timeToNextPoll(now), timeout);     //调用底层的poll方法，发起请求    client.poll(pollTimeout, now, new PollCondition() {        @Override        public boolean shouldBlock() {            // 对于已完成的fetch请求，则不进行阻塞            return !fetcher.hasCompletedFetches();        }    });    // 如果消费组group需要进行负责均衡rebalance，则直接返回空数据，    if (coordinator.needRejoin())        return Collections.emptyMap();    return fetcher.fetchedRecords();}    </code></pre><p>pollOnce方法，主要有以下几个步骤：</p><ol><li>coordinator.poll()</li><li>updateFetchPositions()</li><li>fetcher.fetchedRecords()</li><li>fetcher.sendFetches()</li><li>client.poll()</li><li>coordinator.needRejoin()</li></ol><p>下面详细分析以上几个步骤</p><h3 id="ConsumerCoordinator-poll"><a href="#ConsumerCoordinator-poll" class="headerlink" title="ConsumerCoordinator.poll()"></a>ConsumerCoordinator.poll()</h3><pre><code>//确保这个group的coordinator是已知的，并且已经Consumer已经加入到这个group中public void poll(long now) {    invokeCompletedOffsetCommitCallbacks();      //若订阅了topic，并且该coordinator是未知的，则初始化coordinator    if (subscriptions.partitionsAutoAssigned() &amp;&amp; coordinatorUnknown()) {        ensureCoordinatorReady();        now = time.milliseconds();    }     //Consumer是否需要重新加入到group中（如果partition发生变化，则需要rejoin）    if (needRejoin()) {        // due to a race condition between the initial metadata fetch and the initial rebalance,        // we need to ensure that the metadata is fresh before joining initially. This ensures        // that we have matched the pattern against the cluster&#39;s topics at least once before joining.        if (subscriptions.hasPatternSubscription())            client.ensureFreshMetadata();          // 确保group是active的        ensureActiveGroup();        now = time.milliseconds();    }     //检测心跳线程是否正常，若不正常，则抛出异常    pollHeartbeat(now);    //开启auto commit时，当定时时间到时则自动提交    maybeAutoCommitOffsetsAsync(now);}</code></pre><h3 id="updateFetchPositions"><a href="#updateFetchPositions" class="headerlink" title="updateFetchPositions()"></a>updateFetchPositions()</h3><pre><code>//如果有committed position，则将fetch position设置为committed position，否则使用配置的重置策略去设置offsetprivate void updateFetchPositions(Set&lt;TopicPartition&gt; partitions) {    //先重置那些需要重置的partition，比如调用了seekToBeginning，seekToEnd的partition    fetcher.resetOffsetsIfNeeded(partitions);    if (!subscriptions.hasAllFetchPositions(partitions)) {        // if we still don&#39;t have offsets for the given partitions, then we should either        // seek to the last committed position or reset using the auto reset policy        // first refresh commits for all assigned partitions        coordinator.refreshCommittedOffsetsIfNeeded();        // then do any offset lookups in case some positions are not known        fetcher.updateFetchPositions(partitions);    }}   </code></pre><h3 id="fetcher-fetchedRecords"><a href="#fetcher-fetchedRecords" class="headerlink" title="fetcher.fetchedRecords()"></a>fetcher.fetchedRecords()</h3><pre><code>public Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; fetchedRecords() {    if (nextInLineExceptionMetadata != null) {        ExceptionMetadata exceptionMetadata = nextInLineExceptionMetadata;        nextInLineExceptionMetadata = null;        TopicPartition tp = exceptionMetadata.partition;        if (subscriptions.isFetchable(tp) &amp;&amp; subscriptions.position(tp) == exceptionMetadata.fetchedOffset)            throw exceptionMetadata.exception;    }    Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; drained = new HashMap&lt;&gt;();    int recordsRemaining = maxPollRecords;    while (recordsRemaining &gt; 0) {        if (nextInLineRecords == null || nextInLineRecords.isDrained()) {            CompletedFetch completedFetch = completedFetches.poll();            if (completedFetch == null) break;            try {                nextInLineRecords = parseCompletedFetch(completedFetch);            } catch (KafkaException e) {                if (drained.isEmpty())                    throw e;                nextInLineExceptionMetadata = new ExceptionMetadata(completedFetch.partition, completedFetch.fetchedOffset, e);            }        } else {            TopicPartition partition = nextInLineRecords.partition;            List&lt;ConsumerRecord&lt;K, V&gt;&gt; records = drainRecords(nextInLineRecords, recordsRemaining);            if (!records.isEmpty()) {                List&lt;ConsumerRecord&lt;K, V&gt;&gt; currentRecords = drained.get(partition);                if (currentRecords == null) {                    drained.put(partition, records);                } else {                    // this case shouldn&#39;t usually happen because we only send one fetch at a time per partition,                    // but it might conceivably happen in some rare cases (such as partition leader changes).                    // we have to copy to a new list because the old one may be immutable                    List&lt;ConsumerRecord&lt;K, V&gt;&gt; newRecords = new ArrayList&lt;&gt;(records.size() + currentRecords.size());                    newRecords.addAll(currentRecords);                    newRecords.addAll(records);                    drained.put(partition, newRecords);                }                recordsRemaining -= records.size();            }        }    }    return drained;}</code></pre><h3 id="fetcher-sendFetches"><a href="#fetcher-sendFetches" class="headerlink" title="fetcher.sendFetches()"></a>fetcher.sendFetches()</h3><pre><code>//向订阅的所有的partition所在leader发送fetch请求public int sendFetches() {     //构建fetch请求    Map&lt;Node, FetchRequest.Builder&gt; fetchRequestMap = createFetchRequests();    for (Map.Entry&lt;Node, FetchRequest.Builder&gt; fetchEntry : fetchRequestMap.entrySet()) {        final FetchRequest.Builder request = fetchEntry.getValue();        final Node fetchTarget = fetchEntry.getKey();        log.debug(&quot;Sending fetch for partitions {} to broker {}&quot;, request.fetchData().keySet(), fetchTarget);        //发起fetch请求        client.send(fetchTarget, request)                .addListener(new RequestFutureListener&lt;ClientResponse&gt;() {                    @Override                    public void onSuccess(ClientResponse resp) {                        FetchResponse response = (FetchResponse) resp.responseBody();                        if (!matchesRequestedPartitions(request, response)) {                            // obviously we expect the broker to always send us valid responses, so this check                            // is mainly for test cases where mock fetch responses must be manually crafted.                            log.warn(&quot;Ignoring fetch response containing partitions {} since it does not match &quot; +                                    &quot;the requested partitions {}&quot;, response.responseData().keySet(),                                    request.fetchData().keySet());                            return;                        }                        Set&lt;TopicPartition&gt; partitions = new HashSet&lt;&gt;(response.responseData().keySet());                        FetchResponseMetricAggregator metricAggregator = new FetchResponseMetricAggregator(sensors, partitions);                        for (Map.Entry&lt;TopicPartition, FetchResponse.PartitionData&gt; entry : response.responseData().entrySet()) {                            TopicPartition partition = entry.getKey();                            long fetchOffset = request.fetchData().get(partition).offset;                            FetchResponse.PartitionData fetchData = entry.getValue();                            completedFetches.add(new CompletedFetch(partition, fetchOffset, fetchData, metricAggregator,                                    request.version()));                        }                        sensors.fetchLatency.record(resp.requestLatencyMs());                        sensors.fetchThrottleTimeSensor.record(response.getThrottleTime());                    }                    @Override                    public void onFailure(RuntimeException e) {                        log.debug(&quot;Fetch request to {} for partitions {} failed&quot;, fetchTarget, request.fetchData().keySet(), e);                    }                });    }    return fetchRequestMap.size();}    </code></pre><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="http://matt33.com/2017/11/11/consumer-pollonce/" target="_blank" rel="noopener">http://matt33.com/2017/11/11/consumer-pollonce/</a></li><li><a href="http://matt33.com/2017/10/22/consumer-join-group/" target="_blank" rel="noopener">http://matt33.com/2017/10/22/consumer-join-group/</a>    </li></ul>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kafka源码分析——Producer</title>
      <link href="/2019/01/05/kafka-yuan-ma-fen-xi-producer/"/>
      <url>/2019/01/05/kafka-yuan-ma-fen-xi-producer/</url>
      
        <content type="html"><![CDATA[<h2 id="Producer-使用示例"><a href="#Producer-使用示例" class="headerlink" title="Producer 使用示例"></a>Producer 使用示例</h2><h3 id="kafka-console-producer"><a href="#kafka-console-producer" class="headerlink" title="kafka-console-producer"></a>kafka-console-producer</h3><pre><code>sh kafka-console-producer.sh --broker-list localhost:9092 --topic test</code></pre><h3 id="producer-client"><a href="#producer-client" class="headerlink" title="producer client"></a>producer client</h3><pre><code>Properties props = new Properties(); props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;); props.put(&quot;acks&quot;, &quot;all&quot;); props.put(&quot;retries&quot;, 0); props.put(&quot;batch.size&quot;, 16384); props.put(&quot;linger.ms&quot;, 1); props.put(&quot;buffer.memory&quot;, 33554432); props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props); for(int i = 0; i &lt; 100; i++)     producer.send(new ProducerRecord&lt;String, String&gt;(&quot;my-topic&quot;, Integer.toString(i), Integer.toString(i))); producer.close();</code></pre><p>上述调用kafka Producer相关API，可以看到非常简单</p><pre><code>1. 生成Producer的配置，例如broker的地址，重试次数，key和value的序列化方式2. 调用KafkaProducer的send方法</code></pre><p>下面来看下Producer send的具体流程</p><h2 id="Producer-数据发送流程"><a href="#Producer-数据发送流程" class="headerlink" title="Producer 数据发送流程"></a>Producer 数据发送流程</h2><h3 id="KafkaProducer-send方法"><a href="#KafkaProducer-send方法" class="headerlink" title="KafkaProducer send方法"></a>KafkaProducer send方法</h3><pre><code>/** * * @param record 需要发送的数据    * @param callback 当数据发送成功调用的回调函数 *    */public Future&lt;RecordMetadata&gt; send(ProducerRecord&lt;K, V&gt; record, Callback callback) {    // intercept the record, which can be potentially modified; this method does not throw exceptions    ProducerRecord&lt;K, V&gt; interceptedRecord = this.interceptors == null ? record : this.interceptors.onSend(record);    return doSend(interceptedRecord, callback);}    </code></pre><p>可以看到真正的发送逻辑是在doSend方法中</p><h3 id="KafkaProducer-doSend方法"><a href="#KafkaProducer-doSend方法" class="headerlink" title="KafkaProducer doSend方法"></a>KafkaProducer doSend方法</h3><pre><code>private Future&lt;RecordMetadata&gt; doSend(ProducerRecord&lt;K, V&gt; record, Callback callback) {    TopicPartition tp = null;    try {        // 1. 检测topic的元数据是否可用        ClusterAndWaitTime clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), maxBlockTimeMs);        long remainingWaitMs = Math.max(0, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs);        Cluster cluster = clusterAndWaitTime.cluster;        // 2. 对record的key和value进行序列化        byte[] serializedKey;        try {            serializedKey = keySerializer.serialize(record.topic(), record.key());        } catch (ClassCastException cce) {            throw new SerializationException(&quot;Can&#39;t convert key of class &quot; + record.key().getClass().getName() +                    &quot; to class &quot; + producerConfig.getClass(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).getName() +                    &quot; specified in key.serializer&quot;);        }        byte[] serializedValue;        try {            serializedValue = valueSerializer.serialize(record.topic(), record.value());        } catch (ClassCastException cce) {            throw new SerializationException(&quot;Can&#39;t convert value of class &quot; + record.value().getClass().getName() +                    &quot; to class &quot; + producerConfig.getClass(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG).getName() +                    &quot; specified in value.serializer&quot;);        }          // 3. 确定需要发送的partition        int partition = partition(record, serializedKey, serializedValue, cluster);        int serializedSize = Records.LOG_OVERHEAD + Record.recordSize(serializedKey, serializedValue);        ensureValidRecordSize(serializedSize);        tp = new TopicPartition(record.topic(), partition);        long timestamp = record.timestamp() == null ? time.milliseconds() : record.timestamp();        log.trace(&quot;Sending record {} with callback {} to topic {} partition {}&quot;, record, callback, record.topic(), partition);        // producer callback will make sure to call both &#39;callback&#39; and interceptor callback        Callback interceptCallback = this.interceptors == null ? callback : new InterceptorCallback&lt;&gt;(callback, this.interceptors, tp);        // 4. 往RecordAccumulator追加record        RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey, serializedValue, interceptCallback, remainingWaitMs);        // 5. 如果batch已经满了，或者新的batch已经创建了，则唤醒send线程发送数据        if (result.batchIsFull || result.newBatchCreated) {            log.trace(&quot;Waking up the sender since topic {} partition {} is either full or getting a new batch&quot;, record.topic(), partition);            this.sender.wakeup();        }        return result.future;        // handling exceptions and record the errors;        // for API exceptions return them in the future,        // for other exceptions throw directly    } catch (ApiException e) {        log.debug(&quot;Exception occurred during message send:&quot;, e);        if (callback != null)            callback.onCompletion(null, e);        this.errors.record();        if (this.interceptors != null)            this.interceptors.onSendError(record, tp, e);        return new FutureFailure(e);    } catch (InterruptedException e) {        this.errors.record();        if (this.interceptors != null)            this.interceptors.onSendError(record, tp, e);        throw new InterruptException(e);    } catch (BufferExhaustedException e) {        this.errors.record();        this.metrics.sensor(&quot;buffer-exhausted-records&quot;).record();        if (this.interceptors != null)            this.interceptors.onSendError(record, tp, e);        throw e;    } catch (KafkaException e) {        this.errors.record();        if (this.interceptors != null)            this.interceptors.onSendError(record, tp, e);        throw e;    } catch (Exception e) {        // we notify interceptor about all exceptions, since onSend is called before anything else in this method        if (this.interceptors != null)            this.interceptors.onSendError(record, tp, e);        throw e;    }}</code></pre><p>doSend方法主要做了一下几件事情</p><h4 id="1-确认topic的元数据是否可用"><a href="#1-确认topic的元数据是否可用" class="headerlink" title="1. 确认topic的元数据是否可用"></a>1. 确认topic的元数据是否可用</h4><pre><code>ClusterAndWaitTime clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), maxBlockTimeMs);</code></pre><h4 id="2-对record的key和value进行序列化"><a href="#2-对record的key和value进行序列化" class="headerlink" title="2. 对record的key和value进行序列化"></a>2. 对record的key和value进行序列化</h4><p>kafka提供了需要的序列化的方法，用户也可以根据需要自定义序列化方法，只要实现Serializer接口即可<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1fyvqrc8es2j31zq0kwais.jpg" alt=""></p><h4 id="3-确定需要发送的partition"><a href="#3-确定需要发送的partition" class="headerlink" title="3. 确定需要发送的partition"></a>3. 确定需要发送的partition</h4><pre><code>int partition = partition(record, serializedKey, serializedValue, cluster);private int partition(ProducerRecord&lt;K, V&gt; record, byte[] serializedKey, byte[] serializedValue, Cluster cluster) {    Integer partition = record.partition();    // 若指定了partition则使用指定的partition，若没指定则使用默认(DefaultPartitioner)的生成规则    return partition != null ?            partition :            partitioner.partition(                    record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);}//DefaultPartitioner 中的partition方法public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {    List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);    int numPartitions = partitions.size();    // 若key为空，则随机生成一个num，利用num对partition的格式取余，同时保存num，下次在取num时，则对num递增即可    if (keyBytes == null) {        int nextValue = nextValue(topic);        List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);        if (availablePartitions.size() &gt; 0) {            int part = Utils.toPositive(nextValue) % availablePartitions.size();            return availablePartitions.get(part).partition();        } else {            // no partitions are available, give a non-available partition            return Utils.toPositive(nextValue) % numPartitions;        }    } else {        // 若key不为空，则对key进行hash，并用得到的hash值对partition的个数进行取余        return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;    }}private int nextValue(String topic) {    AtomicInteger counter = topicCounterMap.get(topic);    // 若num为null，则随机取个num    if (null == counter) {        counter = new AtomicInteger(new Random().nextInt());        AtomicInteger currentCounter = topicCounterMap.putIfAbsent(topic, counter);        if (currentCounter != null) {            counter = currentCounter;        }    }    // 对num进行自增操作    return counter.getAndIncrement();}</code></pre><p>获取partition的流程图<br><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1fyvr5e6f0ij319i0nwn59.jpg" alt=""></p><h4 id="4-往RecordAccumulator追加record"><a href="#4-往RecordAccumulator追加record" class="headerlink" title="4. 往RecordAccumulator追加record"></a>4. 往RecordAccumulator追加record</h4><p>RecordAccumulator最重要的数据结构是batches，这是一个map，其中key是topicPartition，value是一个recordBatch的先进后出的队列, batchs的结构如下图所示。batchs每次从队尾append数据，从队头开始send数据</p><pre><code>private final ConcurrentMap&lt;TopicPartition, Deque&lt;RecordBatch&gt;&gt; batches;</code></pre><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNc79gy1fyvrv76ah2j30py0f4juz.jpg" alt=""></p><pre><code>public RecordAppendResult append(TopicPartition tp,                                 long timestamp,                                 byte[] key,                                 byte[] value,                                 Callback callback,                                 long maxTimeToBlock) throws InterruptedException {    // abortIncompleteBatches().    appendsInProgress.incrementAndGet();    try {        // 获取对应topicPartition的Deque        Deque&lt;RecordBatch&gt; dq = getOrCreateDeque(tp);        //对deque进行append操作，会保证线程安全        synchronized (dq) {            if (closed)                throw new IllegalStateException(&quot;Cannot send after the producer is closed.&quot;);            // 开始追加数据            RecordAppendResult appendResult = tryAppend(timestamp, key, value, callback, dq);            // 当前队尾的recordBatch数据追加成功，无需新建recordBatch            if (appendResult != null)                return appendResult;        }        // 当前队尾无recordBatch，或者数据已满，需要新分配recordBatch        int size = Math.max(this.batchSize, Records.LOG_OVERHEAD + Record.recordSize(key, value));        log.trace(&quot;Allocating a new {} byte message buffer for topic {} partition {}&quot;, size, tp.topic(), tp.partition());        ByteBuffer buffer = free.allocate(size, maxTimeToBlock);        synchronized (dq) {            // Need to check if producer is closed again after grabbing the dequeue lock.            if (closed)                throw new IllegalStateException(&quot;Cannot send after the producer is closed.&quot;);            RecordAppendResult appendResult = tryAppend(timestamp, key, value, callback, dq);            // recordBatch已经创建，需要释放刚刚分配的buffer            if (appendResult != null) {                free.deallocate(buffer);                return appendResult;            }            MemoryRecordsBuilder recordsBuilder = MemoryRecords.builder(buffer, compression, TimestampType.CREATE_TIME, this.batchSize);            RecordBatch batch = new RecordBatch(tp, recordsBuilder, time.milliseconds());            FutureRecordMetadata future = Utils.notNull(batch.tryAppend(timestamp, key, value, callback, time.milliseconds()));                // 在deque中追加新建的recordBatch            dq.addLast(batch);            // 往未返回ack的队列中，增加刚刚创建的recordBatch            incomplete.add(batch);            // 如果队列中有多个recordBatch，那么最先创建的recordBatch，肯定是可以发送的，或者新建的recordBatch已满，则可以发送数据            return new RecordAppendResult(future, dq.size() &gt; 1 || batch.isFull(), true);        }    } finally {        appendsInProgress.decrementAndGet();    }}</code></pre><h4 id="5-唤醒send线程发送数据"><a href="#5-唤醒send线程发送数据" class="headerlink" title="5. 唤醒send线程发送数据"></a>5. 唤醒send线程发送数据</h4><p>如果发现recordBatch达到发送的要求，则唤醒send线程开始发送数据，下面来看下send线程中的run方法</p><pre><code>package org.apache.kafka.clients.producer.internals;void run(long now) {    Cluster cluster = metadata.fetch();    // 获取可以发送的recordBatch    RecordAccumulator.ReadyCheckResult result = this.accumulator.ready(cluster, now);    // 如果topicPartition的leader是未知，则强制更新metadata    if (!result.unknownLeaderTopics.isEmpty()) {        // The set of topics with unknown leader contains topics with leader election pending as well as        // topics which may have expired. Add the topic again to metadata to ensure it is included        // and request metadata update, since there are messages to send to the topic.        for (String topic : result.unknownLeaderTopics)            this.metadata.add(topic);        this.metadata.requestUpdate();    }    // 删除没有ready的node    Iterator&lt;Node&gt; iter = result.readyNodes.iterator();    long notReadyTimeout = Long.MAX_VALUE;    while (iter.hasNext()) {        Node node = iter.next();        if (!this.client.ready(node, now)) {            iter.remove();            notReadyTimeout = Math.min(notReadyTimeout, this.client.connectionDelay(node, now));        }    }    // 获取对应node可发送的RecordBatch，key为node id    Map&lt;Integer, List&lt;RecordBatch&gt;&gt; batches = this.accumulator.drain(cluster,                                                                     result.readyNodes,                                                                     this.maxRequestSize,                                                                     now);    if (guaranteeMessageOrder) {        // Mute all the partitions drained        for (List&lt;RecordBatch&gt; batchList : batches.values()) {            for (RecordBatch batch : batchList)                this.accumulator.mutePartition(batch.topicPartition);        }    }    // 删除超时的RecordBatch    List&lt;RecordBatch&gt; expiredBatches = this.accumulator.abortExpiredBatches(this.requestTimeout, now);    // update sensors    for (RecordBatch expiredBatch : expiredBatches)        this.sensors.recordErrors(expiredBatch.topicPartition.topic(), expiredBatch.recordCount);    sensors.updateProduceRequestMetrics(batches);    // If we have any nodes that are ready to send + have sendable data, poll with 0 timeout so this can immediately    // loop and try sending more data. Otherwise, the timeout is determined by nodes that have partitions with data    // that isn&#39;t yet sendable (e.g. lingering, backing off). Note that this specifically does not include nodes    // with sendable data that aren&#39;t ready to send since they would cause busy looping.    long pollTimeout = Math.min(result.nextReadyCheckDelayMs, notReadyTimeout);    if (!result.readyNodes.isEmpty()) {        log.trace(&quot;Nodes with data ready to send: {}&quot;, result.readyNodes);        pollTimeout = 0;    }    // 发送RecordBatch    sendProduceRequests(batches, now);    // if some partitions are already ready to be sent, the select time would be 0;    // otherwise if some partition already has some data accumulated but not ready yet,    // the select time will be the time difference between now and its linger expiry time;    // otherwise the select time will be the time difference between now and the metadata expiry time;    this.client.poll(pollTimeout, now);}</code></pre><p>可以看到具体的发送逻辑在sendProduceRequests</p><pre><code>private void sendProduceRequest(long now, int destination, short acks, int timeout, List&lt;RecordBatch&gt; batches) {    Map&lt;TopicPartition, MemoryRecords&gt; produceRecordsByPartition = new HashMap&lt;&gt;(batches.size());    final Map&lt;TopicPartition, RecordBatch&gt; recordsByPartition = new HashMap&lt;&gt;(batches.size());    // 将同一个topicPartition的RecordBatch放在一起发送    for (RecordBatch batch : batches) {        TopicPartition tp = batch.topicPartition;        produceRecordsByPartition.put(tp, batch.records());        recordsByPartition.put(tp, batch);    }    ProduceRequest.Builder requestBuilder =            new ProduceRequest.Builder(acks, timeout, produceRecordsByPartition);    RequestCompletionHandler callback = new RequestCompletionHandler() {        public void onComplete(ClientResponse response) {            handleProduceResponse(response, recordsByPartition, time.milliseconds());        }    };    String nodeId = Integer.toString(destination);    ClientRequest clientRequest = client.newClientRequest(nodeId, requestBuilder, now, acks != 0, callback);    client.send(clientRequest, now);    log.trace(&quot;Sent produce request to {}: {}&quot;, nodeId, requestBuilder);}</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>总结一下Producer的发送流程</p><ol><li>确认topic的元数据是否可用</li><li>对key和value进行序列化</li><li>确定发送的partition</li><li>往RecordAccumulator追加record</li><li>如果满足发送条件，则唤醒sender线程发送数据</li></ol>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kafka——QuickStart(2)</title>
      <link href="/2018/12/20/kafka-quickstart-2/"/>
      <url>/2018/12/20/kafka-quickstart-2/</url>
      
        <content type="html"><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="下载源码安装"><a href="#下载源码安装" class="headerlink" title="下载源码安装"></a>下载源码安装</h3><p><a href="https://kafka.apache.org/downloads" target="_blank" rel="noopener">下载地址</a></p><p>我用的kafka的版本是0.10.2.0，后续的例子都是使用这个版本</p><pre><code>tar -zxvf kafka-0.10.2.0-src.tgzcd kafka-0.10.2.0</code></pre><h3 id="Mac-Homebrew安装"><a href="#Mac-Homebrew安装" class="headerlink" title="Mac Homebrew安装"></a>Mac Homebrew安装</h3><pre><code>brew install kafka</code></pre><p>kafka的启动需要依赖zookeeper，用homebrew安装时，会自动安装zookeeper。安装完成之后，可以用以下命令查看安装信息</p><pre><code>brew info kafka</code></pre><p>kafka的安装路径，可以用以下命令查看</p><pre><code>brew list kakfa</code></pre><p>一般情况下，brew安装的项目路径为</p><pre><code>/usr/local/Cellar</code></pre><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><h3 id="1-启动zookeeper"><a href="#1-启动zookeeper" class="headerlink" title="1. 启动zookeeper"></a>1. 启动zookeeper</h3><pre><code>cd /usr/local/Cellar/kafka/0.10.2.0/libexec/binsh zookeeper-server-start.sh ../config/zookeeper.properties</code></pre><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNbRwgy1fyfqs9ohd9j327o0patom.jpg" alt=""></p><h3 id="2-启动Kafka-Server"><a href="#2-启动Kafka-Server" class="headerlink" title="2. 启动Kafka Server"></a>2. 启动Kafka Server</h3><pre><code>sh kafka-server-start.sh ../config/server.properties</code></pre><h3 id="3-创建Topic"><a href="#3-创建Topic" class="headerlink" title="3. 创建Topic"></a>3. 创建Topic</h3><pre><code>sh kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test</code></pre><h3 id="4-启动Producer"><a href="#4-启动Producer" class="headerlink" title="4. 启动Producer"></a>4. 启动Producer</h3><pre><code>sh kafka-console-producer.sh --broker-list localhost:9092 --topic test</code></pre><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNbRwgy1fyfqzagbuvj31me07cwfr.jpg" alt="">    </p><h3 id="5-启动Consumer"><a href="#5-启动Consumer" class="headerlink" title="5. 启动Consumer"></a>5. 启动Consumer</h3><pre><code>sh kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning</code></pre><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNbRwgy1fyfr1m23mqj327o08s0vr.jpg" alt=""></p><p>对于新的kafka版本，可以使用如下的命令</p><pre><code>sh kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning</code></pre><h2 id="kafka配置"><a href="#kafka配置" class="headerlink" title="kafka配置"></a>kafka配置</h2><h3 id="broker-配置"><a href="#broker-配置" class="headerlink" title="broker 配置"></a>broker 配置</h3><h4 id="基本配置"><a href="#基本配置" class="headerlink" title="基本配置"></a>基本配置</h4><table><thead><tr><th>配置名称</th><th>配置说明</th></tr></thead><tbody><tr><td>broker.id</td><td>broker在集群中的唯一标识</td></tr><tr><td>listeners</td><td>kafka监听的地址，如果没有配置，则使用java.net.InetAddress.getCanonicalHostName()获取的值</td></tr><tr><td>num.network.threads</td><td>处理网络请求的线程数</td></tr><tr><td>num.io.threads</td><td>处理I/O的线程数</td></tr><tr><td>socket.send.buffer.bytes</td><td>发送缓存区的大小</td></tr><tr><td>socket.receive.buffer.bytes</td><td>接收缓冲区的大小</td></tr><tr><td>socket.request.max.bytes</td><td>kafka允许接收或发送消息的最大字节数</td></tr></tbody></table><h4 id="zookeeper-配置"><a href="#zookeeper-配置" class="headerlink" title="zookeeper 配置"></a>zookeeper 配置</h4><table><thead><tr><th>配置名称</th><th>配置说明</th></tr></thead><tbody><tr><td>zookeeper.connect</td><td>zookeeper的连接地址，多个Server间以逗号分隔</td></tr><tr><td>zookeeper.connection.timeout.ms</td><td>连接zookeeper的超时时间</td></tr></tbody></table><h4 id="日志刷新策略"><a href="#日志刷新策略" class="headerlink" title="日志刷新策略"></a>日志刷新策略</h4><table><thead><tr><th>配置名称</th><th>配置说明</th></tr></thead><tbody><tr><td>log.flush.interval.messages</td><td>每次刷新至磁盘的消息数</td></tr><tr><td>log.flush.interval.ms</td><td>在数据被写入到硬盘前的最大时间</td></tr></tbody></table><h4 id="日志持久化策略"><a href="#日志持久化策略" class="headerlink" title="日志持久化策略"></a>日志持久化策略</h4><table><thead><tr><th>配置名称</th><th>配置说明</th></tr></thead><tbody><tr><td>log.retention.hours</td><td>日志保留的最长时间</td></tr><tr><td>log.retention.bytes</td><td>日志最大字节数</td></tr><tr><td>log.segment.bytes</td><td>单个log segment文件的大小</td></tr><tr><td>log.retention.check.interval.ms</td><td>检查log失效的间隔</td></tr></tbody></table><h3 id="producer-配置"><a href="#producer-配置" class="headerlink" title="producer 配置"></a>producer 配置</h3><table><thead><tr><th>配置名称</th><th>配置说明</th></tr></thead><tbody><tr><td>bootstrap.servers</td><td>broker地址</td></tr><tr><td>compression.type</td><td>数据压缩策略，none,gzip,snappy,lz4</td></tr><tr><td>partitioner.class</td><td>处理分区的类，默认根据key的hash分发到对应的分区</td></tr><tr><td>request.timeout.ms</td><td>请求的超时时间</td></tr></tbody></table><h3 id="consumer-配置"><a href="#consumer-配置" class="headerlink" title="consumer 配置"></a>consumer 配置</h3><table><thead><tr><th>配置名称</th><th>配置说明</th></tr></thead><tbody><tr><td>zookeeper.connect</td><td>zookeeper连接地址</td></tr><tr><td>zookeeper.connection.timeout.ms</td><td>zookeeper连接超时时间</td></tr><tr><td>group.id</td><td>消费组id</td></tr><tr><td>consumer.timeout.ms</td><td>消费者超时时间</td></tr></tbody></table><h2 id="kafka脚本参数说明"><a href="#kafka脚本参数说明" class="headerlink" title="kafka脚本参数说明"></a>kafka脚本参数说明</h2><h3 id="kafka-config"><a href="#kafka-config" class="headerlink" title="kafka-config"></a>kafka-config</h3><p>用于查看并修改kafka的配置，–describe 查看配置， –alter 修改配置</p><table><thead><tr><th>参数名称</th><th>参数说明</th></tr></thead><tbody><tr><td>entity-type</td><td>配置类型，有topics/clients/users/brokers</td></tr><tr><td>entiey-name</td><td>配置名称，对于topics就是topic的名称</td></tr></tbody></table><p>可以通过以下命令查看可管理的配置</p><pre><code>sh kafka-config.sh --help</code></pre><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNbRwgy1fyfuab7stej30u016pdod.jpg" alt="">    </p><h4 id="describe"><a href="#describe" class="headerlink" title="describe"></a>describe</h4><pre><code>sh kafka-configs.sh --zookeeper localhost:2181 --describe --entity-type topics</code></pre><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNbRwgy1fyftxq5ao7j320s04g0uv.jpg" alt=""></p><h4 id="alter"><a href="#alter" class="headerlink" title="alter"></a>alter</h4><pre><code>sh kafka-configs.sh --zookeeper localhost:2181 --alter --entity-type topics --entity-name test --add-config retention.ms=600000</code></pre><p>这个时候在看topic test的配置，发现配置已修改</p><p><img src="https://raw.githubusercontent.com/BloodHunter/blog-comments/master/006tNbRwgy1fyfu4kxpczj321o034wfw.jpg" alt="">    </p><h3 id="kafka-console-consumer"><a href="#kafka-console-consumer" class="headerlink" title="kafka-console-consumer"></a>kafka-console-consumer</h3><p>启动一个consumer</p><table><thead><tr><th>参数名称</th><th>参数说明</th></tr></thead><tbody><tr><td>bootstrap-server</td><td>broker地址，localhost:9092</td></tr><tr><td>zookeeper</td><td>zookeeper地址，localhost:2181</td></tr><tr><td>topic</td><td>topic名称</td></tr><tr><td>formatter</td><td>格式化消息的类的名称</td></tr><tr><td>from-beginning</td><td>如果consumer没有设置offset，则从最开始的消息开始消费，而不是最新的数据</td></tr><tr><td>offset</td><td>指定offset的位置，可以是正整数，也可以是earliest/latest，默认是latest</td></tr><tr><td>partition</td><td>指定从哪个partition开始消费数据</td></tr></tbody></table><h3 id="kafka-topics"><a href="#kafka-topics" class="headerlink" title="kafka-topics"></a>kafka-topics</h3><p>创建，删除，修改topic</p><table><thead><tr><th>参数名称</th><th>参数说明</th></tr></thead><tbody><tr><td>config</td><td>topic配置</td></tr><tr><td>delete-config</td><td>删除配置</td></tr><tr><td>create</td><td>创建topic</td></tr><tr><td>delete</td><td>删除topic</td></tr><tr><td>partitions</td><td>topic的分区数</td></tr><tr><td>replication-factor</td><td>topic备份的数</td></tr><tr><td>topic</td><td>topic名称</td></tr></tbody></table><h4 id="create-topic"><a href="#create-topic" class="headerlink" title="create topic"></a>create topic</h4><pre><code>sh kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 2 --topic test-topic</code></pre><h4 id="delete-topic"><a href="#delete-topic" class="headerlink" title="delete topic"></a>delete topic</h4><pre><code>sh kafka-topics.sh --delete -zookeeper localhost:2181 --topic test-topic</code></pre><h4 id="describe-topic"><a href="#describe-topic" class="headerlink" title="describe topic"></a>describe topic</h4><pre><code>sh kafka-topics.sh --zookeeper localhost:2181 --describe --topic test-topic</code></pre><h4 id="alter-topic"><a href="#alter-topic" class="headerlink" title="alter topic"></a>alter topic</h4><p>修改partitions和replica的个数，只能增加</p><pre><code>sh kafka-topics.sh --alter -zookeeper localhost:2181 --topic test-topic --partitions 3                </code></pre><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://kafka.apache.org/documentation/#configuration" target="_blank" rel="noopener">https://kafka.apache.org/documentation/#configuration</a></li><li><a href="https://my.oschina.net/u/1757002/blog/868517" target="_blank" rel="noopener">https://my.oschina.net/u/1757002/blog/868517</a></li><li><a href="https://www.jianshu.com/p/f94bb7a70ab6" target="_blank" rel="noopener">https://www.jianshu.com/p/f94bb7a70ab6</a></li><li><a href="https://www.jianshu.com/p/3ed342a28a9d" target="_blank" rel="noopener">https://www.jianshu.com/p/3ed342a28a9d</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kafka—-入门介绍(1)</title>
      <link href="/2018/12/16/kafka-ru-men-jie-shao-1/"/>
      <url>/2018/12/16/kafka-ru-men-jie-shao-1/</url>
      
        <content type="html"><![CDATA[<h2 id="Kafka介绍"><a href="#Kafka介绍" class="headerlink" title="Kafka介绍"></a>Kafka介绍</h2><p>kafka是一个分布式的，基于发布/订阅的消息系统。简单的可以理解kafka是一个消息队列，可以往队列里面写入数据，也可以从队列里面取出数据进行处理。</p><h2 id="kafka关键概念"><a href="#kafka关键概念" class="headerlink" title="kafka关键概念"></a>kafka关键概念</h2><p>我以自来水厂的例子来解释kafka的相关概念，可能不够严谨，只为方便大家理解。</p><p>从前有一家自来水厂(producer)负责把水运输到不同的地方，以供当地的居民(consumer)使用。冬天大家用水较少，但是水厂又一直在送水，导致水浪费了；到了夏天大家用水多，自来水来不及生产，导致居民无水可用。因此需要一个蓄水池(broker),自来水厂将水运输到蓄水池中，居民从蓄水池取水使用。蓄水池通过一个管道(topic)将水运输到不同的小区中</p><h3 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h3><p>topic可以理解数据标签，kafka通过topic对数据进行分门别类，就好比上述例子中的管道，使得自来水可以流向不同的地方，而不导致水混在一起。</p><h3 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h3><p>生产者，数据的来源，就好比上述例子中自来水厂，水都是从自来水来的。</p><h3 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h3><p>消费者，数据的处理者，就好比上述例子中的居民，居民需要取水喝。</p><h3 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h3><p>数据保存的地方，多个broker构成一个kafka集群。就好比上述例子中的蓄水池，生成者生成的数据都保存在broker中。</p><h2 id="Topic抽象"><a href="#Topic抽象" class="headerlink" title="Topic抽象"></a>Topic抽象</h2><p><img src="http://img.orchome.com:8888/group1/M00/00/01/KmCudlf7DsaAVF0WAABMe0J0lv4158.png" alt=""></p><p>topic是一个大的管道，但是为了提供吞吐量，在管道中有设置了许多小的通道(partition)，也就是分区。每一个分区都是一个<strong>顺序的</strong>，不可变的消息队列，并且可以持续添加。每个分区通过一个唯一的offset来标识消息处理的进度。</p><p>消费者可以控制offset，例如消费可以控制从最新的数据开始消费，即设置offset为new，也可以从最早的数据开始消费，即设置offset为early</p><h2 id="生成者"><a href="#生成者" class="headerlink" title="生成者"></a>生成者</h2><p>生产者负责往某个topic写入数据。由于topic有多个分区，数据可能会按照分区的顺序写入，也可以按照某种算法写入对应的分区，这个可以有开发者自己控制。</p><h2 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h2><p>消费者负责从topic中读取数据。kafka为消费者提供了一个抽象模型-消费组(consumer group)。消费组可以对应上述例子中小区，每一个居民都是消费者(consumer)，同一个小区的居民就是属于同一个消费组。</p><p>kafka之所以抽象消费组的概念，是为了兼容两种消费模型，队列模型和发布-订阅模型。对于队列来说，一组消费者从同一个服务器消费数据，一个消息只能由一个消费者消费。在发布-订阅模型中，一个消息被广播给所有的消费者。如果所有的消费者都在一个消费组中，则变成了队列模型；如果每一个消费者都在不同的消费组中，则变成了发布-订阅模型。</p><p><img src="http://img.orchome.com:8888/group1/M00/00/01/KmCudlf7D-OAEjy8AABoxGLnMI4173.png" alt=""></p><p>在kafka中，一个分区中的消息只能被同一个消费组中一个消费者消费。例如一个topic中有三个分区p1,p2,p3。消费组groupA，只有一个消费者A1；消费者groupB，有4个消费者，B1,B2,B3,B4。则消费情况可能如下所示，</p><p>对于消费组groupA，</p><table><thead><tr><th>partition</th><th>consumer</th></tr></thead><tbody><tr><td>p1</td><td>A1</td></tr><tr><td>p2</td><td>A1</td></tr><tr><td>p3</td><td>A1</td></tr></tbody></table><p>由于groupA只有一个consumer，所以所有的分区都由这个consumer消费</p><p>对于消费组groupB</p><table><thead><tr><th>partition</th><th>consumer</th></tr></thead><tbody><tr><td>p1</td><td>B1</td></tr><tr><td>p2</td><td>B2</td></tr><tr><td>p3</td><td>B3</td></tr></tbody></table><p>groupB有4个consumer，但是这个topic只有3个partition，所以有一个consumer将消费不到任何数据，除非其中一个consumer挂掉了，剩下空闲的这个consumer才会上位。</p><p><strong>一个partition的数据，只能由一个consumer group的一个consumer消费</strong></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul><li><a href="https://kafka.apache.org/documentation/" target="_blank" rel="noopener">Apache Kafka</a></li><li><a href="https://www.infoq.cn/article/kafka-analysis-part-1" target="_blank" rel="noopener">Kafka 设计解析（一）：Kafka 背景及架构介绍</a></li><li><a href="http://orchome.com/5#/collapse-1005" target="_blank" rel="noopener">kafka入门介绍</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
